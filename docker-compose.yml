# Docker Compose with profiles for dev/prod separation
#
# Usage:
#   Production (default): docker compose run --rm llm-energy-measure-app <command>
#   Development:          docker compose --profile dev run --rm llm-energy-measure-dev <command>
#
# Examples:
#   docker compose run --rm llm-energy-measure-app llm-energy-measure --help
#   docker compose run --rm llm-energy-measure-app llm-energy-measure experiment /app/configs/test.yaml -d alpaca -n 100
#   docker compose --profile dev run --rm llm-energy-measure-dev /bin/bash

# Shared configuration anchor
x-common: &common
  # Run as host user: DOCKER_UID=$(id -u) DOCKER_GID=$(id -g) docker compose ...
  # Defaults to root (0:0) for backwards compatibility
  user: "${DOCKER_UID:-0}:${DOCKER_GID:-0}"

  # GPU access with privileged mode for NVML energy metrics
  privileged: true
  deploy:
    resources:
      reservations:
        devices:
          - driver: nvidia
            count: all
            capabilities: [gpu, utility]

  # Environment variables
  environment:
    - HF_TOKEN
    - CUDA_VISIBLE_DEVICES
    - HF_HOME=/app/.cache/huggingface
    - PIP_NO_CACHE_DIR=1
    - CODECARBON_LOG_LEVEL=warning
    - NVIDIA_DISABLE_REQUIRE=true

  working_dir: /app

  healthcheck:
    test: ["CMD", "python", "-c", "import torch; assert torch.cuda.is_available()"]
    interval: 30s
    timeout: 10s
    retries: 3

services:
  # ==========================================================================
  # Production service - uses runtime stage with baked-in package
  # ==========================================================================
  llm-energy-measure-app:
    <<: *common
    build:
      context: .
      dockerfile: Dockerfile
      target: runtime
    image: llm-energy-measure:latest

    volumes:
      - ./configs:/app/configs:ro
      - ./scripts:/app/scripts:ro
      - ./results:/app/results
      # Uncomment to persist HuggingFace model cache:
      # - ${HF_HOME:-~/.cache/huggingface}:/app/.cache/huggingface

  # ==========================================================================
  # Development service - uses dev stage with editable install
  # ==========================================================================
  llm-energy-measure-dev:
    <<: *common
    profiles: ["dev"]
    build:
      context: .
      dockerfile: Dockerfile
      target: dev
    image: llm-energy-measure:dev

    volumes:
      # Mount source for editable install
      - .:/app
      # Persist HuggingFace cache
      - ${HF_HOME:-~/.cache/huggingface}:/app/.cache/huggingface

    # Auto-install editable package, then run command or shell
    entrypoint: ["/app/scripts/dev-entrypoint.sh"]
    command: []
