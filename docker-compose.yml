services:
  bench:
    build:
      context: .
      dockerfile: Dockerfile
      target: runtime  # Use runtime stage (has package installed), not dev stage
    image: llm-energy-measure:latest

    # GPU access with privileged mode for NVML energy metrics
    # Note: privileged is required for CodeCarbon to read GPU power via NVML
    privileged: true
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu, utility]

    # Volumes
    volumes:
      # Experiment configs (read-only)
      - ./configs:/app/configs:ro
      # Scripts (read-only)
      - ./scripts:/app/scripts:ro
      # Results output
      - ./results:/app/results
      # HuggingFace cache (optional - uncomment to persist models)
      # - ${HF_HOME:-~/.cache/huggingface}:/home/app/.cache/huggingface

    # Environment variables (see .env.example)
    environment:
      - HF_TOKEN
      - CUDA_VISIBLE_DEVICES
      - HF_HOME=/home/app/.cache/huggingface
      - TRANSFORMERS_CACHE=/home/app/.cache/huggingface
      - CODECARBON_LOG_LEVEL=warning
      - NVIDIA_DISABLE_REQUIRE=true  # Suppress CUDA startup banner

    # Working directory
    working_dir: /app

    # Health check - verify GPU is accessible
    healthcheck:
      test: ["CMD", "python", "-c", "import torch; assert torch.cuda.is_available()"]
      interval: 30s
      timeout: 10s
      retries: 3

    # Default shows help; override with: docker compose run --rm bench <command>
    # Examples:
    #   docker compose run --rm bench llm-energy-measure experiment /app/configs/test.yaml -d alpaca -n 100
    #   docker compose run --rm bench accelerate launch --num_processes 2 -m llm_energy_measure.orchestration.launcher ...
