# =============================================================================
# LLenergyMeasure - Environment Configuration
# =============================================================================
#
# IMPORTANT: Run ./setup.sh to auto-generate this file (.env) with correct values!
# Or manually: cp env.example .env && edit values below
#
# =============================================================================

# -----------------------------------------------------------------------------
# REQUIRED: Docker User/Group Mapping
# -----------------------------------------------------------------------------
# These are AUTO-GENERATED by setup.sh. If creating manually:
#   PUID=$(id -u)  # Run this command to get your user ID
#   PGID=$(id -g)  # Run this command to get your group ID
#
# Leaving empty will trigger an error reminding you to run setup.sh:
PUID=
PGID=

# -----------------------------------------------------------------------------
# HuggingFace Configuration
# -----------------------------------------------------------------------------
# Token for gated models (Llama, Mistral, etc.)
# Get yours at: https://huggingface.co/settings/tokens
HF_TOKEN=

# -----------------------------------------------------------------------------
# OPTIONAL: Path Overrides (defaults shown)
# -----------------------------------------------------------------------------
# LLM_ENERGY_RESULTS_DIR=./results
# LLM_ENERGY_CONFIGS_DIR=./configs

# -----------------------------------------------------------------------------
# OPTIONAL: Default Backend
# -----------------------------------------------------------------------------
# Fallback when config doesn't specify backend (pytorch, vllm, tensorrt)
# Note: Config file's backend field takes precedence
# LEM_BACKEND=pytorch

# -----------------------------------------------------------------------------
# OPTIONAL: Performance/Debug
# -----------------------------------------------------------------------------
# CUDA_VISIBLE_DEVICES=0,1,2,3
# OMP_NUM_THREADS=4
# TOKENIZERS_PARALLELISM=false
# CODECARBON_LOG_LEVEL=warning
