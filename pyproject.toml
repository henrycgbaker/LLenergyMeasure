[tool.poetry]
name = "llm-energy-measure"
version = "2.0.0"
description = "LLM inference efficiency measurement framework"
authors = ["henrycgbaker <henry.c.g.baker@gmail.com>"]
readme = "README.md"
packages = [{include = "llm_energy_measure", from = "src"}]

[tool.poetry.dependencies]
python = "^3.10"
# Core dependencies (all backends)
torch = "^2.5.0"
pydantic = "^2.0"
loguru = "^0.7.0"
typer = "^0.15.0"
codecarbon = "^2.8.0"
nvidia-ml-py = "^12.0.0"  # GPU monitoring (replaces deprecated pynvml)
datasets = "^3.0.0"
schedule = "^1.2.2"
python-dotenv = "^1.0.0"
tqdm = "^4.66.0"
transformers = "^4.49.0"

# Optional: PyTorch/HuggingFace backend
accelerate = {version = "^1.4.0", optional = true}
bitsandbytes = {version = "^0.45.0", optional = true}
calflops = {version = "^0.2.0", optional = true}
peft = {version = "^0.18.1", optional = true}

# Optional: vLLM backend (high-throughput inference)
# Requires: NVIDIA GPU, Linux only
# Note: Has dependency conflicts with TensorRT - install separately
vllm = {version = ">=0.6.0", optional = true}

# Optional: ONNX Runtime for torch.compile backend='onnxrt'
# Enables torch.compile to use ONNX Runtime for execution
onnxruntime-gpu = {version = ">=1.17.0", optional = true}

# Optional: TensorRT-LLM backend (high-performance compiled inference)
# Requires: NVIDIA GPU with compute capability >= 8.0 (Ampere/Ada/Hopper), CUDA 12.x, Linux only
# Note: Has dependency conflicts with vLLM - install separately
tensorrt-llm = {version = ">=0.12.0", optional = true}

# Optional: API/Web backend
fastapi = {version = "^0.115.0", optional = true}
uvicorn = {version = "^0.32.0", optional = true}
sqlalchemy = {version = "^2.0", extras = ["asyncio"], optional = true}
asyncpg = {version = "^0.30.0", optional = true}
alembic = {version = "^1.14.0", optional = true}
pydantic-settings = {version = "^2.0", optional = true}
python-jose = {version = "^3.3.0", extras = ["cryptography"], optional = true}
httpx = {version = ">=0.23.0", optional = true}

# Optional: dev dependencies
pytest = {version = "^8.0", optional = true}
pytest-cov = {version = "^4.0", optional = true}
ruff = {version = "^0.8.0", optional = true}
mypy = {version = "^1.0", optional = true}
pre-commit = {version = "^3.0", optional = true}
types-pyyaml = {version = "^6.0.12.20250915", optional = true}
commitizen = {version = "^4.0", optional = true}

[tool.poetry.extras]
# PyTorch/HuggingFace backend (works on any NVIDIA GPU)
# Usage: pip install llm-energy-measure[pytorch]
# Includes ONNX Runtime for torch.compile backend='onnxrt' option
pytorch = ["accelerate", "bitsandbytes", "calflops", "peft", "onnxruntime-gpu"]

# vLLM backend (high-throughput inference)
# Requires: NVIDIA GPU, Linux only
# Usage: pip install llm-energy-measure[vllm]
# WARNING: Do not install alongside [tensorrt] - dependency conflicts
vllm = ["vllm"]

# TensorRT-LLM backend (high-performance compiled inference)
# Requires: NVIDIA GPU (Ampere+, compute capability >= 8.0), CUDA 12.x, Linux only
# Usage: pip install llm-energy-measure[tensorrt]
# WARNING: Do not install alongside [vllm] - dependency conflicts
tensorrt = ["tensorrt-llm"]

# Web API backend (leaderboard server)
# Usage: pip install llm-energy-measure[api]
api = ["fastapi", "uvicorn", "sqlalchemy", "asyncpg", "alembic", "pydantic-settings", "python-jose", "httpx"]

# Development tools
# Usage: pip install llm-energy-measure[dev]
dev = ["pytest", "pytest-cov", "ruff", "mypy", "pre-commit", "types-pyyaml", "commitizen"]

# PyTorch + dev (safe combination for development)
# Usage: pip install llm-energy-measure[pytorch,dev]
# Note: Do NOT use [all] - backend extras conflict with each other
all = ["accelerate", "bitsandbytes", "calflops", "peft", "pytest", "pytest-cov", "ruff", "mypy", "pre-commit", "types-pyyaml", "commitizen"]

[tool.poetry.scripts]
llm-energy-measure = "llm_energy_measure.cli:app"
lem = "llm_energy_measure.cli:app"  # Short alias

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"

[tool.ruff]
line-length = 100
target-version = "py310"

[tool.ruff.lint]
select = ["E", "F", "I", "UP", "B", "SIM", "RUF"]
ignore = ["E501"]  # Line length handled by formatter

[tool.ruff.format]
quote-style = "double"
indent-style = "space"

[tool.mypy]
python_version = "3.10"
strict = true
ignore_missing_imports = true
# Disable checks that fail on untyped third-party libs (torch, transformers)
disallow_untyped_calls = false
# Allow unused type: ignore comments (needed for cross-environment compatibility)
warn_unused_ignores = false
exclude = [
    "experiment_core_utils",
    "experiment_orchestration_utils",
    "configs",
]

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = ["test_*.py"]
python_functions = ["test_*"]
addopts = "-v --tb=short"

[tool.commitizen]
name = "cz_conventional_commits"
version = "2.0.0"
version_files = ["VERSION", "pyproject.toml:tool.poetry.version"]
tag_format = "v$version"
update_changelog_on_bump = true
changelog_file = "CHANGELOG.md"
major_version_zero = false
bump_pattern = "^(feat|fix|refactor|perf|revert)"
bump_map = { feat = "MINOR", fix = "PATCH", refactor = "PATCH", perf = "PATCH", revert = "PATCH" }
