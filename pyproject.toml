[tool.poetry]
name = "llm-energy-measure"
version = "2.0.0"
description = "LLM inference efficiency measurement framework"
authors = ["henrycgbaker <henry.c.g.baker@gmail.com>"]
readme = "README.md"
packages = [{include = "llm_energy_measure", from = "src"}]

[tool.poetry.dependencies]
python = "^3.10"
# Core dependencies (all backends)
torch = "^2.5.0"
pydantic = "^2.0"
loguru = "^0.7.0"
typer = "^0.15.0"
codecarbon = "^2.8.0"
pynvml = "^12.0.0"
datasets = "^3.0.0"
schedule = "^1.2.2"
python-dotenv = "^1.0.0"
tqdm = "^4.66.0"

# Optional: PyTorch/HuggingFace backend
transformers = {version = "^4.49.0", optional = true}
accelerate = {version = "^1.4.0", optional = true}
bitsandbytes = {version = "^0.45.0", optional = true}
calflops = {version = "^0.2.0", optional = true}
peft = {version = "^0.18.1", optional = true}

# Optional: vLLM backend
vllm = {version = ">=0.6.0", optional = true}

# Optional: TensorRT-LLM backend (high-performance compiled inference)
# Note: Requires NVIDIA GPU with compute capability >= 8.0 (Ampere+)
tensorrt-llm = {version = ">=0.12.0", optional = true}

# Optional: dev dependencies
pytest = {version = "^8.0", optional = true}
pytest-cov = {version = "^4.0", optional = true}
ruff = {version = "^0.8.0", optional = true}
mypy = {version = "^1.0", optional = true}
pre-commit = {version = "^3.0", optional = true}
types-pyyaml = {version = "^6.0.12.20250915", optional = true}
commitizen = {version = "^4.0", optional = true}

[tool.poetry.extras]
# PyTorch/HuggingFace backend (default for most use cases)
# Usage: pip install llm-energy-measure[pytorch]
pytorch = ["transformers", "accelerate", "bitsandbytes", "calflops", "peft"]

# vLLM backend (high-throughput inference)
# Usage: pip install llm-energy-measure[vllm]
# Note: Use dedicated Docker image due to dependency conflicts
vllm = ["vllm"]

# TensorRT-LLM backend (high-performance compiled inference)
# Usage: pip install llm-energy-measure[tensorrt]
# Note: Requires NVIDIA GPU (Ampere+) and CUDA 12.x
tensorrt = ["tensorrt-llm"]

# Development tools
# Usage: pip install llm-energy-measure[dev]
dev = ["pytest", "pytest-cov", "ruff", "mypy", "pre-commit", "types-pyyaml", "commitizen"]

# All backends + dev (for full development)
# Usage: pip install llm-energy-measure[all]
# Note: Backend-specific extras (vllm, tensorrt) may have dependency conflicts.
# For production, use individual backend extras: [pytorch], [vllm], or [tensorrt]
all = ["transformers", "accelerate", "bitsandbytes", "calflops", "peft", "vllm", "tensorrt-llm", "pytest", "pytest-cov", "ruff", "mypy", "pre-commit", "types-pyyaml", "commitizen"]

[tool.poetry.scripts]
llm-energy-measure = "llm_energy_measure.cli:app"

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"

[tool.ruff]
line-length = 100
target-version = "py310"

[tool.ruff.lint]
select = ["E", "F", "I", "UP", "B", "SIM", "RUF"]
ignore = ["E501"]  # Line length handled by formatter

[tool.ruff.format]
quote-style = "double"
indent-style = "space"

[tool.mypy]
python_version = "3.10"
strict = true
ignore_missing_imports = true
# Disable checks that fail on untyped third-party libs (torch, transformers)
disallow_untyped_calls = false
# Allow unused type: ignore comments (needed for cross-environment compatibility)
warn_unused_ignores = false
exclude = [
    "experiment_core_utils",
    "experiment_orchestration_utils",
    "configs",
]

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = ["test_*.py"]
python_functions = ["test_*"]
addopts = "-v --tb=short"

[tool.commitizen]
name = "cz_conventional_commits"
version = "2.0.0"
version_files = ["VERSION", "pyproject.toml:tool.poetry.version"]
tag_format = "v$version"
update_changelog_on_bump = true
changelog_file = "CHANGELOG.md"
major_version_zero = false
bump_pattern = "^(feat|fix|refactor|perf|revert)"
bump_map = { feat = "MINOR", fix = "PATCH", refactor = "PATCH", perf = "PATCH", revert = "PATCH" }
