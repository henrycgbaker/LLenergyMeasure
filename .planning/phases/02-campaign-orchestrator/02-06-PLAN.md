---
phase: 02-campaign-orchestrator
plan: 06
type: execute
wave: 3
depends_on: ["02-01", "02-02", "02-03", "02-04", "02-05"]
files_modified:
  - src/llenergymeasure/orchestration/campaign.py
  - src/llenergymeasure/cli/campaign.py
autonomous: true

must_haves:
  truths:
    - "Campaign CLI dispatches experiments via docker compose exec (not run --rm) when running from host"
    - "Campaign CLI supports grid-based campaign YAML (not just config list)"
    - "Campaign CLI supports --resume flag to resume from existing manifest"
    - "Campaign CLI shows validation summary before execution (valid/filtered/warned)"
    - "Campaign execution creates and updates manifest after each experiment"
    - "Campaign supports force_cold_start: container restart or model unload between experiments"
    - "Campaign retains existing features: randomisation, interleaved/shuffled/grouped, thermal gaps, cycles"
    - "Campaign performs health checks per cycle and restarts unhealthy containers"
    - "Failed experiments logged and campaign continues (log-and-continue pattern)"
    - "Campaign aggregates results with bootstrap CIs when cycles > 1"
    - "Campaign supports daemon mode with scheduled start times and interval-based cycle repetition"
  artifacts:
    - path: "src/llenergymeasure/orchestration/campaign.py"
      provides: "Extended CampaignRunner with manifest integration, container lifecycle, cold start"
      contains: "def run_campaign"
    - path: "src/llenergymeasure/cli/campaign.py"
      provides: "Updated campaign CLI with grid support, resume, exec dispatch, validation summary, daemon scheduling"
      contains: "docker.compose.execute\\|ContainerManager\\|ManifestManager"
  key_links:
    - from: "src/llenergymeasure/cli/campaign.py"
      to: "src/llenergymeasure/orchestration/container.py"
      via: "ContainerManager for Docker lifecycle"
      pattern: "ContainerManager"
    - from: "src/llenergymeasure/cli/campaign.py"
      to: "src/llenergymeasure/orchestration/manifest.py"
      via: "ManifestManager for state persistence"
      pattern: "ManifestManager"
    - from: "src/llenergymeasure/cli/campaign.py"
      to: "src/llenergymeasure/orchestration/grid.py"
      via: "expand_campaign_grid for grid-based campaigns"
      pattern: "expand_campaign_grid"
    - from: "src/llenergymeasure/orchestration/campaign.py"
      to: "src/llenergymeasure/results/aggregation.py"
      via: "aggregate_campaign_results for CI computation"
      pattern: "aggregate_campaign_results"
---

<objective>
Wire all Phase 2 modules into the existing CampaignRunner and campaign CLI, creating the integrated campaign orchestrator.

Purpose: This is the integration plan — CAMP-01 (exec dispatch), CAMP-04 (daemon mode), CAMP-05 (cold start), CAMP-07 (retain features). It connects ContainerManager, ManifestManager, grid expansion, bootstrap CIs, and daemon scheduling into the existing campaign workflow. This is the largest plan in Phase 2.
Output: Updated orchestration/campaign.py and cli/campaign.py with full orchestrator integration including daemon mode.
</objective>

<execution_context>
@/home/h.baker@hertie-school.lan/.claude/get-shit-done/workflows/execute-plan.md
@/home/h.baker@hertie-school.lan/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/02-CONTEXT.md
@.planning/phases/02-campaign-orchestrator/02-RESEARCH.md
@.planning/phases/02-campaign-orchestrator/02-01-SUMMARY.md
@.planning/phases/02-campaign-orchestrator/02-02-SUMMARY.md
@.planning/phases/02-campaign-orchestrator/02-03-SUMMARY.md
@.planning/phases/02-campaign-orchestrator/02-04-SUMMARY.md
@.planning/phases/02-campaign-orchestrator/02-05-SUMMARY.md
@src/llenergymeasure/orchestration/campaign.py
@src/llenergymeasure/cli/campaign.py
@src/llenergymeasure/orchestration/container.py
@src/llenergymeasure/orchestration/manifest.py
@src/llenergymeasure/orchestration/grid.py
@src/llenergymeasure/results/bootstrap.py
@src/llenergymeasure/config/campaign_config.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Extend CampaignRunner with manifest and container integration</name>
  <files>src/llenergymeasure/orchestration/campaign.py</files>
  <action>
Extend the existing CampaignRunner in orchestration/campaign.py. Keep ALL existing functionality intact. Add new methods and integrate with manifest + containers.

**New imports (at top, lazy where needed):**
- `from llenergymeasure.orchestration.manifest import ManifestManager, CampaignManifest, CampaignManifestEntry`
- `from llenergymeasure.orchestration.grid import expand_campaign_grid, validate_campaign_grid`

**Add to CampaignExperiment dataclass:**
- `manifest_entry: CampaignManifestEntry | None = None` — Link to manifest entry (for status tracking)

**Add new methods to CampaignRunner:**

1. `generate_execution_order_from_grid(self) -> list[CampaignExperiment]`:
   - If `self.campaign.grid` is not None, use `expand_campaign_grid()` + `validate_campaign_grid()` to generate configs
   - Convert valid config dicts into CampaignExperiment objects
   - Apply cycle expansion (multiply by `self.num_cycles`)
   - Apply ordering (interleaved/shuffled/grouped) — reuse existing logic
   - Falls back to existing `generate_execution_order()` if no grid

2. `create_manifest(self, execution_order: list[CampaignExperiment]) -> CampaignManifest`:
   - Creates CampaignManifestEntry for each experiment in execution_order
   - Generates config hashes from experiment config dicts
   - Returns CampaignManifest with all entries as "pending"

3. `apply_resume_filter(self, manifest: CampaignManifest, execution_order: list[CampaignExperiment]) -> list[CampaignExperiment]`:
   - Filters execution_order to only include experiments whose manifest entry status is "pending" or "failed"
   - Returns filtered list

4. `should_health_check(self, experiment_index: int) -> bool`:
   - Returns True if health check should run based on `campaign.health_check` config
   - Check after each cycle completion (always)
   - Check every N experiments if `health_check.interval_experiments > 0`

5. `should_cold_start(self) -> bool`:
   - Returns `self.campaign.cold_start.force_cold_start` if cold_start config exists, else False

**Important:**
- Do NOT break existing `generate_execution_order()` — the new grid method is a separate path
- Existing `record_experiment_start`, `record_experiment_complete`, gap methods stay unchanged
- Add new methods to support integration but don't refactor existing flow
  </action>
  <verify>
    python -c "
from llenergymeasure.orchestration.campaign import CampaignRunner, CampaignExperiment
# Verify new methods exist
runner = CampaignRunner.__new__(CampaignRunner)
assert hasattr(runner, 'generate_execution_order_from_grid')
assert hasattr(runner, 'create_manifest')
assert hasattr(runner, 'apply_resume_filter')
assert hasattr(runner, 'should_health_check')
assert hasattr(runner, 'should_cold_start')
# Verify CampaignExperiment has manifest_entry field
import dataclasses
fields = {f.name for f in dataclasses.fields(CampaignExperiment)}
assert 'manifest_entry' in fields
print('CampaignRunner extension verified')
"
  </verify>
  <done>CampaignRunner extended with grid-based execution order, manifest creation, resume filtering, health check scheduling, and cold start detection. All existing functionality preserved.</done>
</task>

<task type="auto">
  <name>Task 2: Add CLI options and grid support to campaign command</name>
  <files>src/llenergymeasure/cli/campaign.py</files>
  <action>
Add new CLI options and grid-based campaign support. This is the first of 3 CLI integration tasks — it focuses on the entry point and grid expansion.

**New CLI options to add to `campaign_cmd`:**
- `--resume / --no-resume` (bool, default False) — Resume from existing manifest
- `--force-cold-start / --no-force-cold-start` (bool, default None) — Override cold start config
- `--validate-only` (bool, default False) — Like dry-run but specifically validates grid
- `--quiet / -q` (bool, default False) — Suppress interactive output (for daemon mode)

**Grid support in campaign YAML loading:**
After loading campaign config, check if `campaign.grid` is not None. If so:
- Call `expand_campaign_grid(campaign.grid, base_config=...)` to generate configs
- Call `validate_campaign_grid(config_dicts)` to validate
- Display validation summary via new `_display_validation_summary(result: GridExpansionResult)`: "Generated N experiments (M filtered, W warnings)"
- If `--validate-only`, display summary and exit
- Convert valid configs to temp YAML files in `campaign.io.configs_dir`

**Update `_load_campaign_yaml` to handle new fields:**
- Grid config, health_check, cold_start, daemon, io, experiments fields
- Already handled by Pydantic parsing (CampaignConfig(**data)) — just ensure no field stripping

**New display function:**
- `_display_validation_summary(result: GridExpansionResult)` — Shows grid validation results using Rich console

**Important:**
- Keep all existing display functions intact
- Imports: `from llenergymeasure.orchestration.grid import expand_campaign_grid, validate_campaign_grid`
  </action>
  <verify>
    python -c "
from llenergymeasure.cli.campaign import campaign_cmd
import inspect
sig = inspect.signature(campaign_cmd)
params = list(sig.parameters.keys())
assert 'resume' in params or any('resume' in p for p in params), f'Missing resume param, got: {params}'
assert 'validate_only' in params or any('validate' in p for p in params), f'Missing validate_only, got: {params}'
print(f'CLI params: {params}')
print('CLI options and grid support added')
"
  </verify>
  <done>Campaign CLI extended with --resume, --force-cold-start, --validate-only, --quiet options. Grid expansion and validation summary wired in.</done>
</task>

<task type="auto">
  <name>Task 3: Wire Docker exec dispatch and manifest tracking into CLI</name>
  <files>src/llenergymeasure/cli/campaign.py</files>
  <action>
Wire ContainerManager and ManifestManager into the campaign execution flow.

**Docker exec dispatch (replaces _build_docker_command):**
When `_should_use_docker()` returns True:
- Create `ContainerManager(compose_file="docker-compose.yml")` — lazy import inside function
- Determine backends needed: `{exp.backend for exp in execution_order}`
- Start containers: `container_mgr.start_services(list(backends_needed))`
- Teardown on completion or error (use context manager)

Keep the non-Docker path (direct subprocess) unchanged for running inside containers.

**Update `_run_single_experiment` to support both modes:**
- Add `container_mgr: ContainerManager | None = None` parameter
- If container_mgr provided: use `container_mgr.execute_experiment()` instead of subprocess
- If None: use existing subprocess path (backwards compatible)

**Manifest integration:**
- Create `ManifestManager(manifest_path=campaign.io.manifest_path)` — use CampaignIOConfig to resolve path
- On fresh start: create manifest from execution order via `runner.create_manifest()`, save it
- On `--resume`: load existing manifest, check config hash via `manifest_mgr.check_config_changed()`, filter to remaining experiments via `runner.apply_resume_filter()`
- After each experiment: update manifest entry (started_at, completed_at, status, result_path, error), call `manifest_mgr.save(manifest)`
- Show resume summary if resuming: "Resuming: N remaining (M completed, F failed)"

**Result loading for bootstrap CIs:**
- To load AggregatedResult from manifest result_path: check what exists in `results/repository.py` for a load function
- Group completed results by `manifest_entry.config_name` to build `dict[str, list[AggregatedResult]]`
- Skip failed experiments (no result_path) in aggregation

**Important:**
- ContainerManager import is lazy (inside function, with try/except ImportError pointing to `pip install llenergymeasure[campaign]`)
- ManifestManager import can be at module level (no optional deps)
  </action>
  <verify>
    python -c "
from llenergymeasure.cli.campaign import _run_single_experiment
import inspect
sig = inspect.signature(_run_single_experiment)
params = list(sig.parameters.keys())
assert 'container_mgr' in params, f'Missing container_mgr param, got: {params}'
print('Docker exec dispatch and manifest integration wired')
"
  </verify>
  <done>Campaign CLI dispatches via ContainerManager.execute_experiment() (replacing docker compose run --rm). ManifestManager tracks experiment status with atomic persistence. Resume support loads existing manifest and skips completed experiments.</done>
</task>

<task type="auto">
  <name>Task 4: Add health checks, cold start, daemon scheduling, and CI display</name>
  <files>src/llenergymeasure/cli/campaign.py</files>
  <action>
Add remaining lifecycle features to the campaign execution flow.

**Health checks between cycles:**
- After each cycle completes (existing `is_cycle_complete` check or equivalent), run health check on all active services via `container_mgr.check_and_recover(service, gpu_memory_threshold_pct, max_restarts)` where values come from `campaign.health_check` config
- If unhealthy after recovery: log warning, continue campaign (log-and-continue pattern)
- Log health check results at debug level

**Cold start handling:**
- If `campaign.cold_start.force_cold_start` or `--force-cold-start` CLI override:
  - After each experiment, if `cold_start.restart_container`: call `container_mgr.restart_service(backend)`
  - Otherwise: exec a cleanup command: `container_mgr.execute_experiment(backend, cleanup_cmd)` where cleanup_cmd is `["python", "-c", "import torch; torch.cuda.empty_cache(); import gc; gc.collect()"]`
- Default (no cold start): model stays loaded, rely on health checks

**Daemon scheduling (CAMP-04):**
- If `campaign.daemon` is not None and `campaign.daemon.enabled`:
  - If `daemon.at` is set: compute delay from now to target time, sleep until start. Log: "Daemon: waiting until {at} to start campaign"
  - Implement as wrapper around existing campaign loop:
    ```
    if daemon_enabled:
        wait_until(daemon.at)
        start_time = now()
        while not exceeded_duration(start_time, daemon.total_duration_seconds):
            run_campaign_cycles(...)  # existing campaign loop
            if daemon.interval_seconds:
                sleep(daemon.interval_seconds)
    else:
        run_campaign_cycles(...)  # existing single-run path
    ```
  - Track total elapsed time; if exceeds `daemon.total_duration_seconds`, stop gracefully: "Daemon: total duration {total_duration} reached, stopping after {completed_cycles} cycles"
  - Auto-enable `quiet=True` in daemon mode: suppress Rich progress, use loguru file logging
- Daemon runs in foreground process — users use `nohup`/`screen` for background

**Campaign completion with CIs:**
- After all experiments, if cycles > 1:
  - Load results from manifest (using result loading from Task 3)
  - Call `aggregate_campaign_results(results_by_config)` for bootstrap CIs
  - Display via `_display_ci_summary(aggregated: dict)` — Rich table: config name, n_cycles, metric means with [CI_lower, CI_upper] for energy, throughput, latency
- If cycles == 1: display warning: "Single cycle: use --cycles 3+ for confidence intervals"

**New display function:**
- `_display_ci_summary(aggregated: dict)` — Rich table showing bootstrap CI results
  </action>
  <verify>
    python -c "
from llenergymeasure.cli.campaign import campaign_cmd
from llenergymeasure.config.campaign_config import CampaignDaemonConfig
d = CampaignDaemonConfig(enabled=True, interval='6h')
print(f'Daemon config: enabled={d.enabled}, interval={d.interval}')
print('Health checks, cold start, daemon, and CI display integrated')
"
  </verify>
  <done>Campaign lifecycle complete: health checks per-cycle with auto-recovery, cold start (cache clear or container restart), daemon scheduling (timed start, inter-cycle interval, total-duration enforcement), bootstrap CI display for multi-cycle campaigns.</done>
</task>

</tasks>

<verification>
- `python -c "from llenergymeasure.cli.campaign import campaign_cmd"` succeeds
- Existing tests pass: `pytest tests/ -x -q -k campaign` (if any exist)
- CLI help shows new options: `python -m llenergymeasure --help` or check signature
- Campaign YAML with `grid:` section parses and expands correctly
- Non-Docker path (inside container) still works via subprocess
- Daemon config with `at` and `interval` fields accepted by CLI
</verification>

<success_criteria>
- Docker exec dispatch replaces docker compose run --rm for host-side orchestration
- Grid-based campaigns expand, validate, and execute
- Manifest created on start, updated after each experiment, supports resume
- Health checks run per-cycle, trigger container restart if unhealthy
- Cold start supported (cache clear or container restart)
- Daemon mode waits for scheduled start time, repeats at interval, respects total duration limit
- Bootstrap CIs displayed for multi-cycle campaigns
- All existing campaign features retained (ordering, gaps, warmup, cycles)
- Backwards compatible with existing config-list campaigns
</success_criteria>

<output>
After completion, create `.planning/phases/02-campaign-orchestrator/02-06-SUMMARY.md`
</output>
