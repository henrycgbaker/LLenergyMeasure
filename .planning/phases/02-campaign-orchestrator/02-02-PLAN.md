---
phase: 02-campaign-orchestrator
plan: 02
type: execute
wave: 1
depends_on: ["02-01"]
files_modified:
  - src/llenergymeasure/orchestration/container.py
autonomous: true

must_haves:
  truths:
    - "ContainerManager starts only needed backend containers via docker compose up"
    - "ContainerManager dispatches experiments via docker compose exec (not run --rm)"
    - "ContainerManager performs GPU health checks via NVML inside containers"
    - "ContainerManager restarts unhealthy containers and retries failed experiments"
    - "ContainerManager tears down containers gracefully on campaign completion"
    - "ContainerManager works with python-on-whales DockerClient"
  artifacts:
    - path: "src/llenergymeasure/orchestration/container.py"
      provides: "ContainerManager class with start/exec/health_check/restart/teardown lifecycle"
      exports: ["ContainerManager", "ContainerHealthStatus"]
      min_lines: 150
  key_links:
    - from: "src/llenergymeasure/orchestration/container.py"
      to: "python_on_whales.DockerClient"
      via: "import and use for container lifecycle"
      pattern: "from python_on_whales import DockerClient"
---

<objective>
Create the ContainerManager module that handles Docker container lifecycle using python-on-whales.

Purpose: This module replaces the `docker compose run --rm` subprocess pattern in cli/campaign.py with long-running containers managed via python-on-whales. It handles startup, exec dispatch, health checks, restart, and teardown — the core CAMP-01 and CAMP-06 requirements.
Output: New orchestration/container.py with ContainerManager class.
</objective>

<execution_context>
@/home/h.baker@hertie-school.lan/.claude/get-shit-done/workflows/execute-plan.md
@/home/h.baker@hertie-school.lan/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/02-CONTEXT.md
@.planning/phases/02-campaign-orchestrator/02-RESEARCH.md
@src/llenergymeasure/orchestration/campaign.py
@src/llenergymeasure/cli/campaign.py
@docker-compose.yml
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create ContainerManager with full lifecycle</name>
  <files>src/llenergymeasure/orchestration/container.py</files>
  <action>
Create a new module `src/llenergymeasure/orchestration/container.py` with the ContainerManager class.

**ContainerHealthStatus dataclass:**
- `service: str`
- `healthy: bool`
- `reason: str`
- `gpu_memory_used_gb: float | None = None`
- `gpu_memory_total_gb: float | None = None`

**ContainerManager class:**
```python
class ContainerManager:
    """Manages long-running Docker backend containers for campaign execution.

    Replaces docker compose run --rm with up/exec/down lifecycle:
    - Start: docker compose up (detached, wait for health)
    - Dispatch: docker compose exec (run experiment in running container)
    - Health: Check GPU memory via NVML exec inside container
    - Restart: Restart unhealthy containers
    - Teardown: docker compose down
    """
```

**Constructor:**
- `compose_file: str | Path = "docker-compose.yml"` — Path to compose file
- `project_dir: str | Path | None = None` — Project directory (default: cwd)
- Creates `DockerClient(compose_files=[str(compose_file)])`
- `_active_services: set[str]` — Tracks which services are running
- `_restart_counts: dict[str, int]` — Tracks restart count per service

**Methods:**

1. `start_services(backends: list[str], wait: bool = True) -> None`
   - Calls `docker.compose.up(services=backends, detach=True, wait=wait)`
   - Updates `_active_services`
   - Logs which services started
   - Raises `RuntimeError` if startup fails

2. `execute_experiment(service: str, config_path: str, extra_args: list[str] | None = None, env_vars: dict[str, str] | None = None) -> tuple[str, int]`
   - Builds command: `["lem", "experiment", config_path, "--yes"] + (extra_args or [])`
   - Calls `docker.compose.execute(service=service, command=cmd, tty=False, envs=env_vars or {})`
   - Returns `(stdout_output, return_code)`
   - Catches exceptions from python-on-whales and returns `("error message", 1)` on failure
   - Important: python-on-whales `execute()` returns a string (stdout). For return code, wrap in try/except — if the command fails, `execute()` raises `DockerException`.

3. `check_health(service: str, gpu_memory_threshold_pct: float = 90.0) -> ContainerHealthStatus`
   - Executes NVML memory query inside container via exec:
     `["python", "-c", "import pynvml; pynvml.nvmlInit(); h=pynvml.nvmlDeviceGetHandleByIndex(0); m=pynvml.nvmlDeviceGetMemoryInfo(h); print(f'{m.used},{m.total}')"]`
   - Parses output, computes usage percentage
   - Returns ContainerHealthStatus with healthy=True/False based on threshold
   - On exec failure, returns unhealthy with error reason

4. `restart_service(service: str) -> bool`
   - Calls `docker.compose.restart([service])`
   - Increments `_restart_counts[service]`
   - Waits 10s for recovery
   - Checks health after restart
   - Returns True if healthy after restart, False if still unhealthy

5. `check_and_recover(service: str, gpu_memory_threshold_pct: float = 90.0, max_restarts: int = 3) -> ContainerHealthStatus`
   - Calls `check_health()`
   - If unhealthy and `_restart_counts[service] < max_restarts`: calls `restart_service()`
   - Returns final health status

6. `teardown(timeout: int = 30) -> None`
   - Calls `docker.compose.down(timeout=timeout)`
   - Clears `_active_services`

7. `is_service_running(service: str) -> bool`
   - Returns `service in _active_services`

8. `__enter__` / `__exit__` — Context manager that calls `teardown()` on exit

**Important implementation details:**
- Import python-on-whales lazily (inside methods or `__init__`) because it's an optional dependency. Use try/except ImportError with a helpful message: "pip install llenergymeasure[campaign]"
- Use `from __future__ import annotations` at top
- Use loguru logger for debug/info logging (existing pattern)
- `execute()` in python-on-whales returns stdout as string on success, raises `python_on_whales.exceptions.DockerException` on failure. Handle accordingly.
- All public methods should have Google-style docstrings
- Add module to `__all__`
  </action>
  <verify>
    python -c "
from llenergymeasure.orchestration.container import ContainerManager, ContainerHealthStatus
# Verify class exists and has expected methods
cm = ContainerManager.__new__(ContainerManager)
assert hasattr(cm, 'start_services')
assert hasattr(cm, 'execute_experiment')
assert hasattr(cm, 'check_health')
assert hasattr(cm, 'restart_service')
assert hasattr(cm, 'check_and_recover')
assert hasattr(cm, 'teardown')
# Verify ContainerHealthStatus
hs = ContainerHealthStatus(service='pytorch', healthy=True, reason='OK')
assert hs.service == 'pytorch'
assert hs.healthy is True
print('ContainerManager structure verified')
"
  </verify>
  <done>ContainerManager class with full lifecycle (start/exec/health/restart/teardown) created. Uses python-on-whales with lazy import. Context manager support for safe teardown.</done>
</task>

<task type="auto">
  <name>Task 2: Update orchestration __init__ exports</name>
  <files>src/llenergymeasure/orchestration/__init__.py</files>
  <action>
If `src/llenergymeasure/orchestration/__init__.py` exists, add ContainerManager and ContainerHealthStatus to its exports. If it doesn't have explicit exports, just ensure the module is importable.

Check the existing file first. If it has `__all__`, add the new exports. If it's empty or minimal, leave it as-is — the module is already importable via full path.
  </action>
  <verify>
    python -c "from llenergymeasure.orchestration.container import ContainerManager; print('Import OK')"
  </verify>
  <done>ContainerManager importable from orchestration package.</done>
</task>

</tasks>

<verification>
- `python -c "from llenergymeasure.orchestration.container import ContainerManager"` succeeds
- `ruff check src/llenergymeasure/orchestration/container.py` passes
- ContainerManager has all 7 lifecycle methods + context manager
</verification>

<success_criteria>
- ContainerManager replaces docker compose run --rm pattern with up/exec/down lifecycle
- Health check queries GPU memory via NVML inside container
- Auto-restart with configurable max restarts
- Context manager ensures teardown on failure
- python-on-whales imported lazily with helpful error message
</success_criteria>

<output>
After completion, create `.planning/phases/02-campaign-orchestrator/02-02-SUMMARY.md`
</output>
