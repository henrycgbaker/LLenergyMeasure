---
phase: 03-parameter-completeness
plan: 03
type: execute
wave: 1
depends_on: []
files_modified:
  - src/llenergymeasure/config/backend_configs.py
autonomous: true

must_haves:
  truths:
    - "TensorRT backend exposes 95%+ of energy-impactful build/runtime parameters"
    - "New TensorRT parameters have docstring-documented constraints"
    - "Introspection auto-discovers all new TensorRT parameters"
  artifacts:
    - path: "src/llenergymeasure/config/backend_configs.py"
      provides: "Extended TensorRTConfig with new build/runtime parameters"
      contains: "gemm_plugin"
  key_links:
    - from: "src/llenergymeasure/config/backend_configs.py"
      to: "introspection.py"
      via: "get_backend_params('tensorrt')"
      pattern: "get_backend_params"
---

<objective>
Add missing energy/throughput-impactful parameters to TensorRTConfig Pydantic model.

Purpose: Expand TensorRT parameter coverage from 93.8% to 95%+ by adding build and runtime parameters from TensorRT-LLM that affect energy/throughput.
Output: Extended TensorRTConfig with new fields that introspection auto-discovers.
</objective>

<execution_context>
@/home/h.baker@hertie-school.lan/.claude/get-shit-done/workflows/execute-plan.md
@/home/h.baker@hertie-school.lan/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/03-parameter-completeness/03-CONTEXT.md
@.planning/phases/03-parameter-completeness/03-RESEARCH.md
@src/llenergymeasure/config/backend_configs.py
@src/llenergymeasure/config/introspection.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add missing TensorRT build parameters</name>
  <files>src/llenergymeasure/config/backend_configs.py</files>
  <action>
Add the following missing parameters to TensorRTConfig. Group by functional category:

**Build Configuration (after multiple_profiles):**
1. `gemm_plugin: Literal["auto", "float16", "bfloat16"] | None = Field(default=None, description="GEMM plugin precision. None = auto. Affects matrix multiply performance.")`
2. `gpt_attention_plugin: Literal["auto", "float16", "bfloat16"] | None = Field(default=None, description="GPT attention plugin precision. None = auto. Critical for performance.")`
3. `use_paged_context_fmha: bool = Field(default=True, description="Use paged attention for context phase. Improves memory efficiency.")`
4. `use_fp8_context_fmha: bool = Field(default=False, description="Use FP8 for context attention. Requires Hopper GPU (H100).")`
5. `weight_sparsity: bool = Field(default=False, description="Enable weight sparsity optimisation. Requires sparse-compatible model.")`
6. `weight_streaming: bool = Field(default=False, description="Enable CPU-offload weight streaming. Trades compute for memory.")`
7. `strip_plan: bool = Field(default=False, description="Strip weights from compiled engine. Reduces artifact size.")`
8. `use_custom_all_reduce: bool = Field(default=True, description="Use custom NCCL AllReduce kernels for multi-GPU.")`

**Speculative Decoding (after num_draft_tokens):**
9. `max_draft_len: int = Field(default=5, ge=1, le=20, description="Maximum draft sequence length for speculative decoding.")`

**Runtime (after max_num_tokens):**
10. `batching_type: Literal["static", "inflight"] = Field(default="inflight", description="Batching strategy. 'inflight' for continuous batching, 'static' for fixed batch.")`

Document GPU requirements in docstrings (e.g., FP8 features require Hopper, sparsity requires compatible model).
  </action>
  <verify>
Run `python -c "from llenergymeasure.config.backend_configs import TensorRTConfig; print(len(TensorRTConfig.model_fields))"` - should show increased field count.
Run `python -c "from llenergymeasure.config.introspection import get_backend_params; print('gemm_plugin' in str(get_backend_params('tensorrt')))"` - should print True.
  </verify>
  <done>
TensorRTConfig has 10 new build/runtime parameters. Introspection auto-discovers them. No import errors.
  </done>
</task>

<task type="auto">
  <name>Task 2: Verify escape hatches and update documentation</name>
  <files>src/llenergymeasure/config/backend_configs.py</files>
  <action>
TensorRT already has TWO escape hatches (extra_build_args, extra_runtime_args). Update their descriptions to be more explicit:

```python
extra_build_args: dict[str, Any] = Field(
    default_factory=dict,
    description="Escape hatch: kwargs passed directly to trtllm-build without validation. "
    "Use for undocumented build-time parameters. "
    "Example: extra_build_args: {max_tokens_in_paged_kv_cache: 8192}"
)

extra_runtime_args: dict[str, Any] = Field(
    default_factory=dict,
    description="Escape hatch: kwargs passed directly to TRT-LLM executor without validation. "
    "Use for undocumented runtime parameters. "
    "Example: extra_runtime_args: {medusa_choices: [[0], [1]]}"
)
```

This dual escape hatch is appropriate because TensorRT has distinct build-time vs runtime concerns.
  </action>
  <verify>
Run `python -c "from llenergymeasure.config.backend_configs import TensorRTConfig; print('extra_build_args' in TensorRTConfig.model_fields and 'extra_runtime_args' in TensorRTConfig.model_fields)"` - should print True.
  </verify>
  <done>
TensorRTConfig escape hatches exist with clear passthrough documentation for both build and runtime.
  </done>
</task>

</tasks>

<verification>
- [ ] `python -c "from llenergymeasure.config.backend_configs import TensorRTConfig"` succeeds
- [ ] `ruff check src/llenergymeasure/config/backend_configs.py` passes
- [ ] `python -c "from llenergymeasure.config.introspection import get_backend_params; p=get_backend_params('tensorrt'); print(len(p))"` shows increased param count
- [ ] New params have test_values auto-generated by introspection
</verification>

<success_criteria>
TensorRTConfig expanded with 10 new build/runtime parameters. All parameters have docstrings with GPU requirements documented. Introspection auto-discovers all new fields. Dual escape hatches documented.
</success_criteria>

<output>
After completion, create `.planning/phases/03-parameter-completeness/03-03-SUMMARY.md`
</output>
