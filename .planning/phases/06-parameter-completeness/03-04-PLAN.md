---
phase: 03-parameter-completeness
plan: 04
type: execute
wave: 2
depends_on: ["03-01", "03-02", "03-03"]
files_modified:
  - src/llenergymeasure/config/introspection.py
  - tests/runtime/test_all_params.py
  - docs/generated/config-reference.md
  - docs/generated/parameter-support-matrix.md
  - docs/generated/invalid-combos.md
autonomous: true

must_haves:
  truths:
    - "Introspection functions discover all new parameters from Plans 01-03"
    - "Skip conditions include GPU requirements for new parameters"
    - "Documentation is regenerated with all new parameters"
  artifacts:
    - path: "src/llenergymeasure/config/introspection.py"
      provides: "Updated skip conditions and special test models"
      contains: "use_fp8_context_fmha"
    - path: "docs/generated/config-reference.md"
      provides: "Regenerated config reference with all new parameters"
      contains: "guidance_scale"
  key_links:
    - from: "introspection.py"
      to: "backend_configs.py"
      via: "get_backend_params() introspects Pydantic models"
      pattern: "get_backend_params"
---

<objective>
Update SSOT introspection module with skip conditions for new parameters and regenerate documentation.

Purpose: Ensure new parameters from Plans 01-03 are properly integrated into the SSOT system with correct test constraints and documentation.
Output: Updated introspection.py with skip conditions, regenerated docs via pre-commit hooks.
</objective>

<execution_context>
@/home/h.baker@hertie-school.lan/.claude/get-shit-done/workflows/execute-plan.md
@/home/h.baker@hertie-school.lan/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/03-parameter-completeness/03-CONTEXT.md
@src/llenergymeasure/config/introspection.py
@src/llenergymeasure/config/backend_configs.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Update introspection skip conditions</name>
  <files>src/llenergymeasure/config/introspection.py</files>
  <action>
Update `get_param_skip_conditions()` to include skip conditions for new parameters that have hardware or dependency requirements:

Add to the return dict:
```python
# New PyTorch parameters
"pytorch.guidance_scale>1.0": "Classifier-free guidance requires compatible model architecture",

# New vLLM parameters
"vllm.tokenizer_mode=mistral": "Requires Mistral model family",
"vllm.trust_remote_code=True": "Security risk - only enable for trusted models",
"vllm.num_scheduler_steps>1": "Multi-step scheduling (vLLM >= 0.5.0)",

# New TensorRT parameters
"tensorrt.use_fp8_context_fmha=True": "Requires Hopper GPU (H100)",
"tensorrt.weight_sparsity=True": "Requires sparse-compatible model weights",
"tensorrt.weight_streaming=True": "Trades GPU compute for memory - may reduce throughput",
```

Also update `get_params_requiring_gpu_capability()` to include:
```python
ampere_required = [
    # ... existing ...
    "tensorrt.use_fp8_context_fmha=True",  # Add this
]
```

Update `get_special_test_models()` if any new parameters require specific models.
  </action>
  <verify>
Run `python -c "from llenergymeasure.config.introspection import get_param_skip_conditions; print('use_fp8_context_fmha' in str(get_param_skip_conditions()))"` - should print True.
  </verify>
  <done>
Skip conditions updated with all new parameter constraints. GPU capability requirements documented.
  </done>
</task>

<task type="auto">
  <name>Task 2: Update test_all_params manual fallback definitions</name>
  <files>tests/runtime/test_all_params.py</files>
  <action>
Update the manual parameter definitions (PYTORCH_PARAMS, VLLM_PARAMS, TENSORRT_PARAMS) to include new parameters as fallback when introspection isn't available.

Add to PYTORCH_PARAMS:
```python
"pytorch.guidance_scale": [None, 1.5, 2.0],
"pytorch.low_memory": [False, True],
"pytorch.diversity_penalty": [0.0, 0.5],
"pytorch.typical_p": [1.0, 0.9],
"pytorch.epsilon_cutoff": [0.0, 0.01],
"pytorch.eta_cutoff": [0.0, 0.01],
```

Add to VLLM_PARAMS:
```python
"vllm.dtype": ["auto", "half", "bfloat16"],
"vllm.tokenizer_mode": ["auto", "slow"],
"vllm.trust_remote_code": [False],  # Don't test True by default
"vllm.num_scheduler_steps": [1, 4],
```

Add to TENSORRT_PARAMS:
```python
"tensorrt.gemm_plugin": [None, "float16"],
"tensorrt.gpt_attention_plugin": [None, "float16"],
"tensorrt.use_paged_context_fmha": [True, False],
"tensorrt.batching_type": ["inflight", "static"],
```

Also add to SKIP_CONDITIONS dict for new parameters with known issues.
  </action>
  <verify>
Run `python -c "import sys; sys.path.insert(0, 'tests/runtime'); from test_all_params import PYTORCH_PARAMS; print('guidance_scale' in str(PYTORCH_PARAMS))"` - should print True.
  </verify>
  <done>
Manual parameter definitions updated as fallback. Skip conditions added for new parameters.
  </done>
</task>

<task type="auto">
  <name>Task 3: Regenerate documentation via pre-commit hooks</name>
  <files>docs/generated/config-reference.md, docs/generated/parameter-support-matrix.md, docs/generated/invalid-combos.md</files>
  <action>
Run the documentation generation scripts manually to regenerate all docs with new parameters:

```bash
python scripts/generate_config_docs.py
python scripts/generate_param_matrix.py
python scripts/generate_invalid_combos_doc.py
```

Verify that:
1. config-reference.md includes all new parameters from Plans 01-03
2. parameter-support-matrix.md shows the new parameters (even if not yet tested)
3. invalid-combos.md reflects any new validation rules

The pre-commit hooks will auto-regenerate on future commits, but we need an initial generation now.
  </action>
  <verify>
Check docs/generated/config-reference.md contains "guidance_scale" and "tokenizer_mode" and "gemm_plugin".
  </verify>
  <done>
All documentation regenerated with new parameters. Pre-commit hooks will maintain going forward.
  </done>
</task>

</tasks>

<verification>
- [ ] `python -c "from llenergymeasure.config.introspection import get_param_skip_conditions"` succeeds
- [ ] `ruff check src/llenergymeasure/config/introspection.py` passes
- [ ] `ruff check tests/runtime/test_all_params.py` passes
- [ ] docs/generated/config-reference.md exists and contains new parameters
- [ ] `python scripts/generate_config_docs.py` runs without errors
</verification>

<success_criteria>
Introspection skip conditions updated for all new parameters with hardware/dependency requirements. Manual test parameter definitions updated as fallback. Documentation regenerated showing all new parameters.
</success_criteria>

<output>
After completion, create `.planning/phases/03-parameter-completeness/03-04-SUMMARY.md`
</output>
