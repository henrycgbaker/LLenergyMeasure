---
phase: 03-parameter-completeness
plan: 06
type: execute
wave: 4
depends_on: ["03-05"]
files_modified:
  - tests/unit/test_config_backend_params.py
autonomous: false

must_haves:
  truths:
    - "Unit tests verify all new parameters are discoverable via introspection"
    - "Parameter audit campaign validates runtime coverage targets"
    - "User confirms parameter coverage meets 90%+ targets"
  artifacts:
    - path: "tests/unit/test_config_backend_params.py"
      provides: "Unit tests for new backend parameters"
      contains: "test_pytorch_new_params"
  key_links:
    - from: "tests/unit/test_config_backend_params.py"
      to: "src/llenergymeasure/config/introspection.py"
      via: "get_backend_params()"
      pattern: "get_backend_params"
---

<objective>
Create unit tests for new parameters and run parameter audit campaign for UAT verification.

Purpose: Verify all new parameters are correctly integrated and meet the 90%+ coverage targets.
Output: Unit tests passing, parameter coverage validated via campaign.
</objective>

<execution_context>
@/home/h.baker@hertie-school.lan/.claude/get-shit-done/workflows/execute-plan.md
@/home/h.baker@hertie-school.lan/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/03-parameter-completeness/03-CONTEXT.md
@src/llenergymeasure/config/introspection.py
@src/llenergymeasure/config/backend_configs.py
@tests/unit/test_config_models.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create unit tests for new parameters</name>
  <files>tests/unit/test_config_backend_params.py</files>
  <action>
Create a new test file to verify all Phase 3 parameter additions:

```python
"""Unit tests for Phase 3 parameter completeness.

Tests verify that:
1. All new parameters are discoverable via SSOT introspection
2. Parameter defaults are valid Pydantic values
3. Escape hatches exist for all backends
4. Coverage targets are met (PyTorch 95%+, vLLM 90%+, TensorRT 95%+)
"""

import pytest

from llenergymeasure.config.backend_configs import (
    PyTorchConfig,
    TensorRTConfig,
    VLLMConfig,
)
from llenergymeasure.config.introspection import (
    get_backend_params,
    get_param_skip_conditions,
)


class TestPyTorchNewParams:
    """Test PyTorch parameter additions from Plan 03-01."""

    def test_guidance_scale_exists(self):
        """Verify guidance_scale parameter added."""
        assert "guidance_scale" in PyTorchConfig.model_fields

    def test_low_memory_exists(self):
        """Verify low_memory parameter added."""
        assert "low_memory" in PyTorchConfig.model_fields

    def test_diversity_penalty_exists(self):
        """Verify diversity_penalty parameter added."""
        assert "diversity_penalty" in PyTorchConfig.model_fields

    def test_typical_p_exists(self):
        """Verify typical_p parameter added."""
        assert "typical_p" in PyTorchConfig.model_fields

    def test_epsilon_cutoff_exists(self):
        """Verify epsilon_cutoff parameter added."""
        assert "epsilon_cutoff" in PyTorchConfig.model_fields

    def test_eta_cutoff_exists(self):
        """Verify eta_cutoff parameter added."""
        assert "eta_cutoff" in PyTorchConfig.model_fields

    def test_extra_escape_hatch_exists(self):
        """Verify extra escape hatch exists."""
        assert "extra" in PyTorchConfig.model_fields

    def test_introspection_discovers_new_params(self):
        """Verify introspection discovers new parameters."""
        params = get_backend_params("pytorch")
        assert "pytorch.guidance_scale" in params or "guidance_scale" in str(params)


class TestVLLMNewParams:
    """Test vLLM parameter additions from Plan 03-02."""

    def test_dtype_exists(self):
        """Verify dtype parameter added."""
        assert "dtype" in VLLMConfig.model_fields

    def test_tokenizer_mode_exists(self):
        """Verify tokenizer_mode parameter added."""
        assert "tokenizer_mode" in VLLMConfig.model_fields

    def test_trust_remote_code_exists(self):
        """Verify trust_remote_code parameter added."""
        assert "trust_remote_code" in VLLMConfig.model_fields

    def test_num_scheduler_steps_exists(self):
        """Verify num_scheduler_steps parameter added."""
        assert "num_scheduler_steps" in VLLMConfig.model_fields

    def test_extra_escape_hatch_exists(self):
        """Verify extra escape hatch exists."""
        assert "extra" in VLLMConfig.model_fields

    def test_introspection_discovers_new_params(self):
        """Verify introspection discovers new parameters."""
        params = get_backend_params("vllm")
        assert "vllm.tokenizer_mode" in params or "tokenizer_mode" in str(params)


class TestTensorRTNewParams:
    """Test TensorRT parameter additions from Plan 03-03."""

    def test_gemm_plugin_exists(self):
        """Verify gemm_plugin parameter added."""
        assert "gemm_plugin" in TensorRTConfig.model_fields

    def test_gpt_attention_plugin_exists(self):
        """Verify gpt_attention_plugin parameter added."""
        assert "gpt_attention_plugin" in TensorRTConfig.model_fields

    def test_use_paged_context_fmha_exists(self):
        """Verify use_paged_context_fmha parameter added."""
        assert "use_paged_context_fmha" in TensorRTConfig.model_fields

    def test_batching_type_exists(self):
        """Verify batching_type parameter added."""
        assert "batching_type" in TensorRTConfig.model_fields

    def test_dual_escape_hatches_exist(self):
        """Verify both escape hatches exist."""
        assert "extra_build_args" in TensorRTConfig.model_fields
        assert "extra_runtime_args" in TensorRTConfig.model_fields

    def test_introspection_discovers_new_params(self):
        """Verify introspection discovers new parameters."""
        params = get_backend_params("tensorrt")
        assert "tensorrt.gemm_plugin" in params or "gemm_plugin" in str(params)


class TestParameterCoverage:
    """Test overall parameter coverage targets."""

    def test_pytorch_param_count(self):
        """Verify PyTorch has sufficient parameters for 95%+ coverage."""
        params = get_backend_params("pytorch")
        # Should have at least 25 parameters (was ~20, added 8)
        assert len(params) >= 25, f"PyTorch has {len(params)} params, expected >= 25"

    def test_vllm_param_count(self):
        """Verify vLLM has sufficient parameters for 90%+ coverage."""
        params = get_backend_params("vllm")
        # Should have at least 30 parameters (was ~25, added 9)
        assert len(params) >= 30, f"vLLM has {len(params)} params, expected >= 30"

    def test_tensorrt_param_count(self):
        """Verify TensorRT has sufficient parameters for 95%+ coverage."""
        params = get_backend_params("tensorrt")
        # Should have at least 25 parameters (was ~18, added 10)
        assert len(params) >= 25, f"TensorRT has {len(params)} params, expected >= 25"


class TestSkipConditions:
    """Test skip conditions for new parameters."""

    def test_fp8_skip_condition_exists(self):
        """Verify FP8 skip conditions documented."""
        conditions = get_param_skip_conditions()
        # Should have FP8-related skip conditions
        fp8_conditions = [k for k in conditions.keys() if "fp8" in k.lower()]
        assert len(fp8_conditions) >= 1, "Expected FP8 skip conditions"


class TestEscapeHatchIntegration:
    """Test escape hatch passthrough works."""

    def test_pytorch_extra_accepts_dict(self):
        """Verify PyTorch extra field accepts arbitrary dict."""
        config = PyTorchConfig(extra={"custom_param": 42, "another": "value"})
        assert config.extra["custom_param"] == 42

    def test_vllm_extra_accepts_dict(self):
        """Verify vLLM extra field accepts arbitrary dict."""
        config = VLLMConfig(extra={"seed": 42})
        assert config.extra["seed"] == 42

    def test_tensorrt_extra_build_accepts_dict(self):
        """Verify TensorRT extra_build_args accepts arbitrary dict."""
        config = TensorRTConfig(extra_build_args={"custom_flag": True})
        assert config.extra_build_args["custom_flag"] is True
```

Run the tests with `pytest tests/unit/test_config_backend_params.py -v`.
  </action>
  <verify>
Run `pytest tests/unit/test_config_backend_params.py -v` - all tests should pass.
  </verify>
  <done>
Unit tests created and passing for all new parameters and escape hatches.
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>
Parameter expansion for all three backends (PyTorch, vLLM, TensorRT) with:
- 8 new PyTorch generation parameters
- 9 new vLLM engine parameters
- 10 new TensorRT build/runtime parameters
- Escape hatches for all backends
- Updated introspection and documentation
- Comprehensive example configs
- Unit tests
  </what-built>
  <how-to-verify>
1. Check parameter counts meet targets:
   ```bash
   python -c "from llenergymeasure.config.introspection import get_backend_params; print('PyTorch:', len(get_backend_params('pytorch'))); print('vLLM:', len(get_backend_params('vllm'))); print('TensorRT:', len(get_backend_params('tensorrt')))"
   ```
   Expected: PyTorch >= 25, vLLM >= 30, TensorRT >= 25

2. Validate example configs:
   ```bash
   lem config validate configs/examples/pytorch_example.yaml
   lem config validate configs/examples/vllm_example.yaml
   lem config validate configs/examples/tensorrt_example.yaml
   ```

3. Run unit tests:
   ```bash
   pytest tests/unit/test_config_backend_params.py -v
   ```

4. Check documentation was regenerated:
   ```bash
   grep "guidance_scale" docs/generated/config-reference.md
   grep "tokenizer_mode" docs/generated/config-reference.md
   grep "gemm_plugin" docs/generated/config-reference.md
   ```

5. (Optional - requires GPU) Run parameter audit campaign to verify runtime coverage:
   ```bash
   python -m tests.runtime.test_all_params --backend pytorch --discover --quick
   ```
  </how-to-verify>
  <resume-signal>Type "approved" if parameter coverage targets met, or describe issues found.</resume-signal>
</task>

</tasks>

<verification>
- [ ] `pytest tests/unit/test_config_backend_params.py -v` all tests pass
- [ ] Parameter counts meet targets (PyTorch 25+, vLLM 30+, TensorRT 25+)
- [ ] Example configs validate successfully
- [ ] Documentation contains all new parameters
- [ ] User approves parameter coverage
</verification>

<success_criteria>
All unit tests pass. Parameter counts meet or exceed coverage targets. Example configs valid. User approves Phase 3 completion.
</success_criteria>

<output>
After completion, create `.planning/phases/03-parameter-completeness/03-06-SUMMARY.md`
</output>
