# Phase 2.3: Campaign State & Resume - Research

**Researched:** 2026-02-04
**Domain:** Interactive CLI interfaces, webhook notifications, state persistence
**Confidence:** HIGH

## Summary

Phase 2.3 builds interactive CLI commands (`lem resume`, `lem init`) and webhook notifications on top of existing state infrastructure. The standard stack centers on **questionary** for interactive prompts (arrow-key menus, confirmations), **httpx** for webhook POST requests, and **Rich** (already integrated) for table formatting. YAML generation uses PyYAML (already integrated).

The existing codebase provides strong foundations: ManifestManager for atomic state persistence, StateManager pattern for resilience, and Typer+Rich for CLI. The new commands extend these patterns rather than introducing new architectural approaches.

**Primary recommendation:** Use questionary for all interactive prompts (menu selection, confirmations), httpx.post() with explicit timeouts for webhook notifications, and extend existing display patterns from `cli/doctor.py` for environment detection in `lem init`.

## Standard Stack

The established libraries/tools for this domain:

### Core
| Library | Version | Purpose | Why Standard |
|---------|---------|---------|--------------|
| questionary | 2.1.1 | Interactive CLI prompts | Most actively maintained (Aug 2025 release), Python 3.9+, clean API for select/confirm/text |
| httpx | latest | HTTP client for webhooks | Modern requests alternative, built-in timeout defaults, better error handling |
| Rich | 14.1.0 | Terminal formatting (existing) | Already integrated, excellent table rendering |
| PyYAML | 6.0+ | YAML generation (existing) | Already integrated for config parsing |
| Typer | 0.15.0+ | CLI framework (existing) | Already integrated, typer.confirm() for simple y/n prompts |

### Supporting
| Library | Version | Purpose | When to Use |
|---------|---------|---------|-------------|
| pathlib | stdlib | File operations | Gitignore manipulation, config file creation |
| datetime | stdlib | Timestamp formatting | Manifest sorting, last activity display |

### Alternatives Considered
| Instead of | Could Use | Tradeoff |
|------------|-----------|----------|
| questionary | inquirer/InquirerPy | inquirer less actively maintained, InquirerPy more complex API |
| questionary | Typer built-ins | Typer only has basic prompt/confirm, no arrow-key menus |
| httpx | requests | requests has no default timeout (dangerous), no async support |

**Installation:**
```bash
# Already installed: typer, rich, pyyaml
pip install questionary httpx
```

## Architecture Patterns

### Recommended Project Structure
```
src/llenergymeasure/
├── cli/
│   ├── resume.py        # NEW: lem resume command
│   ├── init.py          # NEW: lem init wizard
│   └── doctor.py        # EXISTING: pattern to follow for env detection
├── notifications/
│   └── webhook.py       # NEW: webhook POST sender
└── config/
    └── user_config.py   # MODIFY: extend with notifications field
```

### Pattern 1: Interactive Menu Selection with questionary
**What:** Arrow-key navigable menu for campaign/experiment selection
**When to use:** Resume command when multiple interrupted items exist
**Example:**
```python
# Source: https://questionary.readthedocs.io/en/stable/pages/types.html
import questionary
from questionary import Choice

# Build choices from manifest data
choices = [
    Choice(
        title=f"Campaign: {campaign.campaign_name} ({campaign.completed_count}/{campaign.total_experiments})",
        value=campaign.campaign_id
    )
    for campaign in discovered_campaigns
]

selected_id = questionary.select(
    "Select campaign to resume:",
    choices=choices
).ask()

# Handle user abort (Ctrl+C)
if selected_id is None:
    raise typer.Abort()
```

### Pattern 2: Confirmation Prompts with typer.confirm()
**What:** Simple yes/no confirmation with automatic abort
**When to use:** Destructive actions (wipe state, retry failed experiments)
**Example:**
```python
# Source: https://typer.tiangolo.com/tutorial/prompt/
import typer

# Auto-abort if user says no
typer.confirm(
    f"Delete state for {campaign_name}?",
    abort=True  # Raises typer.Abort() on "no"
)

# Or handle manually
retry_failed = typer.confirm(f"Retry {failed_count} failed experiments?")
if retry_failed:
    # Include failed experiments in resume
    pass
```

### Pattern 3: Webhook POST with Timeout and Error Handling
**What:** Send JSON notification to webhook URL with retry on failure
**When to use:** Experiment completion/failure notifications
**Example:**
```python
# Source: https://www.python-httpx.org/advanced/timeouts/
# Source: https://betterstack.com/community/guides/scaling-python/httpx-explained/
import httpx
from loguru import logger

def send_webhook(webhook_url: str, payload: dict, timeout: float = 10.0) -> bool:
    """Send webhook notification with timeout and error handling.

    Returns True on success (2xx), False on failure.
    Does not retry (caller handles retry logic if needed).
    """
    try:
        response = httpx.post(
            webhook_url,
            json=payload,
            timeout=timeout,  # Default: 10 seconds
            follow_redirects=True  # HTTPX doesn't follow redirects by default
        )
        response.raise_for_status()  # Raise on 4xx/5xx
        logger.info(f"Webhook sent successfully: {webhook_url}")
        return True
    except httpx.TimeoutException:
        logger.warning(f"Webhook timeout after {timeout}s: {webhook_url}")
        return False
    except httpx.HTTPStatusError as e:
        logger.warning(f"Webhook failed with {e.response.status_code}: {webhook_url}")
        return False
    except httpx.RequestError as e:
        logger.warning(f"Webhook request error: {e}")
        return False
```

### Pattern 4: Environment Detection (from doctor.py)
**What:** Detect GPU, Docker, backends for init wizard context
**When to use:** `lem init` wizard to show user their environment first
**Example:**
```python
# Source: src/llenergymeasure/cli/doctor.py
import sys
import shutil
import subprocess
from pathlib import Path

def detect_environment() -> dict:
    """Detect environment info for init wizard."""
    env_info = {}

    # Python environment
    env_info['python_version'] = sys.version.split()[0]
    env_info['in_venv'] = (sys.prefix != sys.base_prefix)

    # CUDA/GPU
    try:
        import torch
        env_info['cuda_available'] = torch.cuda.is_available()
        if env_info['cuda_available']:
            env_info['gpu_count'] = torch.cuda.device_count()
    except ImportError:
        env_info['cuda_available'] = False

    # Docker
    env_info['docker_available'] = shutil.which("docker") is not None
    if env_info['docker_available']:
        try:
            result = subprocess.run(
                ["docker", "info"],
                capture_output=True,
                timeout=5,
                check=False
            )
            env_info['docker_running'] = (result.returncode == 0)
        except (subprocess.TimeoutExpired, FileNotFoundError):
            env_info['docker_running'] = False

    return env_info
```

### Pattern 5: Rich Table for Summary Display
**What:** Formatted table showing campaign status
**When to use:** `lem resume` to display campaign options
**Example:**
```python
# Source: https://rich.readthedocs.io/en/latest/console.html
from rich.table import Table
from llenergymeasure.cli.display import console

def display_campaign_summary(campaigns: list[CampaignManifest]) -> None:
    """Display campaigns as formatted table."""
    table = Table(title="Interrupted Campaigns")

    table.add_column("ID", style="cyan")
    table.add_column("Name", style="bold")
    table.add_column("Progress", justify="right")
    table.add_column("Status", justify="center")
    table.add_column("Last Activity", style="dim")

    for campaign in campaigns:
        progress_pct = f"{campaign.progress_fraction * 100:.0f}%"
        status = f"✓{campaign.completed_count} ✗{campaign.failed_count} ⧖{campaign.pending_count}"
        last_activity = campaign.updated_at.strftime("%Y-%m-%d %H:%M")

        table.add_row(
            campaign.campaign_id[:8],
            campaign.campaign_name,
            progress_pct,
            status,
            last_activity
        )

    console.print(table)
```

### Pattern 6: Configuration Wizard with Validation
**What:** Guided setup with per-question validation
**When to use:** `lem init` command
**Example:**
```python
# Source: https://questionary.readthedocs.io/en/stable/pages/advanced.html
import questionary
from pathlib import Path

def validate_webhook_url(url: str) -> bool | str:
    """Validator for webhook URL (returns True or error message)."""
    if not url:  # Empty is OK (optional field)
        return True
    if not url.startswith(("http://", "https://")):
        return "Webhook URL must start with http:// or https://"
    return True

# Use in wizard
webhook_url = questionary.text(
    "Webhook URL for notifications (optional):",
    default="",
    validate=validate_webhook_url
).ask()
```

### Anti-Patterns to Avoid
- **Rich "interactive" mode for menus:** Rich doesn't provide arrow-key selection, use questionary instead
- **requests library for webhooks:** No default timeout (can hang indefinitely), use httpx
- **Manual .gitignore parsing:** Use simple append with duplicate check, don't parse git patterns
- **Complex retry logic in webhook sender:** Keep sender simple, let caller decide retry policy

## Don't Hand-Roll

Problems that look simple but have existing solutions:

| Problem | Don't Build | Use Instead | Why |
|---------|-------------|-------------|-----|
| Interactive menu selection | Custom arrow-key listener with curses | questionary.select() | Handles terminal compatibility, cursor management, styling edge cases |
| HTTP retry with backoff | Custom loop with time.sleep | httpx with RetryTransport (optional) | Exponential backoff, jitter, connection pooling already solved |
| YAML generation | String templating | yaml.safe_dump() | Handles escaping, indentation, type serialization correctly |
| Webhook payload signing | Manual HMAC | Not needed for Phase 2.3 | User's webhook endpoint handles auth, we just POST |
| Gitignore pattern matching | Regex parsing | Simple append with duplicate check | Git patterns are complex (**, !, etc.), we only add lines |

**Key insight:** Interactive CLI prompts are deceptively complex (terminal state, cursor positioning, cross-platform compatibility). Use questionary instead of reinventing.

## Common Pitfalls

### Pitfall 1: HTTPX Doesn't Follow Redirects by Default
**What goes wrong:** Webhook POST gets 301/302, notification fails silently
**Why it happens:** HTTPX explicitly requires `follow_redirects=True` (unlike requests)
**How to avoid:** Always set `follow_redirects=True` on httpx.post() for webhooks
**Warning signs:** Webhook logs show success but endpoint never receives notification

### Pitfall 2: Typer prompt() vs questionary.select() Confusion
**What goes wrong:** Using typer.prompt() for menu selection (only supports text input)
**Why it happens:** Typer's API looks similar, but doesn't support arrow-key menus
**How to avoid:** Use typer.prompt() for text/password, typer.confirm() for yes/no, questionary.select() for menus
**Warning signs:** Users have to type option text instead of selecting with arrows

### Pitfall 3: Questionary Returns None on Ctrl+C
**What goes wrong:** User presses Ctrl+C, `.ask()` returns None, code crashes with AttributeError
**Why it happens:** questionary doesn't raise exception on interrupt, returns None
**How to avoid:** Always check `if result is None: raise typer.Abort()` after `.ask()`
**Warning signs:** TypeError: 'NoneType' object is not subscriptable after user interrupt

### Pitfall 4: Webhook Timeout Too Short
**What goes wrong:** Webhooks fail because endpoint is slow to respond
**Why it happens:** Default 5s timeout may be too short for endpoints that process data
**How to avoid:** Use 10-30s timeout for webhooks (they're fire-and-forget, OK to wait)
**Warning signs:** Webhook failures increase when endpoint is under load

### Pitfall 5: YAML Dumping Python Objects Without Conversion
**What goes wrong:** yaml.dump() fails or produces ugly output with Python objects
**Why it happens:** PyYAML can't serialize Pydantic models directly
**How to avoid:** Convert to dict first: `yaml.safe_dump(config.model_dump())`
**Warning signs:** TypeError: cannot serialize <class 'UserConfig'>

### Pitfall 6: Not Handling Existing Config in lem init
**What goes wrong:** Overwriting user's existing config without asking
**Why it happens:** Not checking if .lem-config.yaml exists before writing
**How to avoid:** Check Path(".lem-config.yaml").exists(), prompt to update or overwrite
**Warning signs:** User complaints about lost configuration

### Pitfall 7: Gitignore Duplicates
**What goes wrong:** Adding `.state/` to .gitignore multiple times when running init repeatedly
**Why it happens:** Not checking if pattern already exists before appending
**How to avoid:** Read existing lines, only append if not present
**Warning signs:** .gitignore has duplicate entries

## Code Examples

Verified patterns from official sources and existing codebase:

### Complete Resume Command Flow
```python
# Source: Synthesized from questionary + existing manifest.py patterns
import typer
import questionary
from pathlib import Path
from llenergymeasure.orchestration.manifest import ManifestManager
from llenergymeasure.cli.display import console

app = typer.Typer()

@app.command("resume")
def resume_cmd(
    dry_run: bool = typer.Option(False, "--dry-run", help="Show what would be resumed"),
    wipe: bool = typer.Option(False, "--wipe", help="Clear all state"),
) -> None:
    """Resume interrupted campaign or experiment."""

    # Handle --wipe flag
    if wipe:
        typer.confirm("Delete ALL state files?", abort=True)
        state_dir = Path(".state")
        if state_dir.exists():
            import shutil
            shutil.rmtree(state_dir)
            console.print("[green]✓[/green] State cleared")
        return

    # Discover interrupted work
    state_dir = Path(".state")
    if not state_dir.exists():
        console.print("[yellow]No interrupted work found[/yellow]")
        raise typer.Exit(1)

    # Find manifest files
    manifest_files = list(state_dir.glob("**/campaign_manifest.json"))
    if not manifest_files:
        console.print("[yellow]No interrupted campaigns found[/yellow]")
        raise typer.Exit(1)

    # Load manifests
    campaigns = []
    for manifest_path in manifest_files:
        manager = ManifestManager(manifest_path)
        manifest = manager.load()
        if manifest and not manifest.is_complete:
            campaigns.append(manifest)

    # Sort by most recent first
    campaigns.sort(key=lambda c: c.updated_at, reverse=True)

    # Single campaign: auto-select
    if len(campaigns) == 1:
        selected_campaign = campaigns[0]
        console.print(f"[bold]Found:[/bold] {selected_campaign.campaign_name}")
    else:
        # Multiple: show menu
        from rich.table import Table

        table = Table(title="Interrupted Campaigns")
        table.add_column("Option", style="cyan")
        table.add_column("Name", style="bold")
        table.add_column("Progress")
        table.add_column("Last Activity", style="dim")

        for i, campaign in enumerate(campaigns, 1):
            progress = f"{campaign.completed_count}/{campaign.total_experiments}"
            last = campaign.updated_at.strftime("%H:%M")
            table.add_row(str(i), campaign.campaign_name, progress, last)

        console.print(table)

        # Let user select
        choices = [
            questionary.Choice(
                title=f"{i}. {c.campaign_name} ({c.progress_fraction*100:.0f}%)",
                value=c
            )
            for i, c in enumerate(campaigns, 1)
        ]

        selected_campaign = questionary.select(
            "Select campaign to resume:",
            choices=choices
        ).ask()

        if selected_campaign is None:  # User pressed Ctrl+C
            raise typer.Abort()

    # Ask about failed experiments
    failed_count = selected_campaign.failed_count
    if failed_count > 0:
        retry_failed = typer.confirm(f"Retry {failed_count} failed experiments?")
    else:
        retry_failed = False

    # Dry run: just show what would happen
    if dry_run:
        console.print(f"\n[bold]Would resume:[/bold] {selected_campaign.campaign_name}")
        console.print(f"  Pending: {selected_campaign.pending_count}")
        console.print(f"  Failed:  {failed_count} ({'retry' if retry_failed else 'skip'})")
        return

    # Execute: call campaign runner with resume flag
    # (Implementation delegates to existing campaign.py)
    console.print(f"[green]Resuming:[/green] {selected_campaign.campaign_name}")
```

### Complete Init Wizard
```python
# Source: Synthesized from questionary + doctor.py patterns
import typer
import questionary
import yaml
from pathlib import Path
from llenergymeasure.config.user_config import UserConfig

app = typer.Typer()

@app.command("init")
def init_cmd(
    non_interactive: bool = typer.Option(False, "--non-interactive"),
    results_dir: str = typer.Option(None, "--results-dir"),
    webhook_url: str = typer.Option(None, "--webhook-url"),
) -> None:
    """Initialize project with guided configuration wizard."""

    config_path = Path(".lem-config.yaml")

    # Check if config exists
    if config_path.exists():
        update = typer.confirm("Config already exists. Update it?", default=False)
        if not update:
            console.print("[yellow]Cancelled[/yellow]")
            return
        # Load existing for defaults
        existing_config = UserConfig.model_validate(yaml.safe_load(config_path.read_text()))
    else:
        existing_config = UserConfig()  # Defaults

    # Non-interactive mode
    if non_interactive:
        config = UserConfig(
            results_dir=results_dir or existing_config.results_dir,
            notifications={
                "webhook_url": webhook_url,
                "on_complete": webhook_url is not None,
                "on_failure": webhook_url is not None,
            } if webhook_url else None
        )
    else:
        # Interactive wizard
        console.print("\n[bold]LLenergyMeasure Configuration Wizard[/bold]\n")

        # 1. Detect environment
        env_info = detect_environment()  # From Pattern 4
        console.print("[dim]Environment detected:[/dim]")
        console.print(f"  Python: {env_info['python_version']}")
        console.print(f"  GPU:    {'✓' if env_info['cuda_available'] else '✗'}")
        console.print(f"  Docker: {'✓' if env_info['docker_running'] else '✗'}\n")

        # 2. Results directory
        results_dir_input = questionary.text(
            "Results directory:",
            default=existing_config.results_dir
        ).ask()

        # 3. Thermal gaps
        thermal_between_exp = questionary.text(
            "Thermal gap between experiments (seconds):",
            default=str(existing_config.thermal_gaps.between_experiments)
        ).ask()

        # 4. Docker strategy (if Docker available)
        if env_info.get('docker_running'):
            docker_strategy = questionary.select(
                "Docker strategy:",
                choices=["ephemeral", "persistent"],
                default=existing_config.docker.strategy
            ).ask()
        else:
            docker_strategy = existing_config.docker.strategy

        # 5. Webhook notifications
        webhook_url_input = questionary.text(
            "Webhook URL (optional, for notifications):",
            default=existing_config.notifications.webhook_url if existing_config.notifications else "",
            validate=lambda url: True if not url or url.startswith(("http://", "https://")) else "Must start with http:// or https://"
        ).ask()

        # Build config
        config = UserConfig(
            results_dir=results_dir_input,
            thermal_gaps={
                "between_experiments": float(thermal_between_exp),
                "between_cycles": existing_config.thermal_gaps.between_cycles,
            },
            docker={
                "strategy": docker_strategy,
                "warmup_delay": existing_config.docker.warmup_delay,
                "auto_teardown": existing_config.docker.auto_teardown,
            },
            notifications={
                "webhook_url": webhook_url_input,
                "on_complete": True,
                "on_failure": True,
            } if webhook_url_input else None
        )

    # Write config
    with config_path.open("w") as f:
        yaml.safe_dump(config.model_dump(exclude_none=True), f, default_flow_style=False)

    console.print(f"\n[green]✓[/green] Config written to {config_path}")

    # Run doctor to verify setup
    console.print("\n[dim]Running diagnostics...[/dim]\n")
    from llenergymeasure.cli.doctor import doctor_cmd
    doctor_cmd()
```

### Webhook Sender with Notification Config
```python
# Source: httpx docs + webhook best practices
import httpx
from loguru import logger
from llenergymeasure.config.user_config import load_user_config

def send_experiment_notification(
    event_type: str,  # "complete" or "failure"
    experiment_id: str,
    payload: dict,
) -> None:
    """Send webhook notification if configured.

    Args:
        event_type: "complete" or "failure"
        experiment_id: Experiment identifier
        payload: Additional data to include in webhook
    """
    # Load user config
    user_config = load_user_config()

    # Check if notifications configured
    if not user_config.notifications or not user_config.notifications.webhook_url:
        return  # No webhook configured, skip silently

    # Check if this event type is enabled
    if event_type == "complete" and not user_config.notifications.on_complete:
        return
    if event_type == "failure" and not user_config.notifications.on_failure:
        return

    # Build webhook payload
    webhook_payload = {
        "event": f"experiment.{event_type}",
        "experiment_id": experiment_id,
        "timestamp": datetime.now().isoformat(),
        **payload
    }

    # Send webhook (non-blocking, log errors but don't fail experiment)
    try:
        response = httpx.post(
            user_config.notifications.webhook_url,
            json=webhook_payload,
            timeout=10.0,
            follow_redirects=True
        )
        response.raise_for_status()
        logger.debug(f"Webhook sent: {event_type} for {experiment_id}")
    except httpx.TimeoutException:
        logger.warning(f"Webhook timeout for {experiment_id}")
    except httpx.HTTPStatusError as e:
        logger.warning(f"Webhook failed ({e.response.status_code}) for {experiment_id}")
    except httpx.RequestError as e:
        logger.warning(f"Webhook request error for {experiment_id}: {e}")
```

## State of the Art

| Old Approach | Current Approach | When Changed | Impact |
|--------------|------------------|--------------|--------|
| PyInquirer | questionary | 2020+ | PyInquirer unmaintained, questionary actively developed |
| requests | httpx | 2020+ | httpx has async support, better defaults (timeout), modern API |
| manual curses menus | questionary.select() | N/A | Cross-platform compatibility, styling, error handling |
| prompt_toolkit directly | questionary (wrapper) | N/A | questionary provides simpler API over prompt_toolkit |

**Deprecated/outdated:**
- **PyInquirer:** Unmaintained since 2020, use questionary or InquirerPy instead
- **requests for new projects:** No async, no default timeout, use httpx
- **Rich for interactive input:** Rich is output-only, use questionary for input

## Open Questions

Things that couldn't be fully resolved:

1. **Webhook retry policy**
   - What we know: Best practice is 3-5 retries with exponential backoff
   - What's unclear: Should Phase 2.3 implement retry, or just single attempt?
   - Recommendation: Single attempt for Phase 2.3 (fail fast), retry can be added later if users request it

2. **Gitignore manipulation edge cases**
   - What we know: Simple append is safe for basic patterns like `.state/`
   - What's unclear: Should we handle commented-out patterns, trailing whitespace?
   - Recommendation: Simple append with duplicate check (exact string match), don't parse git patterns

3. **Init wizard verbosity level**
   - What we know: Should be "balanced" per CONTEXT.md
   - What's unclear: Exact wording for help text, how much to explain
   - Recommendation: Follow docker.py pattern (1-line description per question, show detected env first)

## Sources

### Primary (HIGH confidence)
- questionary PyPI (version 2.1.1): https://pypi.org/project/questionary/
- questionary documentation: https://questionary.readthedocs.io/en/stable/
- HTTPX timeouts documentation: https://www.python-httpx.org/advanced/timeouts/
- HTTPX compatibility guide: https://www.python-httpx.org/compatibility/
- Typer prompt documentation: https://typer.tiangolo.com/tutorial/prompt/
- Rich Console API: https://rich.readthedocs.io/en/latest/console.html

### Secondary (MEDIUM confidence)
- Webhook best practices 2026: https://latenode.com/blog/integration-api-management/webhook-setup-configuration/how-to-implement-webhook-retry-logic
- HTTPX retry patterns: https://will-ockmore.github.io/httpx-retries/
- Python atomic writes: https://sahmanish20.medium.com/better-file-writing-in-python-embrace-atomic-updates-593843bfab4f
- YAML configuration best practices: https://configu.com/blog/working-with-python-configuration-files-tutorial-best-practices/

### Tertiary (LOW confidence - synthesized from search results)
- CLI wizard patterns (no single authoritative source, synthesized from AWS CLI and Cisco examples)
- Gitignore Python patterns (community conventions, not official spec)

## Metadata

**Confidence breakdown:**
- Standard stack: HIGH - questionary actively maintained (Aug 2025), httpx official docs, existing Typer/Rich integration
- Architecture: HIGH - Patterns verified from official docs and existing codebase (doctor.py, manifest.py)
- Pitfalls: MEDIUM - Some from official docs (HTTPX redirects), some from common patterns (questionary None return)

**Research date:** 2026-02-04
**Valid until:** ~60 days (stable libraries, slow-moving domain)
