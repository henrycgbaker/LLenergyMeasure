---
phase: 02.3-campaign-state-resume
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/llenergymeasure/cli/resume.py
  - src/llenergymeasure/cli/__init__.py
  - src/llenergymeasure/cli/campaign.py
  - src/llenergymeasure/config/user_config.py
  - src/llenergymeasure/notifications/__init__.py
  - src/llenergymeasure/notifications/webhook.py
  - pyproject.toml
autonomous: true
user_setup: []

must_haves:
  truths:
    - "User runs `lem resume` and sees list of interrupted campaigns"
    - "User selects campaign with arrow keys and it resumes execution"
    - "User runs `lem resume --dry-run` and sees what would be resumed without executing"
    - "User runs `lem resume --wipe` and all state is cleared after confirmation"
    - "Webhook notifications POST to configured URL on experiment completion/failure"
  artifacts:
    - path: "src/llenergymeasure/cli/resume.py"
      provides: "`lem resume` command with interactive menu"
      min_lines: 80
    - path: "src/llenergymeasure/notifications/webhook.py"
      provides: "Webhook sender with timeout and error handling"
      exports: ["send_webhook_notification"]
    - path: "src/llenergymeasure/config/user_config.py"
      provides: "Extended UserConfig with NotificationsConfig"
      contains: "class NotificationsConfig"
  key_links:
    - from: "src/llenergymeasure/cli/resume.py"
      to: "orchestration/manifest.py"
      via: "ManifestManager.load()"
      pattern: "ManifestManager.*load"
    - from: "src/llenergymeasure/notifications/webhook.py"
      to: "config/user_config.py"
      via: "load_user_config()"
      pattern: "load_user_config"
    - from: "src/llenergymeasure/cli/campaign.py"
      to: "notifications/webhook.py"
      via: "send_webhook_notification() calls"
      pattern: "send_webhook_notification"
---

<objective>
Implement `lem resume` command, webhook notification system, and wire webhooks into campaign execution.

Purpose: Enable users to discover and resume interrupted campaigns with interactive selection, and receive webhook notifications when experiments complete or fail.

Output: Working `lem resume` command, webhook sender module, extended UserConfig with notifications support, webhooks integrated into campaign execution loop.
</objective>

<execution_context>
@/Users/henrybaker/.claude/get-shit-done/workflows/execute-plan.md
@/Users/henrybaker/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02.3-CONTEXT.md
@.planning/phases/02.3-campaign-state-resume/02.3-RESEARCH.md

# Existing implementation patterns
@src/llenergymeasure/cli/doctor.py
@src/llenergymeasure/config/user_config.py
@src/llenergymeasure/orchestration/manifest.py
@src/llenergymeasure/cli/campaign.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Extend UserConfig with NotificationsConfig and add questionary/httpx dependencies</name>
  <files>
    src/llenergymeasure/config/user_config.py
    pyproject.toml
  </files>
  <action>
1. Add `questionary` and `httpx` to pyproject.toml dependencies (main, not optional).

2. In `user_config.py`:
   - REMOVE `default_backend` field (decision D3: backend must be explicit in config)
   - ADD `NotificationsConfig` model:
     ```python
     class NotificationsConfig(BaseModel):
         webhook_url: str | None = Field(default=None, description="URL for webhook POST notifications")
         on_complete: bool = Field(default=True, description="Send notification on experiment completion")
         on_failure: bool = Field(default=True, description="Send notification on experiment failure")
     ```
   - ADD `notifications` field to UserConfig: `notifications: NotificationsConfig = Field(default_factory=NotificationsConfig)`
   - CHANGE error handling in load_user_config: Instead of silently returning defaults on invalid config, raise ValueError with descriptive message (fail-fast validation per decision D3)
   - Add `NotificationsConfig` to `__all__`
  </action>
  <verify>
    `python -c "from llenergymeasure.config.user_config import UserConfig, NotificationsConfig; c = UserConfig(); print(c.model_dump())"`
    Should show notifications field, no default_backend field.
  </verify>
  <done>
    UserConfig has notifications field, default_backend removed, invalid config raises ValueError.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create webhook sender module and integrate into campaign execution</name>
  <files>
    src/llenergymeasure/notifications/__init__.py
    src/llenergymeasure/notifications/webhook.py
    src/llenergymeasure/cli/campaign.py
  </files>
  <action>
1. Create `src/llenergymeasure/notifications/` directory.

2. Create `__init__.py` with exports:
   ```python
   from llenergymeasure.notifications.webhook import send_webhook_notification
   __all__ = ["send_webhook_notification"]
   ```

3. Create `webhook.py` implementing:
   ```python
   import httpx
   from typing import Literal
   from loguru import logger
   from llenergymeasure.config.user_config import load_user_config

   def send_webhook_notification(
       event_type: Literal["complete", "failure"],
       experiment_id: str,
       campaign_id: str | None = None,
       payload: dict | None = None,
   ) -> bool:
       """Send webhook notification if configured.

       Args:
           event_type: "complete" or "failure"
           experiment_id: Experiment identifier
           campaign_id: Optional campaign identifier
           payload: Additional data to include

       Returns:
           True if sent successfully, False otherwise (or if not configured)
       """
   ```

   Implementation:
   - Load user config via `load_user_config()`
   - Check if notifications configured and webhook_url set
   - Check if this event_type is enabled (on_complete/on_failure)
   - Build payload with event type, experiment_id, campaign_id, timestamp, and any extra payload
   - Use `httpx.post()` with:
     - `timeout=10.0`
     - `follow_redirects=True` (HTTPX pitfall from RESEARCH.md)
   - Catch httpx.TimeoutException, HTTPStatusError, RequestError and log warnings (don't raise)
   - Return True on success, False on any failure
   - Use loguru logger for all logging

4. **Wire webhooks into campaign execution** in `cli/campaign.py`:

   In the `_run_config_sequence` function (around lines 583-612), add webhook calls:
   - After `if exit_code == 0:` block (experiment completed successfully), add:
     ```python
     # Send webhook notification on completion
     from llenergymeasure.notifications import send_webhook_notification
     send_webhook_notification(
         event_type="complete",
         experiment_id=experiment_id,
         campaign_id=campaign.campaign_id,
         payload={"config_name": config_name, "cycle": experiment.cycle_index},
     )
     ```
   - After the `else:` block (experiment failed), add:
     ```python
     # Send webhook notification on failure
     from llenergymeasure.notifications import send_webhook_notification
     send_webhook_notification(
         event_type="failure",
         experiment_id=experiment_id,
         campaign_id=campaign.campaign_id,
         payload={"config_name": config_name, "exit_code": exit_code},
     )
     ```

   In the `_run_campaign_loop` function (around lines 763-784), add the same webhook calls:
   - After successful completion block, call send_webhook_notification with event_type="complete"
   - After failure block, call send_webhook_notification with event_type="failure"

   Note: Import lazily inside the if/else blocks to avoid import at module level.
  </action>
  <verify>
    `python -c "from llenergymeasure.notifications import send_webhook_notification; print(send_webhook_notification.__doc__)"`
    Should print docstring without import errors.

    `grep -n "send_webhook_notification" src/llenergymeasure/cli/campaign.py`
    Should show webhook calls in both _run_config_sequence and _run_campaign_loop functions.
  </verify>
  <done>
    Webhook sender module exists, handles timeouts/errors gracefully, returns bool success.
    Webhooks are called in campaign.py when experiments complete or fail.
  </done>
</task>

<task type="auto">
  <name>Task 3: Create `lem resume` command with interactive menu</name>
  <files>
    src/llenergymeasure/cli/resume.py
    src/llenergymeasure/cli/__init__.py
  </files>
  <action>
1. Create `resume.py` implementing the `lem resume` command per CONTEXT.md decisions:

   Add imports at top of file:
   ```python
   import shutil
   from pathlib import Path
   from typing import Annotated

   import questionary
   import typer
   from rich.table import Table

   from llenergymeasure.cli.display import console
   from llenergymeasure.orchestration.manifest import CampaignManifest, ManifestManager
   ```

   Command signature:
   ```python
   @app.command("resume")
   def resume_cmd(
       dry_run: Annotated[bool, typer.Option("--dry-run", help="Show what would be resumed")] = False,
       wipe: Annotated[bool, typer.Option("--wipe", help="Clear all state")] = False,
   ) -> None:
   ```

   Flow:
   a. Handle `--wipe` flag first:
      - `typer.confirm("Delete ALL state files?", abort=True)`
      - If confirmed, delete `.state/` directory with shutil.rmtree
      - Print success message and return

   b. Discover interrupted campaigns:
      - Check if `.state/` exists, if not print "No interrupted work found" and exit 1
      - Glob for `**/campaign_manifest.json` files in `.state/`
      - For each manifest file, instantiate ManifestManager and call `.load()`:
        ```python
        manifest_mgr = ManifestManager(manifest_path)
        manifest = manifest_mgr.load()
        ```
      - Filter to incomplete ones (not manifest.is_complete)
      - Sort by `updated_at` descending (most recent first per decision D1)

   c. Handle no campaigns found:
      - Print "No interrupted campaigns found" and exit 1

   d. Single campaign auto-select:
      - If only one campaign, auto-select it and print "Found: {campaign_name}"

   e. Multiple campaigns - show table and menu:
      - Use Rich Table to display: ID (first 8 chars), Name, Progress (X/Y), Last Activity
      - Use questionary.select() with Choice objects for menu:
        ```python
        choices = [questionary.Choice(title=f"{m.campaign_name} ({m.completed_count}/{m.total_experiments})", value=m) for m in manifests]
        selected = questionary.select("Select campaign to resume:", choices=choices).ask()
        ```
      - Handle None return (Ctrl+C) with `raise typer.Abort()`

   f. Ask about failed experiments:
      - If selected_campaign.failed_count > 0:
        `retry_failed = typer.confirm(f"Retry {failed_count} failed experiments?")`

   g. Handle `--dry-run`:
      - Print what would be resumed (campaign name, pending count, failed count + retry decision)
      - Return without executing

   h. Execute resume:
      - Import campaign module lazily: `from llenergymeasure.cli import campaign`
      - NOTE: This creates new dispatch logic - there is no existing "resume campaign" function.
        The resume command should:
        1. Load the campaign config from the manifest's stored config path (if available)
        2. OR reconstruct minimal CampaignConfig from manifest data
        3. Call the campaign execution functions with `resume=True` flag
      - For Phase 2.3, implement a simple approach:
        - Print "Resuming: {campaign_name}" and the state directory path
        - Print instruction: "Run: lem campaign <original_config.yaml> --resume"
        - This guides user to use existing --resume flag on campaign command
      - Print "Resuming: {campaign_name}"

2. Register command in `cli/__init__.py`:
   - Add `resume` to the imports in `_register_commands()`
   - Add `app.command("resume")(resume.resume_cmd)`
  </action>
  <verify>
    `lem resume --help` shows the command with --dry-run and --wipe options.
    `lem resume` (with no interrupted campaigns) exits with "No interrupted campaigns found".
  </verify>
  <done>
    `lem resume` command works: discovers campaigns, shows interactive menu, supports --dry-run and --wipe.
  </done>
</task>

</tasks>

<verification>
1. `lem resume --help` shows command with options
2. `lem resume` with no state directory prints "No interrupted work found"
3. `python -c "from llenergymeasure.config.user_config import UserConfig; print('default_backend' not in UserConfig.model_fields)"` returns True
4. `python -c "from llenergymeasure.notifications import send_webhook_notification; print('OK')"` prints OK
5. Dependencies installed: `pip show questionary httpx` shows both packages
6. `grep -n "send_webhook_notification" src/llenergymeasure/cli/campaign.py` shows webhook integration
</verification>

<success_criteria>
- `lem resume` command registered and functional
- Interactive menu works with questionary (arrow keys)
- --dry-run shows planned actions without executing
- --wipe clears state after confirmation
- UserConfig extended with notifications, default_backend removed
- Webhook sender handles timeouts/errors gracefully
- Webhooks called in campaign execution on completion and failure
</success_criteria>

<output>
After completion, create `.planning/phases/02.3-campaign-state-resume/02.3-01-SUMMARY.md`
</output>
