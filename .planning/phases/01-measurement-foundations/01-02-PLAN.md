---
phase: 01-measurement-foundations
plan: 02
type: execute
wave: 2
depends_on: ["01-01"]
files_modified:
  - src/llenergymeasure/core/power_thermal.py
  - src/llenergymeasure/core/environment.py
  - src/llenergymeasure/core/baseline.py
autonomous: true

must_haves:
  truths:
    - "PowerThermalSampler collects power, memory, and thermal throttle data at configurable intervals"
    - "Environment metadata collector returns GPU name, CUDA version, driver, thermal state, CPU governor, container detection"
    - "Baseline power measurement samples idle GPU power with session-level caching"
    - "All three components gracefully degrade when NVML is unavailable"
  artifacts:
    - path: "src/llenergymeasure/core/power_thermal.py"
      provides: "PowerThermalSampler with context manager, thread-safe sampling"
      exports: ["PowerThermalSampler", "PowerThermalSample", "PowerThermalResult"]
    - path: "src/llenergymeasure/core/environment.py"
      provides: "collect_environment_metadata() returning EnvironmentMetadata"
      exports: ["collect_environment_metadata"]
    - path: "src/llenergymeasure/core/baseline.py"
      provides: "measure_baseline_power() with session caching, adjust_energy_for_baseline()"
      exports: ["measure_baseline_power", "adjust_energy_for_baseline"]
  key_links:
    - from: "src/llenergymeasure/core/power_thermal.py"
      to: "src/llenergymeasure/domain/metrics.py"
      via: "uses ThermalThrottleInfo to summarise throttle state"
      pattern: "ThermalThrottleInfo"
    - from: "src/llenergymeasure/core/environment.py"
      to: "src/llenergymeasure/domain/environment.py"
      via: "returns EnvironmentMetadata model"
      pattern: "EnvironmentMetadata"
    - from: "src/llenergymeasure/core/baseline.py"
      to: "src/llenergymeasure/domain/metrics.py"
      via: "returns EnergyBreakdown model"
      pattern: "EnergyBreakdown"
---

<objective>
Implement the three core NVML-based measurement components: power/thermal sampling, environment metadata collection, and baseline power measurement with caching.

Purpose: These are the measurement primitives that the orchestrator will wire into the experiment lifecycle. MEAS-01 (environment), MEAS-02 (baseline), MEAS-03 (thermal throttling), MEAS-04 (time-series).
Output: Three new core modules ready for orchestrator integration.
</objective>

<execution_context>
@/home/h.baker@hertie-school.lan/.claude/get-shit-done/workflows/execute-plan.md
@/home/h.baker@hertie-school.lan/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/01-CONTEXT.md
@.planning/phases/01-measurement-foundations/01-RESEARCH.md

Key source files — read these BEFORE implementing:
@src/llenergymeasure/core/gpu_utilisation.py  (REFERENCE PATTERN — follow this exactly)
@src/llenergymeasure/domain/metrics.py  (EnergyBreakdown, ThermalThrottleInfo models from Plan 01)
@src/llenergymeasure/domain/environment.py  (EnvironmentMetadata model from Plan 01)

Plan 01 summary (if available):
@.planning/phases/01-measurement-foundations/01-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: PowerThermalSampler (time-series + thermal throttle detection)</name>
  <files>
    src/llenergymeasure/core/power_thermal.py
  </files>
  <action>
    Create `core/power_thermal.py` following the EXACT pattern of `core/gpu_utilisation.py` (GPUUtilisationSampler). This module handles MEAS-03 (thermal throttling) and MEAS-04 (time-series sampling).

    1. Define `PowerThermalSample` dataclass:
    - `timestamp: float` — `time.perf_counter()` value
    - `power_w: float | None = None` — GPU power draw in Watts
    - `memory_used_mb: float | None = None` — GPU memory used in MB
    - `memory_total_mb: float | None = None` — GPU total memory in MB
    - `temperature_c: float | None = None` — GPU temperature in Celsius
    - `sm_utilisation: float | None = None` — SM utilisation 0-100%
    - `thermal_throttle: bool = False` — Whether thermal throttling active
    - `throttle_reasons: int = 0` — Raw NVML throttle reason bitmask

    2. Create `PowerThermalSampler` class:
    - `__init__(self, device_index: int = 0, sample_interval_ms: int = 100)` — Same signature pattern as GPUUtilisationSampler
    - `__enter__` / `__exit__` context manager (identical pattern)
    - `start()` / `stop()` methods (identical pattern)
    - `_sample_loop()` background thread:
      - `import pynvml` inside the method (lazy import, like GPUUtilisationSampler)
      - `pynvml.nvmlInit()`, get device handle
      - In loop: sample power (`nvmlDeviceGetPowerUsage` — returns milliwatts, divide by 1000), memory (`nvmlDeviceGetMemoryInfo`), temperature (`nvmlDeviceGetTemperature`), utilisation (`nvmlDeviceGetUtilizationRates`), throttle reasons (`nvmlDeviceGetCurrentClocksThrottleReasons`)
      - Set `thermal_throttle = bool(reasons & (nvmlClocksThrottleReasonThermal | nvmlClocksThrottleReasonSwThermalSlowdown | nvmlClocksThrottleReasonHwThermalSlowdown))`
      - Catch `pynvml.NVMLError` per sample (skip failed samples, don't crash)
      - `pynvml.nvmlShutdown()` on exit
    - Graceful degradation: if pynvml not importable, log debug and return empty results
    - Use `loguru.logger` for debug logging (same as GPUUtilisationSampler)

    3. Accessor methods:
    - `get_samples() -> list[PowerThermalSample]` — All collected samples
    - `get_power_samples() -> list[float]` — Power values only (non-None)
    - `get_mean_power() -> float | None` — Mean power in Watts
    - `get_thermal_throttle_info() -> ThermalThrottleInfo` — Summarise throttle state from samples (import from domain/metrics.py)
      - `detected`: True if ANY sample had thermal_throttle=True
      - `throttle_duration_sec`: Count of throttled samples * sample_interval
      - `max_temperature_c`: Max temperature across all samples
      - `throttle_timestamps`: Timestamps of throttled samples
      - For the individual boolean flags (thermal, power, sw_thermal, hw_thermal, hw_power), check if ANY sample had the corresponding bit set in throttle_reasons. Use the NVML constants.
    - `sample_count` property
    - `is_available` property

    4. Create `PowerThermalResult` dataclass (analogous to GPUSamplerResult):
    - `power_samples: list[float]`
    - `memory_samples: list[float]`
    - `temperature_samples: list[float]`
    - `thermal_throttle_info: ThermalThrottleInfo`
    - `sample_count: int`
    - `available: bool`
    - `@classmethod from_sampler(cls, sampler: PowerThermalSampler) -> PowerThermalResult`

    IMPORTANT: Follow gpu_utilisation.py structure exactly — same import pattern, same thread safety, same graceful degradation. The only difference is we sample MORE metrics per tick.
  </action>
  <verify>
    Run `python -c "from llenergymeasure.core.power_thermal import PowerThermalSampler, PowerThermalSample, PowerThermalResult; print('PowerThermalSampler imports OK')"` — must succeed.
    Run `python -c "
from llenergymeasure.core.power_thermal import PowerThermalSampler
s = PowerThermalSampler(device_index=0, sample_interval_ms=100)
# Test that it doesn't crash even without GPU
info = s.get_thermal_throttle_info()
assert info.detected == False
print('Graceful degradation OK')
"` — must succeed even without GPU.
  </verify>
  <done>
    PowerThermalSampler exists as context manager, samples power/memory/temperature/utilisation/throttle at configurable intervals. Returns ThermalThrottleInfo summary. Gracefully degrades without GPU.
  </done>
</task>

<task type="auto">
  <name>Task 2: Environment metadata collector + baseline power measurement</name>
  <files>
    src/llenergymeasure/core/environment.py
    src/llenergymeasure/core/baseline.py
  </files>
  <action>
    **Part A: Environment metadata collector (`core/environment.py`)**

    Create `core/environment.py` implementing MEAS-01 (environment metadata).

    1. `collect_environment_metadata(device_index: int = 0) -> EnvironmentMetadata`:
    - Import `EnvironmentMetadata` and sub-models from `domain/environment.py`
    - GPU info via NVML: `nvmlDeviceGetName`, `nvmlDeviceGetMemoryInfo`, `nvmlDeviceGetCudaComputeCapability` (returns major, minor — format as "major.minor")
    - CUDA/driver: `nvmlSystemGetCudaDriverVersion` (parse: major = version // 1000, minor = (version % 1000) // 10), `nvmlSystemGetDriverVersion`
    - Thermal: `nvmlDeviceGetTemperature(handle, NVML_TEMPERATURE_GPU)`, `nvmlDeviceGetPowerManagementLimit` (milliwatts, divide by 1000), `nvmlDeviceGetPowerManagementDefaultLimit` (milliwatts)
    - CPU governor: Read `/sys/devices/system/cpu/cpu0/cpufreq/scaling_governor` (Linux only, catch FileNotFoundError). Use `platform.processor()` for CPU model.
    - Container detection: Check `os.path.exists("/.dockerenv")` or `os.path.exists("/run/.containerenv")`. Try to detect runtime from `/proc/1/cgroup`.
    - Wrap entire function in try/except: if NVML unavailable, return EnvironmentMetadata with reasonable defaults and `gpu.name = "unavailable"`.
    - Use `datetime.now()` for `collected_at`.
    - Log debug messages for each section.

    **Part B: Baseline power measurement (`core/baseline.py`)**

    Create `core/baseline.py` implementing MEAS-02 (baseline power + adjusted energy).

    1. `BaselineCache` dataclass:
    - `power_w: float` — Measured baseline power
    - `timestamp: float` — `time.time()` when measured
    - `device_index: int` — GPU device
    - `sample_count: int` — Number of samples taken
    - `duration_sec: float` — Measurement duration

    2. Module-level cache: `_baseline_cache: dict[int, BaselineCache] = {}` (keyed by device_index).

    3. `measure_baseline_power(device_index: int = 0, duration_sec: float = 30.0, sample_interval_ms: int = 100, cache_ttl_sec: float = 3600.0) -> BaselineCache | None`:
    - Check module-level cache first: if cached AND `(time.time() - cached.timestamp) < cache_ttl_sec`, log "Using cached baseline" and return cached value
    - Otherwise: `import pynvml`, init, get handle
    - Sample `nvmlDeviceGetPowerUsage(handle)` (milliwatts -> watts) at sample_interval_ms for duration_sec
    - Compute mean power from samples
    - Create BaselineCache, store in module-level dict
    - Log info: `f"Baseline power measured: {mean_power:.1f}W ({len(samples)} samples over {duration_sec}s)"`
    - On any error: log warning, return None (never crash)

    4. `invalidate_baseline_cache(device_index: int | None = None) -> None`:
    - If device_index given, remove that entry. If None, clear all.

    5. `adjust_energy_for_baseline(total_energy_j: float, baseline_power_w: float, duration_sec: float) -> float`:
    - `baseline_energy_j = baseline_power_w * duration_sec`
    - `adjusted = total_energy_j - baseline_energy_j`
    - `return max(0.0, adjusted)` — Conservative floor at zero (physically meaningless to have negative energy)

    6. `create_energy_breakdown(total_energy_j: float, baseline: BaselineCache | None, duration_sec: float) -> EnergyBreakdown`:
    - Import `EnergyBreakdown` from `domain/metrics.py`
    - If baseline is not None: compute adjusted_j, fill all baseline fields
    - If baseline is None: raw_j only, everything else None, baseline_method = "unavailable"
    - Calculate `baseline_cache_age_sec = time.time() - baseline.timestamp` if baseline exists

    IMPORTANT for both files: Graceful degradation. These run on GPU machines but must NOT crash if NVML is unavailable. Always catch ImportError for pynvml and NVMLError for API calls.
  </action>
  <verify>
    Run `python -c "from llenergymeasure.core.environment import collect_environment_metadata; print('environment imports OK')"` — must succeed.
    Run `python -c "from llenergymeasure.core.baseline import measure_baseline_power, adjust_energy_for_baseline, create_energy_breakdown; print('baseline imports OK')"` — must succeed.
    Run `python -c "
from llenergymeasure.core.baseline import adjust_energy_for_baseline
# Test: 100J total, 10W baseline, 5s duration = 100 - 50 = 50J
assert adjust_energy_for_baseline(100.0, 10.0, 5.0) == 50.0
# Test: floor at zero
assert adjust_energy_for_baseline(10.0, 50.0, 5.0) == 0.0
print('Baseline adjustment OK')
"` — must succeed.
    Run `python -c "
from llenergymeasure.core.baseline import create_energy_breakdown
# Test without baseline
eb = create_energy_breakdown(total_energy_j=100.0, baseline=None, duration_sec=60.0)
assert eb.raw_j == 100.0
assert eb.adjusted_j is None
assert eb.baseline_method == 'unavailable'
print('Energy breakdown (no baseline) OK')
"` — must succeed.
  </verify>
  <done>
    1. `core/environment.py` collects GPU, CUDA, driver, thermal, CPU, container metadata via NVML
    2. `core/baseline.py` measures idle baseline power with session caching, computes adjusted energy with floor-at-zero
    3. Both gracefully degrade when NVML unavailable
  </done>
</task>

</tasks>

<verification>
- All three new modules import cleanly
- PowerThermalSampler follows GPUUtilisationSampler pattern exactly
- Baseline adjustment arithmetic correct (including floor at zero)
- Environment collector handles missing NVML gracefully
- No existing tests broken: `python -m pytest tests/unit/ -x -q`
</verification>

<success_criteria>
1. PowerThermalSampler collects power/memory/temp/utilisation/throttle at configurable intervals via NVML
2. Environment metadata collector returns EnvironmentMetadata with GPU, CUDA, thermal, CPU, container info
3. Baseline power measurement with session-level caching and configurable TTL
4. All components degrade gracefully without GPU (return defaults/None, never crash)
</success_criteria>

<output>
After completion, create `.planning/phases/01-measurement-foundations/01-02-SUMMARY.md`
</output>
