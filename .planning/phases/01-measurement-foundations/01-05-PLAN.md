---
phase: 01-measurement-foundations
plan: 05
type: execute
wave: 3
depends_on: ["01-02", "01-03", "01-04"]
files_modified:
  - src/llenergymeasure/orchestration/runner.py
  - src/llenergymeasure/orchestration/factory.py
  - src/llenergymeasure/results/aggregation.py
  - src/llenergymeasure/cli/experiment.py
autonomous: true

must_haves:
  truths:
    - "Experiment lifecycle includes baseline measurement before inference"
    - "PowerThermalSampler runs during inference (alongside existing GPUUtilisationSampler)"
    - "Environment metadata collected and stored in RawProcessResult"
    - "Warmup uses CV-based convergence (not fixed iterations)"
    - "Time-series data saved when timeseries.save=True in config"
    - "Thermal throttle flags appear in results"
    - "Aggregation handles new schema v3 fields (energy_breakdown, thermal, environment)"
    - "CLI shows environment summary line after experiment completes"
  artifacts:
    - path: "src/llenergymeasure/orchestration/runner.py"
      provides: "ExperimentOrchestrator.run() with baseline, warmup, sampler, environment wiring"
      contains: "measure_baseline_power"
    - path: "src/llenergymeasure/orchestration/factory.py"
      provides: "Factory wires new components based on config"
      contains: "WarmupConfig"
    - path: "src/llenergymeasure/results/aggregation.py"
      provides: "Aggregation handles energy_breakdown, thermal_throttle, environment"
      contains: "energy_breakdown"
    - path: "src/llenergymeasure/cli/experiment.py"
      provides: "CLI displays environment summary after experiment"
      contains: "summary_line"
  key_links:
    - from: "src/llenergymeasure/orchestration/runner.py"
      to: "src/llenergymeasure/core/baseline.py"
      via: "calls measure_baseline_power before inference"
      pattern: "measure_baseline_power"
    - from: "src/llenergymeasure/orchestration/runner.py"
      to: "src/llenergymeasure/core/power_thermal.py"
      via: "uses PowerThermalSampler context manager during inference"
      pattern: "PowerThermalSampler"
    - from: "src/llenergymeasure/orchestration/runner.py"
      to: "src/llenergymeasure/core/warmup.py"
      via: "calls warmup_until_converged before inference"
      pattern: "warmup_until_converged"
    - from: "src/llenergymeasure/orchestration/runner.py"
      to: "src/llenergymeasure/core/environment.py"
      via: "calls collect_environment_metadata"
      pattern: "collect_environment_metadata"
    - from: "src/llenergymeasure/orchestration/runner.py"
      to: "src/llenergymeasure/results/timeseries.py"
      via: "calls export_timeseries when config.timeseries.save=True"
      pattern: "export_timeseries"
---

<objective>
Wire all Phase 1 measurement components into the experiment lifecycle: baseline power measurement before inference, PowerThermalSampler during inference, warmup convergence, environment metadata collection, time-series export, and aggregation of new fields.

Purpose: This is the integration plan that connects all the measurement primitives (Plans 02-04) into the orchestrator. Without this, the components exist but don't run.
Output: Modified runner.py, factory.py, aggregation.py, and experiment.py (CLI) with Phase 1 measurement wiring.
</objective>

<execution_context>
@/home/h.baker@hertie-school.lan/.claude/get-shit-done/workflows/execute-plan.md
@/home/h.baker@hertie-school.lan/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/01-CONTEXT.md
@.planning/phases/01-measurement-foundations/01-RESEARCH.md

Key source files — read ALL before implementing:
@src/llenergymeasure/orchestration/runner.py  (MAIN FILE TO MODIFY)
@src/llenergymeasure/orchestration/factory.py
@src/llenergymeasure/orchestration/context.py
@src/llenergymeasure/results/aggregation.py
@src/llenergymeasure/cli/experiment.py

Prior plan summaries (read ALL):
@.planning/phases/01-measurement-foundations/01-01-SUMMARY.md
@.planning/phases/01-measurement-foundations/01-02-SUMMARY.md
@.planning/phases/01-measurement-foundations/01-03-SUMMARY.md
@.planning/phases/01-measurement-foundations/01-04-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Wire measurement components into ExperimentOrchestrator.run()</name>
  <files>
    src/llenergymeasure/orchestration/runner.py
  </files>
  <action>
    Modify `ExperimentOrchestrator.run()` to integrate the new Phase 1 measurement components. The existing method runs: load model -> start energy tracking -> run inference -> stop tracking -> collect metrics -> save result. We need to insert new steps at specific points.

    **Read the existing `run()` method carefully before making changes.** Preserve ALL existing behaviour.

    1. **BEFORE model loading** — Collect environment metadata:
    ```python
    # Collect environment metadata (MEAS-01)
    from llenergymeasure.core.environment import collect_environment_metadata
    try:
        environment = collect_environment_metadata(ctx.device.index or 0)
        logger.info(f"Environment: {environment.summary_line}")
    except Exception as e:
        logger.warning(f"Environment metadata collection failed (non-fatal): {e}")
        environment = None
    ```

    2. **BEFORE model loading** — Measure baseline power:
    ```python
    # Baseline power measurement (MEAS-02)
    from llenergymeasure.core.baseline import measure_baseline_power, create_energy_breakdown
    baseline = None
    if ctx.config.baseline.enabled:
        try:
            baseline = measure_baseline_power(
                device_index=ctx.device.index or 0,
                duration_sec=ctx.config.baseline.duration_sec,
                sample_interval_ms=ctx.config.baseline.sample_interval_ms,
                cache_ttl_sec=ctx.config.baseline.cache_ttl_sec,
            )
            if baseline:
                logger.info(f"Baseline power: {baseline.power_w:.1f}W")
            elif ctx.config.baseline.required:
                raise RuntimeError("Baseline measurement required but failed")
            else:
                logger.warning("Baseline measurement failed, continuing with raw energy only")
        except RuntimeError:
            raise
        except Exception as e:
            if ctx.config.baseline.required:
                raise RuntimeError(f"Baseline measurement required but failed: {e}") from e
            logger.warning(f"Baseline measurement failed (non-fatal): {e}")
    ```

    3. **AFTER model loading, BEFORE inference** — Run warmup:
    ```python
    # Warmup convergence (MEAS-05)
    from llenergymeasure.core.warmup import warmup_until_converged, create_warmup_inference_fn
    warmup_result = None
    if ctx.config.warmup.enabled:
        try:
            warmup_fn = create_warmup_inference_fn(
                model, tokenizer, prompts[0] if prompts else "Hello",
                max_new_tokens=min(32, ctx.config.max_output_tokens),
            )
            warmup_result = warmup_until_converged(
                warmup_fn, ctx.config.warmup, show_progress=True
            )
            if warmup_result.converged:
                logger.info(f"Warmup converged: {warmup_result.iterations_completed} prompts, CV={warmup_result.final_cv:.3f}")
            else:
                logger.warning(f"Warmup did not converge after {warmup_result.iterations_completed} prompts (CV={warmup_result.final_cv:.3f})")
        except Exception as e:
            logger.warning(f"Warmup failed (non-fatal): {e}")
    ```

    4. **AROUND inference** — PowerThermalSampler (alongside existing GPUUtilisationSampler):
    The existing code likely already uses GPUUtilisationSampler or similar. We need to add PowerThermalSampler alongside it. Look at how the existing sampler is used and mirror the pattern.

    ```python
    # PowerThermalSampler (MEAS-03, MEAS-04)
    from llenergymeasure.core.power_thermal import PowerThermalSampler
    power_sampler = PowerThermalSampler(
        device_index=ctx.device.index or 0,
        sample_interval_ms=ctx.config.timeseries.sample_interval_ms
        if ctx.config.timeseries.enabled else 100,
    )
    ```

    Wrap the inference call in the sampler context manager:
    ```python
    with power_sampler:
        inference_result = self._inference.run(model, tokenizer, prompts, ctx.config)
    ```

    5. **AFTER inference, before result construction** — Build energy breakdown and thermal info:
    ```python
    # Energy breakdown (MEAS-02)
    energy_breakdown = create_energy_breakdown(
        total_energy_j=energy_metrics.total_energy_j,
        baseline=baseline,
        duration_sec=energy_metrics.duration_sec,
    )

    # Thermal throttle info (MEAS-03)
    thermal_throttle = power_sampler.get_thermal_throttle_info()
    if thermal_throttle.detected:
        logger.warning(f"Thermal throttling detected during experiment ({thermal_throttle.throttle_duration_sec:.1f}s)")
    ```

    6. **AFTER result save** — Export time-series if configured:
    ```python
    # Time-series export (MEAS-04)
    timeseries_path_str = None
    if ctx.config.timeseries.save and power_sampler.is_available:
        try:
            from llenergymeasure.results.timeseries import export_timeseries
            ts_path = export_timeseries(
                samples=power_sampler.get_samples(),
                experiment_id=ctx.experiment_id,
                process_index=ctx.process_index,
                output_dir=result_path.parent,
                sample_interval_ms=ctx.config.timeseries.sample_interval_ms,
            )
            timeseries_path_str = str(ts_path)
            logger.info(f"Time-series saved: {ts_path}")
        except Exception as e:
            logger.warning(f"Time-series export failed (non-fatal): {e}")
    ```

    7. **In RawProcessResult construction** — Add new fields:
    Add these to the `RawProcessResult(...)` constructor call:
    ```python
    environment=environment,
    energy_breakdown=energy_breakdown,
    thermal_throttle=thermal_throttle,
    warmup_result=warmup_result,
    timeseries_path=timeseries_path_str,
    ```

    IMPORTANT: Every new integration point must be wrapped in try/except with `(non-fatal)` logging. Phase 1 measurement failures must NEVER crash the experiment. The experiment must always complete and save results, even if all new features fail.

    IMPORTANT: Read the existing `run()` method line by line. Do NOT rewrite it. INSERT new code at the correct points. Preserve all existing logic including energy tracking, metrics collection, GPU info, MIG detection, extended metrics, completion markers, etc.
  </action>
  <verify>
    Run `python -c "from llenergymeasure.orchestration.runner import ExperimentOrchestrator; print('Runner imports OK')"` — must succeed.
    Run `python -m pytest tests/unit/test_orchestration_runner.py -x -q 2>&1 | tail -10` — existing orchestration tests must pass (new code wrapped in try/except shouldn't break mocked tests).
  </verify>
  <done>
    ExperimentOrchestrator.run() integrates: (1) environment metadata collection, (2) baseline power measurement with caching, (3) warmup convergence before inference, (4) PowerThermalSampler during inference, (5) energy breakdown and thermal throttle info computation, (6) time-series export when configured, (7) all new fields in RawProcessResult. All integrations are non-fatal — experiment always completes.
  </done>
</task>

<task type="auto">
  <name>Task 2: Aggregation + CLI display for schema v3 fields</name>
  <files>
    src/llenergymeasure/results/aggregation.py
    src/llenergymeasure/cli/experiment.py
  </files>
  <action>
    **Part A: Update aggregation to handle schema v3 fields**

    Read `results/aggregation.py` first. Find where `AggregatedResult` is constructed from per-process `RawProcessResult` objects. Add handling for new fields:

    1. `environment`: Take from first process (all processes share same GPU environment):
    ```python
    environment = process_results[0].environment if process_results else None
    ```

    2. `energy_breakdown`: If multiple processes, sum raw_j and adjusted_j:
    ```python
    if any(p.energy_breakdown for p in process_results):
        breakdowns = [p.energy_breakdown for p in process_results if p.energy_breakdown]
        total_raw = sum(b.raw_j for b in breakdowns)
        total_adjusted = sum(b.adjusted_j for b in breakdowns if b.adjusted_j is not None)
        # Use first process baseline info (same GPU)
        first = breakdowns[0]
        energy_breakdown = EnergyBreakdown(
            raw_j=total_raw,
            adjusted_j=total_adjusted if any(b.adjusted_j is not None for b in breakdowns) else None,
            baseline_power_w=first.baseline_power_w,
            baseline_method=first.baseline_method,
            baseline_timestamp=first.baseline_timestamp,
            baseline_cache_age_sec=first.baseline_cache_age_sec,
        )
    else:
        energy_breakdown = None
    ```

    3. `thermal_throttle`: Merge across processes (any process throttled = throttled):
    ```python
    if any(p.thermal_throttle for p in process_results):
        throttles = [p.thermal_throttle for p in process_results if p.thermal_throttle]
        thermal_throttle = ThermalThrottleInfo(
            detected=any(t.detected for t in throttles),
            thermal=any(t.thermal for t in throttles),
            power=any(t.power for t in throttles),
            sw_thermal=any(t.sw_thermal for t in throttles),
            hw_thermal=any(t.hw_thermal for t in throttles),
            hw_power=any(t.hw_power for t in throttles),
            throttle_duration_sec=max(t.throttle_duration_sec for t in throttles),
            max_temperature_c=max((t.max_temperature_c for t in throttles if t.max_temperature_c is not None), default=None),
        )
    else:
        thermal_throttle = None
    ```

    4. `timeseries_path`: Set to aggregated path if timeseries were exported (or None).

    Add these to the `AggregatedResult(...)` construction.

    **Part B: CLI environment summary display**

    Read `cli/experiment.py`. Find where experiment results are displayed after completion. Add an environment summary line:

    After the experiment completes and results are displayed, add:
    ```python
    # Display environment summary (Phase 1)
    if hasattr(result, 'environment') and result.environment:
        console.print(f"  Environment: {result.environment.summary_line}")
    if hasattr(result, 'thermal_throttle') and result.thermal_throttle and result.thermal_throttle.detected:
        console.print(f"  [yellow]Warning: Thermal throttling detected ({result.thermal_throttle.throttle_duration_sec:.1f}s)[/yellow]")
    if hasattr(result, 'energy_breakdown') and result.energy_breakdown and result.energy_breakdown.adjusted_j is not None:
        console.print(f"  Energy: {result.energy_breakdown.raw_j:.2f}J raw, {result.energy_breakdown.adjusted_j:.2f}J adjusted (baseline: {result.energy_breakdown.baseline_power_w:.1f}W)")
    if hasattr(result, 'warmup_result') and result.warmup_result:
        status = "converged" if result.warmup_result.converged else "not converged"
        console.print(f"  Warmup: {result.warmup_result.iterations_completed} prompts ({status}, CV={result.warmup_result.final_cv:.3f})")
    ```

    Find the appropriate location in the CLI output flow. This should display right after the main experiment metrics. Use Rich console for formatting (it's already used in the CLI).

    If you can't find a natural insertion point (e.g., the display happens in a separate display module), create a simple helper function and call it at the appropriate place.
  </action>
  <verify>
    Run `python -c "from llenergymeasure.results.aggregation import ResultAggregator; print('Aggregation imports OK')"` — must succeed (or whatever the actual aggregation class/function is named).
    Run `python -m pytest tests/unit/ -x -q 2>&1 | tail -10` — all unit tests must pass.
    Run `python -m pytest tests/integration/ -x -q 2>&1 | tail -10` — integration tests must pass.
  </verify>
  <done>
    1. Aggregation handles schema v3 fields: environment (from first process), energy_breakdown (summed), thermal_throttle (merged), timeseries_path
    2. CLI displays environment summary line, thermal throttling warning, energy breakdown, and warmup status after experiment completes
    3. All existing tests pass
  </done>
</task>

</tasks>

<verification>
- Runner.py integrates all 4 measurement components (environment, baseline, warmup, sampler)
- All integration points wrapped in try/except (non-fatal)
- Aggregation handles new fields correctly
- CLI shows new information after experiment
- All existing unit and integration tests pass
- A mock experiment (without GPU) should not crash
</verification>

<success_criteria>
1. Experiment lifecycle: environment -> baseline -> model load -> warmup -> sampler+inference -> energy breakdown -> thermal check -> save results -> export timeseries
2. All new features are non-fatal (experiment always completes)
3. Aggregation correctly merges new fields across processes
4. CLI displays environment summary, thermal warnings, energy breakdown, warmup status
5. Zero regressions in existing tests
</success_criteria>

<output>
After completion, create `.planning/phases/01-measurement-foundations/01-05-SUMMARY.md`
</output>
