---
phase: 01-measurement-foundations
plan: 04
type: execute
wave: 2
depends_on: ["01-01"]
files_modified:
  - src/llenergymeasure/results/exporters.py
  - src/llenergymeasure/results/timeseries.py
autonomous: true

must_haves:
  truths:
    - "CSV export includes grouped-prefix columns for energy breakdown, thermal, environment, and warmup"
    - "Time-series data exported to separate JSON file (not embedded in main results)"
    - "CSV column ordering groups related fields together (energy_*, thermal_*, env_*, warmup_*)"
    - "Existing CSV export still works for v2 results without new fields"
  artifacts:
    - path: "src/llenergymeasure/results/exporters.py"
      provides: "Extended _aggregated_to_row with energy, thermal, environment, warmup columns"
      contains: "energy_raw_j"
    - path: "src/llenergymeasure/results/timeseries.py"
      provides: "export_timeseries() and load_timeseries() functions"
      exports: ["export_timeseries", "load_timeseries"]
  key_links:
    - from: "src/llenergymeasure/results/exporters.py"
      to: "src/llenergymeasure/domain/experiment.py"
      via: "reads energy_breakdown, thermal_throttle, environment, warmup_result fields"
      pattern: "energy_breakdown"
    - from: "src/llenergymeasure/results/timeseries.py"
      to: "src/llenergymeasure/core/power_thermal.py"
      via: "accepts PowerThermalSample list for serialisation"
      pattern: "PowerThermalSample"
---

<objective>
Extend CSV export with grouped-prefix columns for new Phase 1 metrics and create time-series export as separate JSON files.

Purpose: MEAS-07 (extended CSV export) and part of MEAS-04 (time-series export). Users need new metrics in CSV for spreadsheet analysis and optional time-series files for power/memory profiling.
Output: Updated exporters.py with new CSV columns, new timeseries.py for separate file export.
</objective>

<execution_context>
@/home/h.baker@hertie-school.lan/.claude/get-shit-done/workflows/execute-plan.md
@/home/h.baker@hertie-school.lan/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/01-CONTEXT.md
@.planning/phases/01-measurement-foundations/01-RESEARCH.md

Key source files — read BEFORE implementing:
@src/llenergymeasure/results/exporters.py  (existing CSV export to extend)
@src/llenergymeasure/domain/experiment.py  (schema v3 fields from Plan 01)
@src/llenergymeasure/domain/metrics.py  (new models from Plan 01)
@src/llenergymeasure/domain/environment.py  (EnvironmentMetadata from Plan 01)

Plan 01 summary (if available):
@.planning/phases/01-measurement-foundations/01-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Extended CSV export with grouped-prefix columns</name>
  <files>
    src/llenergymeasure/results/exporters.py
  </files>
  <action>
    Extend the existing `_aggregated_to_row()` function in `exporters.py` to include new Phase 1 fields. Follow the CONTEXT.md decision: grouped prefixes for CSV readability.

    1. Update `_aggregated_to_row()` to add these columns AFTER the existing core metrics:

    **Energy breakdown** (grouped prefix `energy_`):
    ```python
    # Energy breakdown (schema v3)
    "energy_raw_j": result.total_energy_j,  # Existing field, renamed for clarity
    "energy_adjusted_j": (
        result.energy_breakdown.adjusted_j
        if result.energy_breakdown else None
    ),
    "energy_baseline_w": (
        result.energy_breakdown.baseline_power_w
        if result.energy_breakdown else None
    ),
    "energy_baseline_method": (
        result.energy_breakdown.baseline_method
        if result.energy_breakdown else None
    ),
    ```

    **Thermal throttling** (grouped prefix `thermal_`):
    ```python
    "thermal_throttle_detected": (
        result.thermal_throttle.detected
        if result.thermal_throttle else False
    ),
    "thermal_throttle_duration_sec": (
        result.thermal_throttle.throttle_duration_sec
        if result.thermal_throttle else 0.0
    ),
    "thermal_max_temp_c": (
        result.thermal_throttle.max_temperature_c
        if result.thermal_throttle else None
    ),
    ```

    **Environment** (grouped prefix `env_`):
    ```python
    "env_gpu_name": (
        result.environment.gpu.name
        if result.environment else None
    ),
    "env_gpu_vram_mb": (
        result.environment.gpu.vram_total_mb
        if result.environment else None
    ),
    "env_cuda_version": (
        result.environment.cuda.version
        if result.environment else None
    ),
    "env_driver_version": (
        result.environment.cuda.driver_version
        if result.environment else None
    ),
    "env_gpu_temp_c": (
        result.environment.thermal.temperature_c
        if result.environment else None
    ),
    "env_power_limit_w": (
        result.environment.thermal.power_limit_w
        if result.environment else None
    ),
    "env_cpu_governor": (
        result.environment.cpu.governor
        if result.environment else None
    ),
    "env_in_container": (
        result.environment.container.detected
        if result.environment else None
    ),
    "env_summary": (
        result.environment.summary_line
        if result.environment else None
    ),
    ```

    **Extended metrics** (already partially exported, add missing grouped columns):
    ```python
    # GPU utilisation
    "gpu_util_mean_pct": (
        result.extended_metrics.gpu_utilisation.sm_utilisation_mean
        if result.extended_metrics else None
    ),
    "gpu_mem_peak_mb": (
        result.extended_metrics.memory.peak_memory_mb
        if result.extended_metrics else None
    ),
    # Request latency
    "latency_e2e_mean_ms": (
        result.extended_metrics.request_latency.e2e_latency_mean_ms
        if result.extended_metrics else None
    ),
    "latency_e2e_p95_ms": (
        result.extended_metrics.request_latency.e2e_latency_p95_ms
        if result.extended_metrics else None
    ),
    # Batch efficiency
    "batch_effective_size": (
        result.extended_metrics.batch.effective_batch_size
        if result.extended_metrics else None
    ),
    # KV cache
    "kv_cache_hit_rate": (
        result.extended_metrics.kv_cache.kv_cache_hit_rate
        if result.extended_metrics else None
    ),
    ```

    **Time-series reference**:
    ```python
    "timeseries_path": result.timeseries_path if hasattr(result, 'timeseries_path') else None,
    ```

    2. Update `_order_columns()` to group new columns. Add these AFTER the existing priority list:
    ```python
    # Phase 1 column groups (after existing priority columns)
    "energy_raw_j", "energy_adjusted_j", "energy_baseline_w", "energy_baseline_method",
    "thermal_throttle_detected", "thermal_throttle_duration_sec", "thermal_max_temp_c",
    "env_gpu_name", "env_gpu_vram_mb", "env_cuda_version", "env_driver_version",
    "env_gpu_temp_c", "env_power_limit_w", "env_cpu_governor", "env_in_container", "env_summary",
    "gpu_util_mean_pct", "gpu_mem_peak_mb",
    "latency_e2e_mean_ms", "latency_e2e_p95_ms",
    "batch_effective_size", "kv_cache_hit_rate",
    "timeseries_path",
    ```

    3. IMPORTANT: Preserve existing behaviour. The `total_energy_j` field REMAINS in its original position (it's the raw value). `energy_raw_j` is an alias that also exports it. If this creates a duplicate column, keep only `energy_raw_j` and remove `total_energy_j` from the priority list (it's now `energy_raw_j`).

    Actually, simpler approach: rename `total_energy_j` to `energy_raw_j` in the row dict. This is a CSV column name change (not a model field change). Add `energy_raw_j` to priority list, remove `total_energy_j`.

    4. Handle None gracefully: Use `None` (which becomes empty string or "NA" in CSV), not errors when optional fields are missing.
  </action>
  <verify>
    Run `python -c "
from llenergymeasure.results.exporters import _aggregated_to_row
from unittest.mock import MagicMock
from datetime import datetime

# Create minimal AggregatedResult-like mock
result = MagicMock()
result.experiment_id = 'test_001'
result.start_time = datetime(2024, 1, 1)
result.end_time = datetime(2024, 1, 1, 0, 1)
result.duration_sec = 60.0
result.aggregation.num_processes = 1
result.aggregation.method = 'sum_energy_avg_throughput'
result.total_tokens = 100
result.total_energy_j = 50.0
result.total_inference_time_sec = 60.0
result.avg_tokens_per_second = 1.67
result.avg_energy_per_token_j = 0.5
result.total_flops = 1e12
result.tokens_per_joule = 2.0
result.aggregation.temporal_overlap_verified = True
result.aggregation.gpu_attribution_verified = True
result.aggregation.warnings = []
# Schema v3 fields missing (backwards compat)
result.energy_breakdown = None
result.thermal_throttle = None
result.environment = None
result.extended_metrics = None
result.timeseries_path = None

row = _aggregated_to_row(result, include_process_breakdown=False)
assert 'energy_raw_j' in row or 'total_energy_j' in row
assert row.get('thermal_throttle_detected') == False or row.get('thermal_throttle_detected') is None
print(f'CSV row has {len(row)} columns')
print('Extended CSV OK')
"` — must succeed.
    Run `python -m pytest tests/unit/ -x -q -k "export" 2>&1 | tail -5` — existing export tests must pass.
  </verify>
  <done>
    CSV export includes grouped-prefix columns for energy breakdown, thermal throttling, environment, extended metrics, and time-series path. Column ordering groups related fields. Backwards compatible with v2 results (new fields show as None/empty).
  </done>
</task>

<task type="auto">
  <name>Task 2: Time-series export to separate JSON files</name>
  <files>
    src/llenergymeasure/results/timeseries.py
  </files>
  <action>
    Create `results/timeseries.py` implementing MEAS-04's export component (time-series data saved as separate files).

    1. `export_timeseries(samples: list[PowerThermalSample], experiment_id: str, process_index: int, output_dir: Path, sample_interval_ms: int = 100) -> Path`:
    - Import `PowerThermalSample` from `core/power_thermal` (use TYPE_CHECKING guard for optional import)
    - Build JSON structure:
      ```python
      data = {
          "schema_version": SCHEMA_VERSION,
          "experiment_id": experiment_id,
          "process_index": process_index,
          "sample_count": len(samples),
          "sample_interval_ms": sample_interval_ms,
          "duration_sec": (samples[-1].timestamp - samples[0].timestamp) if len(samples) > 1 else 0.0,
          "summary": {
              "power_mean_w": mean of power values,
              "power_min_w": min,
              "power_max_w": max,
              "memory_mean_mb": mean of memory values,
              "memory_max_mb": max,
              "temperature_mean_c": mean of temperature values,
              "temperature_max_c": max,
              "thermal_throttle_detected": any sample had thermal_throttle=True,
              "thermal_throttle_sample_count": count of throttled samples,
          },
          "samples": [
              {
                  "t": round(s.timestamp - samples[0].timestamp, 4),  # Relative time in seconds
                  "power_w": round(s.power_w, 2) if s.power_w else None,
                  "mem_mb": round(s.memory_used_mb, 1) if s.memory_used_mb else None,
                  "temp_c": s.temperature_c,
                  "sm_pct": s.sm_utilisation,
                  "throttle": s.thermal_throttle,
              }
              for s in samples
          ],
      }
      ```
    - Use compact keys (t, mem_mb, sm_pct, throttle) to keep file size manageable
    - Write to `output_dir / f"process_{process_index}_timeseries.json"`
    - Use atomic write (temp file + rename)
    - Return the path

    2. `load_timeseries(path: Path) -> dict`:
    - Load JSON from path
    - Return the dict (simple accessor)
    - Raise FileNotFoundError if path doesn't exist

    3. `aggregate_timeseries(timeseries_paths: list[Path], output_path: Path, experiment_id: str) -> Path`:
    - Load all per-process timeseries files
    - Create aggregated timeseries: merge by nearest timestamp, compute per-timestamp means
    - Actually, simpler: just bundle all per-process timeseries into one file:
      ```python
      data = {
          "schema_version": SCHEMA_VERSION,
          "experiment_id": experiment_id,
          "process_count": len(timeseries_paths),
          "processes": [load_timeseries(p) for p in timeseries_paths],
      }
      ```
    - Write to output_path
    - Return the path

    4. File layout follows research recommendation:
    ```
    results/raw/exp_ID/
    ├── process_0.json              # Main results
    ├── process_0_timeseries.json   # Time-series (optional)
    └── .completed_0
    ```

    Use `from __future__ import annotations`. Follow existing exporters.py patterns for logging (loguru) and path handling.
  </action>
  <verify>
    Run `python -c "from llenergymeasure.results.timeseries import export_timeseries, load_timeseries; print('timeseries imports OK')"` — must succeed.
    Run `python -c "
from llenergymeasure.results.timeseries import export_timeseries, load_timeseries
from pathlib import Path
import tempfile, time

# Create mock samples (can't import PowerThermalSample without the module from Plan 02)
# Use a simple dataclass stand-in
from dataclasses import dataclass

@dataclass
class MockSample:
    timestamp: float
    power_w: float = 100.0
    memory_used_mb: float = 5000.0
    memory_total_mb: float = 80000.0
    temperature_c: float = 45.0
    sm_utilisation: float = 80.0
    thermal_throttle: bool = False
    throttle_reasons: int = 0

base_time = time.perf_counter()
samples = [MockSample(timestamp=base_time + i * 0.1) for i in range(10)]

with tempfile.TemporaryDirectory() as tmpdir:
    path = export_timeseries(samples, 'test_exp', 0, Path(tmpdir), 100)
    assert path.exists()
    data = load_timeseries(path)
    assert data['sample_count'] == 10
    assert len(data['samples']) == 10
    print(f'Time-series export OK: {path.name}, {data[\"sample_count\"]} samples')
"` — must succeed.
  </verify>
  <done>
    Time-series export creates separate JSON files with compact sample format. Summary statistics included in header. Atomic writes. Load and aggregate functions available. File layout matches research recommendation.
  </done>
</task>

</tasks>

<verification>
- CSV export includes all grouped-prefix columns (energy_*, thermal_*, env_*, gpu_*, latency_*, batch_*, kv_cache_*)
- Time-series exports to separate JSON file, not embedded in main results
- CSV column ordering groups related fields together
- Existing v2 results export without errors (backwards compatible)
- Time-series file is compact (short keys), includes summary header
</verification>

<success_criteria>
1. CSV export has ~20 new columns with grouped prefixes
2. Time-series data saved as separate JSON file per process
3. Both exports handle missing/None fields gracefully
4. Existing export tests pass unchanged
</success_criteria>

<output>
After completion, create `.planning/phases/01-measurement-foundations/01-04-SUMMARY.md`
</output>
