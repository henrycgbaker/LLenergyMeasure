---
phase: 02.4-cli-polish-testing
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/llenergymeasure/cli/config.py
  - src/llenergymeasure/cli/campaign.py
  - src/llenergymeasure/results/aggregation.py
autonomous: true

must_haves:
  truths:
    - "User can run 'lem config list' and see available configs in configs/ directory"
    - "User can run 'lem campaign --group-by backend,batch_size' and see grouped summary statistics"
    - "Grouped results appear in both CLI output table and campaign JSON"
  artifacts:
    - path: "src/llenergymeasure/cli/config.py"
      provides: "lem config list subcommand"
      contains: "def config_list"
    - path: "src/llenergymeasure/results/aggregation.py"
      provides: "Grouping logic for campaign aggregation"
      contains: "aggregate_campaign_with_grouping"
  key_links:
    - from: "src/llenergymeasure/cli/campaign.py"
      to: "src/llenergymeasure/results/aggregation.py"
      via: "aggregate_campaign_with_grouping function call"
      pattern: "aggregate_campaign_with_grouping"
---

<objective>
Add `lem config list` command for config discoverability and `--group-by` flag for campaign result aggregation.

Purpose: Improve CLI UX by making configuration files discoverable and enabling flexible campaign result grouping by any config field (backend, model, batch_size, etc.).

Output: Two new CLI features fully wired and working.
</objective>

<execution_context>
@/home/h.baker@hertie-school.lan/.claude/get-shit-done/workflows/execute-plan.md
@/home/h.baker@hertie-school.lan/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02.4-cli-polish-testing/02.4-CONTEXT.md
@.planning/phases/02.4-cli-polish-testing/02.4-RESEARCH.md

@src/llenergymeasure/cli/config.py
@src/llenergymeasure/cli/campaign.py
@src/llenergymeasure/results/aggregation.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add lem config list subcommand</name>
  <files>src/llenergymeasure/cli/config.py</files>
  <action>
Add `config_list` command to the config_app Typer subcommand group:

1. Add new command `@config_app.command("list")` that:
   - Scans `configs/` directory for YAML files (recursive, glob `**/*.yaml`)
   - Displays table with columns: Name, Backend, Model, Path
   - Extract backend and model from each config (load YAML, get fields)
   - Optionally show user config settings from `.lem-config.yaml` if exists

2. Parameters:
   - `--directory` / `-d`: Custom config directory (default: `configs/`)
   - `--show-user-config` / `-u`: Also show .lem-config.yaml settings (boolean flag)

3. Use Rich table for output:
   - Title: "Available Configurations"
   - Columns: Name (from filename), Backend, Model (truncated if >40 chars), Path (relative)
   - Style: cyan for backend column

4. Handle edge cases:
   - Empty directory: print "No configuration files found in {directory}"
   - Invalid YAML: skip with warning, continue listing others
   - Missing fields: show "-" for missing backend/model

Implementation note: Use yaml.safe_load to parse configs; don't validate against Pydantic (just list, not validate).
  </action>
  <verify>
Run:
```bash
lem config list
lem config list --show-user-config
lem config list -d configs/examples
```
All should display tables without errors.
  </verify>
  <done>
`lem config list` shows table of available configs with backend/model info extracted from YAML files.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add campaign --group-by flag and grouping logic</name>
  <files>
    src/llenergymeasure/results/aggregation.py
    src/llenergymeasure/cli/campaign.py
  </files>
  <action>
**Part A: aggregation.py - Add grouping function**

Add `aggregate_campaign_with_grouping` function:

```python
def aggregate_campaign_with_grouping(
    results_by_config: dict[str, list[AggregatedResult]],
    group_by: list[str],
    confidence: float = 0.95,
) -> dict[tuple[str, ...], dict[str, Any]]:
    """Aggregate campaign results with configurable grouping.

    Args:
        results_by_config: Dict mapping config name to list of AggregatedResult
        group_by: List of field paths to group by (e.g., ["backend", "model_name"])
        confidence: Confidence level for bootstrap CI

    Returns:
        Dict mapping group key tuple to aggregated metrics with CIs.
    """
```

Implementation:
1. Flatten all results into single list
2. For each result, extract grouping key by reading fields:
   - Simple fields: `backend`, `model_name`, `config_name`
   - Nested fields: `effective_config.pytorch.batch_size` -> traverse dict
   - Use helper function `_extract_field_value(result, field_path)`
3. Group results by extracted key tuple
4. Compute bootstrap CI for each group using existing `bootstrap_ci` function
5. Return grouped results with metrics (n_cycles, energy_j, throughput_tps, ttft_mean_ms, itl_mean_ms)

Helper function:
```python
def _extract_field_value(result: AggregatedResult, field_path: str) -> str:
    """Extract value from result using dot-notation path."""
    # Handle special cases first
    if field_path == "config_name":
        return result.effective_config.get("config_name", "unknown")
    if field_path == "backend":
        return result.backend
    if field_path == "model_name":
        return result.effective_config.get("model_name", "unknown")

    # Traverse nested path in effective_config
    parts = field_path.split(".")
    value = result.effective_config
    for part in parts:
        if isinstance(value, dict) and part in value:
            value = value[part]
        else:
            return "unknown"
    return str(value)
```

**Part B: campaign.py - Add --group-by flag**

1. Add parameter to `campaign_cmd`:
```python
group_by: Annotated[
    str | None,
    typer.Option(
        "--group-by",
        help="Comma-separated fields to group results by (e.g., backend,batch_size)",
    ),
] = None,
```

2. Parse comma-separated string into list:
```python
group_by_fields = group_by.split(",") if group_by else ["config_name"]
```

3. Update `_display_campaign_ci_summary` to accept and use group_by:
   - Change signature to accept `group_by: list[str]`
   - Call `aggregate_campaign_with_grouping` instead of `aggregate_campaign_results`
   - Update table columns dynamically based on group_by fields
   - Update table title to show "grouped by {fields}"

4. Save grouped results to campaign manifest/JSON:
   - Add `grouped_summary` field to manifest when saving final results
   - Structure: `{"group_by": ["backend"], "groups": {("pytorch",): {...}, ...}}`
  </action>
  <verify>
Create a test campaign with multiple backends and batch sizes, run:
```bash
lem campaign configs/examples/campaign_example.yaml --group-by backend --dry-run
```

Verify the execution plan shows and that grouped output would work.

For full verification (if campaign data exists):
```bash
# After running a multi-config campaign
lem campaign configs/*.yaml --campaign-name test --cycles 2 --group-by backend
```

Check that output table shows grouping by backend with CI metrics.
  </verify>
  <done>
Campaign CLI accepts `--group-by` flag, results are grouped by specified fields, and grouped summary appears in both CLI table and campaign JSON.
  </done>
</task>

</tasks>

<verification>
1. `lem config list` displays config table
2. `lem config list --show-user-config` shows .lem-config.yaml if exists
3. `lem campaign --help` shows `--group-by` option
4. Campaign with `--group-by backend` produces grouped output table
5. No regressions in existing campaign functionality
</verification>

<success_criteria>
- `lem config list` shows available configs with extracted metadata
- `--group-by` flag accepted by campaign command
- Grouping logic extracts fields correctly (simple and nested)
- Grouped results display in Rich table with dynamic columns
- Campaign JSON includes grouped_summary when group_by specified
</success_criteria>

<output>
After completion, create `.planning/phases/02.4-cli-polish-testing/02.4-01-SUMMARY.md`
</output>
