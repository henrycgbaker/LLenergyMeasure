# Phase 8.1: PyTorch Result Wiring Fixes — Research

**Researched:** 2026-02-27
**Domain:** PyTorch backend result assembly / Pydantic model wiring
**Confidence:** HIGH (all findings from direct source inspection)

---

## Summary

Phase 8.1 fixes 4 broken E2E flows that all trace to a single root cause: `PyTorchBackend._build_result()` does not wire 3 fields correctly when constructing `ExperimentResult`. This is pure internal wiring work — no new logic, no new libraries, no external dependencies. All changes are in 2 files.

The bugs are confirmed from direct codebase inspection against the M1 milestone audit (`M1-MILESTONE-AUDIT.md`). Every fix is a targeted 1-2 line change plus corresponding test coverage.

An additional structural fix (`extra="forbid"` on `ExperimentResult`) is required to prevent silent field name mistakes like the one that caused bug 1 in the first place.

**Primary recommendation:** Fix all 4 issues in a single phase with two tasks: (1) fix `_build_result()` wiring, (2) fix timeseries co-location. Tests for each fix are added in the same task. No design decisions required — the correct values are computed and present; they just are not set.

---

<phase_requirements>
## Phase Requirements

| ID | Description | Research Support |
|----|-------------|-----------------|
| RES-06 | `baseline_power_w`, `energy_adjusted_j`, `energy_per_device_j` on ExperimentResult | `energy_breakdown.baseline_power_w` and `energy_breakdown.adjusted_j` are computed in `_build_result()` but not propagated to top-level fields. Fix: extract before `ExperimentResult(...)` call. |
| RES-16 | Output always in subdirectory `{name}_{timestamp}/result.json` + `timeseries.parquet` co-located | Two sub-issues: (a) `effective_config` never set → dir named `unknown_pytorch_{ts}`; (b) timeseries written to flat `output_dir/` while result.json goes to subdirectory. Fix: set `effective_config`, change timeseries write to temp path + pass as `timeseries_source` to `save_result()`. |
| CM-16 | Timeseries: 1 Hz sidecar `timeseries.parquet` reachable from `ExperimentResult.timeseries` | `timeseries_path=` kwarg silently dropped by Pydantic (field is named `timeseries`). Fix: change kwarg name. Adding `extra="forbid"` prevents recurrence. |
</phase_requirements>

---

## Standard Stack

No new libraries. This phase operates entirely within the existing project stack:

### Core (already in use)
| Library | Version | Purpose | Why Standard |
|---------|---------|---------|--------------|
| Pydantic v2 | 2.x | `BaseModel` with `model_config` dict | Already used for all domain models |
| pytest | 7.x | Unit test framework | Project standard — 461 tests already |
| pathlib.Path | stdlib | File path operations | Project standard (per CLAUDE.md) |

### No new dependencies required.

---

## Architecture Patterns

### Relevant Project Structure

```
src/llenergymeasure/
├── core/backends/pytorch.py      # PyTorchBackend._build_result() ← CHANGE HERE
├── domain/experiment.py          # ExperimentResult model ← ADD extra="forbid"
├── results/persistence.py        # save_result(), _experiment_dir_name() ← timeseries co-location
└── cli/run.py                    # result.save() caller ← may need timeseries_source
tests/unit/
└── test_measurement_integration.py  # ← ADD tests here
```

### Pattern 1: Pydantic extra="forbid" on frozen models

```python
# CURRENT (domain/experiment.py line 259)
model_config = {"frozen": True}

# CORRECT — catches unrecognised kwargs at construction time
model_config = {"frozen": True, "extra": "forbid"}
```

Pydantic v2 supports combining `frozen` and `extra` in the same `model_config` dict. When `extra="forbid"`, any kwarg not matching a declared field raises `ValidationError`. This would have caught the `timeseries_path=` bug immediately.

**Verification:** `ExperimentConfig` (config/models.py) already uses `model_config = {"extra": "forbid"}` — the pattern is established and correct.

### Pattern 2: Extracting nested model fields before constructor call

```python
# CURRENT in _build_result() — energy_breakdown computed but top-level fields not set
energy_breakdown = create_energy_breakdown(total_energy_j, baseline, duration_sec)

return ExperimentResult(
    ...
    energy_breakdown=energy_breakdown,
    # baseline_power_w and energy_adjusted_j NEVER SET
)

# CORRECT — extract from computed EnergyBreakdown
energy_breakdown = create_energy_breakdown(total_energy_j, baseline, duration_sec)
baseline_power_w = energy_breakdown.baseline_power_w   # float | None
energy_adjusted_j = energy_breakdown.adjusted_j        # float | None

return ExperimentResult(
    ...
    energy_breakdown=energy_breakdown,
    baseline_power_w=baseline_power_w,
    energy_adjusted_j=energy_adjusted_j,
)
```

`EnergyBreakdown.baseline_power_w` and `EnergyBreakdown.adjusted_j` are already set correctly by `create_energy_breakdown()` (confirmed in `src/llenergymeasure/core/baseline.py` lines 184-195). The data is there; it just is not propagated.

### Pattern 3: effective_config from ExperimentConfig.model_dump()

```python
# CURRENT — effective_config never set, defaults to {}
return ExperimentResult(
    ...
    # NO effective_config kwarg
)

# CORRECT — populate from config
return ExperimentResult(
    ...
    effective_config=config.model_dump(),
)
```

`config.model_dump()` on an `ExperimentConfig` produces the full resolved config dict. This is what `_experiment_dir_name()` in `persistence.py` reads to build the directory name:

```python
# persistence.py line 32
raw_model = result.effective_config.get("model", "unknown")
```

When `effective_config={}`, `raw_model` is `"unknown"` and the directory is named `unknown_pytorch_{ts}`.

### Pattern 4: Timeseries co-location via timeseries_source

The fix requires changing the timeseries write flow from:

```
CURRENT:
  run() → write_timeseries_parquet(output_dir/timeseries.parquet)   ← FLAT (wrong)
  CLI   → result.save(output_dir)                                     ← creates output_dir/{subdir}/result.json
  RESULT: timeseries in output_dir/, result.json in output_dir/{subdir}/

CORRECT:
  run() → write_timeseries_parquet(output_dir/timeseries.parquet)   ← still write to temp path
  run() → set timeseries=ts_file.name on result                      ← correct field name
  CLI   → result.save(output_dir, timeseries_source=ts_path)        ← pass source to save_result()
  save_result() → shutil.copy2(timeseries_source, target_dir/timeseries.parquet)
  RESULT: both in output_dir/{subdir}/
```

`save_result()` already supports `timeseries_source: Path | None = None` (persistence.py line 73) — it copies the parquet into the same subdirectory as result.json (lines 99-106). The calling code in `cli/run.py` just needs to pass it:

```python
# cli/run.py — CURRENT (line 194)
result.save(Path(experiment_config.output_dir))

# cli/run.py — CORRECT
ts_source = None
if result.timeseries:
    ts_source = Path(experiment_config.output_dir) / result.timeseries
result.save(Path(experiment_config.output_dir), timeseries_source=ts_source)
```

BUT this only works if the backend writes to the flat `output_dir/` first — which it does at step 14 of `run()`. The sequence is correct: backend writes timeseries to `output_dir/timeseries.parquet`, CLI calls `result.save(output_dir, timeseries_source=Path(output_dir)/"timeseries.parquet")`, and persistence copies it into the subdirectory.

After the copy, the original flat file at `output_dir/timeseries.parquet` is a stale artifact. Recommend cleaning it up in the CLI after save, or writing it to a temp file in the first place.

**Simpler alternative:** Write timeseries to a `tempfile.NamedTemporaryFile()` path inside `run()`, return the temp path via `timeseries` field, then CLI passes it as `timeseries_source`. This avoids the stale file issue. However, this changes the backend's signature more significantly. Given the `output_dir` path is already available in `run()`, the simpler fix is to write to `output_dir/` and clean up, or accept the stale flat file.

**Recommended approach:** Keep the write to `output_dir/timeseries.parquet` in `run()` (unchanged). Fix the field name (`timeseries=` not `timeseries_path=`). In `cli/run.py`, pass the timeseries source to `result.save()`. After `save_result()` copies it into the subdir, optionally unlink the flat copy.

### Anti-Patterns to Avoid

- **Changing `ExperimentResult` to accept `timeseries_path=`**: Wrong direction — the field is correctly named `timeseries`. Fix the caller, not the model.
- **Modifying `_experiment_dir_name()` to not use `effective_config`**: That would require a different naming scheme. The right fix is to populate `effective_config` correctly.
- **Setting `extra="ignore"` instead of `extra="forbid"`**: `ignore` was the implicit default that caused the silent bug. `forbid` is the correct defensive setting for a frozen result model.

---

## Don't Hand-Roll

| Problem | Don't Build | Use Instead | Why |
|---------|-------------|-------------|-----|
| File copy for timeseries | Custom file copy logic | `shutil.copy2()` already in `persistence.py` | Already implemented at persistence.py:103 |
| Dict serialization of config | Custom serialization | `config.model_dump()` | Pydantic built-in, correct JSON-safe representation |
| Directory cleanup | Custom cleanup | stdlib `Path.unlink()` | Simple one-liner if needed |

---

## Common Pitfalls

### Pitfall 1: Forgetting `extra="forbid"` Breaks Existing Tests

**What goes wrong:** Adding `extra="forbid"` to `ExperimentResult` will cause any existing test that constructs `ExperimentResult(...)` with an unrecognised kwarg to fail.

**Why it happens:** Tests may use `timeseries_path=` (the old bug) or other stale kwargs from before the fix.

**How to avoid:** Run the full test suite after adding `extra="forbid"`. Fix any test failures — they are evidence of the same bug class.

**Warning signs:** `ValidationError: Extra inputs are not permitted` in tests.

### Pitfall 2: effective_config Containing Non-Serializable Values

**What goes wrong:** `config.model_dump()` may contain Pydantic sub-models or special types that are not JSON-serializable if mode="python" is used.

**Why it happens:** `model_dump()` by default returns Python objects (dicts, Pydantic models). For nested configs, inner models are returned as dicts already in Pydantic v2 (deep serialisation by default).

**How to avoid:** Verify `ExperimentConfig.model_dump()` returns a plain dict. It does — Pydantic v2 `model_dump()` recursively serialises nested `BaseModel` instances to dicts. No special handling needed.

**Warning signs:** `TypeError: Object of type PyTorchConfig is not JSON serializable` at persistence write time.

### Pitfall 3: Timeseries Source File Missing When CLI Passes It

**What goes wrong:** If `config.output_dir` is None, the backend does not write the timeseries file. The CLI cannot pass a non-existent file as `timeseries_source`.

**Why it happens:** The timeseries write in `run()` is guarded by `if config.output_dir is not None and timeseries_samples`. If no output_dir, `result.timeseries` will be None after the fix (correct — no file was written).

**How to avoid:** CLI guard: `ts_source = Path(output_dir) / result.timeseries if result.timeseries else None`. `save_result()` already handles `timeseries_source=None` gracefully.

### Pitfall 4: Pydantic frozen=True with extra="forbid" — Order Matters

**What goes wrong:** Setting only `{"extra": "forbid"}` removes `frozen=True` accidentally.

**Why it happens:** If the developer writes `model_config = {"extra": "forbid"}` instead of merging with the existing `{"frozen": True}`.

**How to avoid:** The correct dict is `model_config = {"frozen": True, "extra": "forbid"}`. Both keys must be present.

---

## Code Examples

### Bug 1: Field name mismatch (timeseries_path= vs timeseries=)

```python
# CURRENT — broken (pytorch.py line 782)
return ExperimentResult(
    ...
    timeseries_path=timeseries_path,   # ← WRONG: field is named `timeseries`
    ...
)

# FIXED
return ExperimentResult(
    ...
    timeseries=timeseries_path,        # ← CORRECT field name
    ...
)
```

With `extra="forbid"`, the old code raises `ValidationError: Extra inputs are not permitted [timeseries_path]`.

### Bug 2: effective_config not set

```python
# CURRENT — never set (pytorch.py _build_result())
return ExperimentResult(
    ...
    # effective_config NOT in kwargs → defaults to {}
    ...
)

# FIXED
return ExperimentResult(
    ...
    effective_config=config.model_dump(),
    ...
)
```

### Bug 3: baseline_power_w and energy_adjusted_j not propagated

```python
# CURRENT — data computed but top-level fields not set
energy_breakdown = create_energy_breakdown(total_energy_j, baseline, duration_sec)

return ExperimentResult(
    ...
    energy_breakdown=energy_breakdown,
    # baseline_power_w not set → None
    # energy_adjusted_j not set → None
    ...
)

# FIXED — extract from breakdown
energy_breakdown = create_energy_breakdown(total_energy_j, baseline, duration_sec)

return ExperimentResult(
    ...
    energy_breakdown=energy_breakdown,
    baseline_power_w=energy_breakdown.baseline_power_w,   # float | None
    energy_adjusted_j=energy_breakdown.adjusted_j,        # float | None
    ...
)
```

### Bug 4: Timeseries co-location (cli/run.py)

```python
# CURRENT — no timeseries_source passed (run.py line 194)
if experiment_config.output_dir:
    result.save(Path(experiment_config.output_dir))

# FIXED — pass timeseries source for co-location
if experiment_config.output_dir:
    output_dir = Path(experiment_config.output_dir)
    ts_source = output_dir / result.timeseries if result.timeseries else None
    result.save(output_dir, timeseries_source=ts_source)
```

### Fix 5: ExperimentResult model_config

```python
# CURRENT (domain/experiment.py line 259)
model_config = {"frozen": True}

# FIXED — both keys in same dict
model_config = {"frozen": True, "extra": "forbid"}
```

### Test Template: _build_result() wiring tests

```python
def test_build_result_populates_timeseries_field() -> None:
    """_build_result() sets timeseries= (not timeseries_path=)."""
    # ... construct backend, data, etc. ...
    result = backend._build_result(..., timeseries_path="timeseries.parquet", ...)
    assert result.timeseries == "timeseries.parquet"
    assert result.timeseries is not None


def test_build_result_populates_effective_config() -> None:
    """_build_result() sets effective_config from config.model_dump()."""
    config = ExperimentConfig(model="gpt2")
    result = backend._build_result(config=config, ...)
    assert result.effective_config.get("model") == "gpt2"
    assert result.effective_config != {}


def test_build_result_propagates_baseline_fields() -> None:
    """_build_result() propagates baseline_power_w and energy_adjusted_j from energy_breakdown."""
    from llenergymeasure.core.baseline import BaselineCache
    baseline = BaselineCache(power_w=30.0, timestamp=time.time(), device_index=0)
    result = backend._build_result(..., baseline=baseline, ...)
    assert result.baseline_power_w == pytest.approx(30.0)
    assert result.energy_adjusted_j is not None
    assert result.energy_adjusted_j >= 0.0


def test_experiment_result_rejects_unknown_kwargs() -> None:
    """ExperimentResult raises ValidationError for unrecognised kwargs (extra='forbid')."""
    with pytest.raises(ValidationError):
        ExperimentResult(..., timeseries_path="ts.parquet")
```

---

## State of the Art

| Old Approach | Current Approach | When Changed | Impact |
|--------------|------------------|--------------|--------|
| `timeseries_path=` kwarg | `timeseries=` field name | Fix in Phase 8.1 | Silent discard → ValidationError |
| `extra` not set (implicit "ignore") | `extra="forbid"` | Fix in Phase 8.1 | Silent bugs → immediate errors |
| baseline fields not propagated | Extracted from `energy_breakdown` | Fix in Phase 8.1 | CLI baseline display works |
| `effective_config={}` always | `config.model_dump()` | Fix in Phase 8.1 | Directory naming works |
| Timeseries in wrong directory | Co-located via `timeseries_source` | Fix in Phase 8.1 | Sidecar discoverable |

---

## Open Questions

1. **Stale flat timeseries file after save_result() copy**
   - What we know: After the fix, `save_result()` copies `output_dir/timeseries.parquet` into `output_dir/{subdir}/timeseries.parquet`. The original flat file remains.
   - What's unclear: Is the stale flat file a problem for users? They would see `results/timeseries.parquet` (stale) and `results/gpt2_pytorch_{ts}/timeseries.parquet` (correct).
   - Recommendation: Unlink the flat file after `save_result()` succeeds in `cli/run.py`. One-liner: `ts_source.unlink(missing_ok=True)`. If this adds complexity, accept the stale file for now (it is non-destructive).

2. **`effective_config` with `model_dump()` — mode parameter**
   - What we know: Pydantic v2 `model_dump()` without `mode=` returns Python-native types (dicts for nested models, not raw JSON strings). This is what `persistence.py` uses (`result.effective_config.get("model")`).
   - What's unclear: Does `model_dump_json()` serialise `effective_config` correctly when it contains nested dicts from `model_dump()`? Yes — Pydantic serialises `dict[str, Any]` fields correctly to JSON as nested objects.
   - Recommendation: Use plain `config.model_dump()` — no `mode=` needed. Test with `ExperimentResult.model_dump_json()` round-trip.

---

## Sources

### Primary (HIGH confidence)
- Direct source inspection of `src/llenergymeasure/core/backends/pytorch.py` — confirmed `timeseries_path=` kwarg and missing `effective_config`, `baseline_power_w`, `energy_adjusted_j`
- Direct source inspection of `src/llenergymeasure/domain/experiment.py` — confirmed field name is `timeseries`, `model_config = {"frozen": True}` with no `extra`
- Direct source inspection of `src/llenergymeasure/results/persistence.py` — confirmed `timeseries_source` parameter already exists
- Direct source inspection of `src/llenergymeasure/cli/run.py` line 194 — confirmed `timeseries_source` not passed
- Direct source inspection of `src/llenergymeasure/core/baseline.py` lines 184-195 — confirmed `baseline_power_w` and `adjusted_j` are set correctly on `EnergyBreakdown`
- `.planning/M1-MILESTONE-AUDIT.md` — integration gaps section defines all 4 broken flows exactly
- Pydantic v2 documentation pattern — `model_config = {"frozen": True, "extra": "forbid"}` is valid and combining both is standard

---

## Metadata

**Confidence breakdown:**
- Standard stack: HIGH — no new libraries, all existing project patterns
- Architecture: HIGH — all patterns verified by direct code inspection
- Pitfalls: HIGH — confirmed from test suite and Pydantic v2 behaviour

**Research date:** 2026-02-27
**Valid until:** Until ExperimentResult or PyTorchBackend changes significantly (stable for M2 duration)
