---
phase: 17-docker-runner-infrastructure
plan: "01"
type: execute
wave: 1
depends_on: []
files_modified:
  - src/llenergymeasure/exceptions.py
  - src/llenergymeasure/infra/docker_errors.py
  - src/llenergymeasure/infra/container_entrypoint.py
  - src/llenergymeasure/infra/image_registry.py
  - tests/unit/test_docker_errors.py
  - tests/unit/test_container_entrypoint.py
  - tests/unit/test_image_registry.py
autonomous: true
requirements: [DOCK-02, DOCK-03, DOCK-11]

must_haves:
  truths:
    - "Docker errors are categorised into specific types (ImagePull, GPUAccess, OOM, Timeout, Permission) with actionable fix suggestions"
    - "A container entrypoint module can deserialise an ExperimentConfig from a JSON file, run it via ExperimentOrchestrator, and write the ExperimentResult back to disk"
    - "A built-in image registry maps backend names to default Docker images with CUDA version detection"
  artifacts:
    - path: "src/llenergymeasure/infra/docker_errors.py"
      provides: "Docker error hierarchy and error translation from container stderr"
      contains: "DockerError"
    - path: "src/llenergymeasure/infra/container_entrypoint.py"
      provides: "Container-side entry point that reads config JSON, runs experiment, writes result JSON"
      contains: "run_container_experiment"
    - path: "src/llenergymeasure/infra/image_registry.py"
      provides: "Backend-to-image mapping with CUDA version detection"
      contains: "get_default_image"
  key_links:
    - from: "src/llenergymeasure/infra/container_entrypoint.py"
      to: "src/llenergymeasure/orchestration/factory.py"
      via: "creates ExperimentOrchestrator to run experiment inside container"
      pattern: "create_orchestrator"
    - from: "src/llenergymeasure/infra/docker_errors.py"
      to: "src/llenergymeasure/exceptions.py"
      via: "DockerError inherits from LLEMError"
      pattern: "class DockerError.*LLEMError"
---

<objective>
Create the foundation types and modules for Docker dispatch: Docker error hierarchy with categorised error translation, a container entrypoint that runs experiments via the library API (not CLI re-entry), and a built-in image registry mapping backends to default Docker images.

Purpose: These are the building blocks consumed by the DockerRunner (Plan 02) and StudyRunner integration (Plan 04). Establishing contracts first prevents the "scavenger hunt" anti-pattern.

Output: Three new modules in `infra/` with full unit test coverage.
</objective>

<execution_context>
@/home/h.baker@hertie-school.lan/.claude/get-shit-done/workflows/execute-plan.md
@/home/h.baker@hertie-school.lan/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/17-docker-runner-infrastructure/17-CONTEXT.md

<interfaces>
<!-- Key types and contracts the executor needs. Extracted from codebase. -->

From src/llenergymeasure/exceptions.py:
```python
class LLEMError(Exception):
    """Base exception for llenergymeasure."""

class ConfigError(LLEMError): ...
class BackendError(LLEMError): ...
class PreFlightError(LLEMError): ...
class ExperimentError(LLEMError): ...
class StudyError(LLEMError): ...
```

From src/llenergymeasure/config/models.py:
```python
class ExperimentConfig(BaseModel):
    model: str
    backend: Literal["pytorch", "vllm", "tensorrt"]
    # ... full config with extra="forbid"

class StudyConfig(BaseModel):
    experiments: list[ExperimentConfig]
    execution: ExecutionConfig
    # ...
```

From src/llenergymeasure/domain/experiment.py:
```python
def compute_measurement_config_hash(config: ExperimentConfig) -> str:
    """SHA-256[:16] of ExperimentConfig."""

class ExperimentResult(BaseModel):
    experiment_id: str
    measurement_config_hash: str
    # ... frozen model with extra="forbid"
```

From src/llenergymeasure/orchestration/factory.py:
```python
def create_orchestrator(ctx: ExperimentContext, results_dir: Path | None = None) -> ExperimentOrchestrator:
    """Create a fully wired ExperimentOrchestrator."""

def create_components(ctx: ExperimentContext, results_dir: Path | None = None) -> ExperimentComponents:
    """Create all experiment components wired for the given context."""
```

From src/llenergymeasure/config/docker_detection.py:
```python
def is_inside_docker() -> bool:
    """Check if code is running inside a Docker container."""
```
</interfaces>
</context>

<tasks>

<task type="auto">
  <name>Task 1: Docker error hierarchy and stderr translation</name>
  <files>
    src/llenergymeasure/exceptions.py
    src/llenergymeasure/infra/docker_errors.py
    tests/unit/test_docker_errors.py
  </files>
  <action>
    1. Add `DockerError(LLEMError)` to `exceptions.py` — base class for all Docker-specific errors.

    2. Create `infra/docker_errors.py` with:
       - Subclasses of `DockerError`: `DockerImagePullError`, `DockerGPUAccessError`, `DockerOOMError`, `DockerTimeoutError`, `DockerPermissionError`, `DockerContainerError` (generic fallback).
       - Each subclass stores: `message: str`, `fix_suggestion: str`, `stderr_snippet: str | None`.
       - `translate_docker_error(returncode: int, stderr: str, image: str) -> DockerError` function that pattern-matches known Docker/NVIDIA Container Toolkit error strings:
         - "No such image" / "not found" / "manifest unknown" → `DockerImagePullError` with fix: "docker pull {image}"
         - "could not select device driver" / "nvidia-container-cli" / "GPU" → `DockerGPUAccessError` with fix: "Install NVIDIA Container Toolkit: https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html"
         - "OOM" / "out of memory" / "CUDA out of memory" / "OutOfMemoryError" → `DockerOOMError` with fix: "Reduce batch size or use a smaller model"
         - "permission denied" / "Got permission denied" → `DockerPermissionError` with fix: "Add user to docker group: sudo usermod -aG docker $USER"
         - Timeout (returncode 124 or -9) → `DockerTimeoutError` with fix: "Increase timeout or reduce experiment size"
         - Anything else → `DockerContainerError` with last 20 lines of stderr
       - `capture_stderr_snippet(stderr: str, max_lines: int = 20) -> str` — extracts last N lines.

    3. Create `tests/unit/test_docker_errors.py` with tests for:
       - Each error category pattern-matches correctly
       - Unknown errors produce `DockerContainerError` with stderr snippet
       - `capture_stderr_snippet` truncates long output
       - All error subclasses have `fix_suggestion` attribute
       - `DockerError` inherits from `LLEMError`
  </action>
  <verify>
    <automated>cd /home/h.baker@hertie-school.lan/workspace/llm-efficiency-measurement-tool && python -m pytest tests/unit/test_docker_errors.py -x -v</automated>
  </verify>
  <done>
    - DockerError hierarchy is importable from exceptions.py and infra/docker_errors.py
    - translate_docker_error() categorises all 5 error types + fallback
    - Every error includes a fix_suggestion string
    - All tests pass
  </done>
</task>

<task type="auto">
  <name>Task 2: Container entrypoint and built-in image registry</name>
  <files>
    src/llenergymeasure/infra/container_entrypoint.py
    src/llenergymeasure/infra/image_registry.py
    tests/unit/test_container_entrypoint.py
    tests/unit/test_image_registry.py
  </files>
  <action>
    1. Create `infra/container_entrypoint.py` (DOCK-11: library API, not CLI re-entry):
       - `run_container_experiment(config_path: Path, result_dir: Path) -> Path`:
         - Reads `config_path` as JSON, validates into `ExperimentConfig`
         - Computes `config_hash = compute_measurement_config_hash(config)`
         - Runs the experiment using the core/backends path (same path as StudyRunner worker):
           ```python
           from llenergymeasure.core.backends import get_backend
           from llenergymeasure.orchestration.preflight import run_preflight
           run_preflight(config)
           backend = get_backend(config.backend)
           result = backend.run(config)
           ```
         - Writes result as JSON to `result_dir / f"{config_hash}_result.json"`
         - Returns path to result file
       - `main()` function that reads `LLEM_CONFIG_PATH` env var, determines result dir (parent of config file = `/run/llem`), calls `run_container_experiment`, and handles errors (writes error JSON on failure for host to read).
       - Error JSON format on failure: `{"type": "...", "message": "...", "traceback": "..."}` — same format as StudyRunner worker error payloads.
       - Module-level `if __name__ == "__main__": main()` for direct invocation.

    2. Create `infra/image_registry.py`:
       - `DEFAULT_IMAGES: dict[str, str]` mapping backend to default image tag:
         ```python
         DEFAULT_IMAGES = {
             "pytorch": "ghcr.io/llenergymeasure/pytorch:{version}-cuda{cuda_major}",
             "vllm": "ghcr.io/llenergymeasure/vllm:{version}-cuda{cuda_major}",
             "tensorrt": "ghcr.io/llenergymeasure/tensorrt:{version}-cuda{cuda_major}",
         }
         ```
       - `get_cuda_major_version() -> str | None`: detect CUDA major version from `nvcc --version` output (or pynvml), return e.g. "12". Returns None if not detectable.
       - `get_default_image(backend: str) -> str`: resolve template with current package version and CUDA version. Falls back to "latest" if CUDA version unknown.
       - `parse_runner_value(value: str) -> tuple[str, str | None]`: parse "docker" → ("docker", None) or "docker:custom/image:tag" → ("docker", "custom/image:tag"). Returns ("local", None) for "local".

    3. Create `tests/unit/test_container_entrypoint.py`:
       - Test `run_container_experiment` with a mocked backend: writes config JSON to tmpdir, calls function, asserts result JSON written with config_hash naming.
       - Test error handling: simulated backend failure writes error JSON.
       - Test `main()` reads LLEM_CONFIG_PATH env var.

    4. Create `tests/unit/test_image_registry.py`:
       - Test `get_default_image("vllm")` returns well-formed image string
       - Test `parse_runner_value("docker")` returns ("docker", None)
       - Test `parse_runner_value("docker:custom/img:v1")` returns ("docker", "custom/img:v1")
       - Test `parse_runner_value("local")` returns ("local", None)
       - Test `get_cuda_major_version()` with mocked subprocess output
  </action>
  <verify>
    <automated>cd /home/h.baker@hertie-school.lan/workspace/llm-efficiency-measurement-tool && python -m pytest tests/unit/test_container_entrypoint.py tests/unit/test_image_registry.py -x -v</automated>
  </verify>
  <done>
    - Container entrypoint reads ExperimentConfig JSON, runs via library API (not CLI), writes result JSON
    - Image registry resolves backend name to Docker image with version/CUDA tags
    - parse_runner_value correctly parses "local", "docker", and "docker:image" forms
    - Error payloads match StudyRunner worker format
    - All tests pass
  </done>
</task>

</tasks>

<verification>
```bash
cd /home/h.baker@hertie-school.lan/workspace/llm-efficiency-measurement-tool

# All new tests pass
python -m pytest tests/unit/test_docker_errors.py tests/unit/test_container_entrypoint.py tests/unit/test_image_registry.py -x -v

# No regression in full suite
python -m pytest tests/unit/ -x --timeout=120

# Type check
python -m mypy src/llenergymeasure/infra/docker_errors.py src/llenergymeasure/infra/container_entrypoint.py src/llenergymeasure/infra/image_registry.py --ignore-missing-imports

# Lint
python -m ruff check src/llenergymeasure/infra/
```
</verification>

<success_criteria>
- DockerError hierarchy with 5 categorised subclasses and fix suggestions
- translate_docker_error() maps container stderr to appropriate error type
- Container entrypoint runs experiments via library API (ExperimentOrchestrator path, not CLI re-entry) — DOCK-11
- Config read from JSON at LLEM_CONFIG_PATH, result written to volume — DOCK-02, DOCK-03
- Built-in image registry resolves backend → Docker image with version + CUDA tags
- parse_runner_value() handles "local", "docker", "docker:image" forms
- All tests pass, no regressions
</success_criteria>

<output>
After completion, create `.planning/phases/17-docker-runner-infrastructure/17-01-SUMMARY.md`
</output>
