---
phase: 02.1-zero-config-install
plan: 05
type: execute
wave: 4
depends_on: ["02.1-01", "02.1-02", "02.1-03", "02.1-04", "02.1-06"]
files_modified:
  - tests/unit/test_docker_detection.py
  - tests/unit/test_backend_detection.py
  - tests/unit/test_env_setup.py
autonomous: false

must_haves:
  truths:
    - "Unit tests cover docker detection (inside/outside Docker scenarios)"
    - "Unit tests cover backend detection (available/unavailable backends)"
    - "Unit tests cover .env generation (create when missing, skip when exists)"
    - "All existing tests still pass"
    - "User verifies lem backend list and lem docker status work correctly"
  artifacts:
    - path: "tests/unit/test_docker_detection.py"
      provides: "Unit tests for docker_detection module"
      min_lines: 30
    - path: "tests/unit/test_backend_detection.py"
      provides: "Unit tests for backend_detection module"
      min_lines: 30
    - path: "tests/unit/test_env_setup.py"
      provides: "Unit tests for env_setup module"
      min_lines: 30
  key_links:
    - from: "tests/unit/test_docker_detection.py"
      to: "src/llenergymeasure/config/docker_detection.py"
      via: "imports and tests public functions"
      pattern: "from llenergymeasure.config.docker_detection import"
    - from: "tests/unit/test_backend_detection.py"
      to: "src/llenergymeasure/config/backend_detection.py"
      via: "imports and tests public functions"
      pattern: "from llenergymeasure.config.backend_detection import"
    - from: "tests/unit/test_env_setup.py"
      to: "src/llenergymeasure/config/env_setup.py"
      via: "imports and tests public functions"
      pattern: "from llenergymeasure.config.env_setup import"
---

<objective>
Write unit tests for the three detection/env modules and verify the full Phase 2.1 install experience end-to-end.

Purpose: Ensure detection logic is correct under various scenarios (mocked Docker, mocked backends, mocked filesystem) and that the user-facing CLI commands work as expected.

Output: Three test files, all tests passing, user-verified CLI commands.
</objective>

<execution_context>
@/home/h.baker@hertie-school.lan/.claude/get-shit-done/workflows/execute-plan.md
@/home/h.baker@hertie-school.lan/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/phases/02.1-zero-config-install/02.1-CONTEXT.md
@tests/CLAUDE.md
@src/llenergymeasure/config/docker_detection.py
@src/llenergymeasure/config/backend_detection.py
@src/llenergymeasure/config/env_setup.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Unit tests for detection and env modules</name>
  <files>tests/unit/test_docker_detection.py, tests/unit/test_backend_detection.py, tests/unit/test_env_setup.py</files>
  <action>
**test_docker_detection.py:**
- `test_is_inside_docker_false_on_host`: Mock `Path("/.dockerenv").exists()` to False, mock `/proc/1/cgroup` read to raise FileNotFoundError → returns False
- `test_is_inside_docker_true_dockerenv`: Mock `Path("/.dockerenv").exists()` to True → returns True
- `test_is_inside_docker_true_cgroup`: Mock /.dockerenv False, mock /proc/1/cgroup content with "docker" → returns True
- `test_should_use_docker_inside_container`: Mock `is_inside_docker` to True → returns False (no nested Docker)
- `test_should_use_docker_single_backend_available`: Mock not inside Docker, mock `is_backend_available("pytorch")` True → returns False (run locally)
- `test_should_use_docker_multi_backend`: Mock not inside Docker → returns True (multi-backend needs Docker)
- `test_should_use_docker_single_backend_unavailable`: Mock not inside Docker, mock `is_backend_available("vllm")` False → returns True (need Docker)

Use `unittest.mock.patch` for mocking Path.exists(), Path.read_text(), and imported functions.

**test_backend_detection.py:**
- `test_known_backends_list`: Verify KNOWN_BACKENDS contains pytorch, vllm, tensorrt
- `test_is_backend_available_pytorch`: If torch is installed (likely in dev env), returns True
- `test_is_backend_available_unknown`: `is_backend_available("nonexistent")` returns False
- `test_get_available_backends`: Returns list, pytorch should be in it if torch installed
- `test_get_backend_install_hint_vllm`: Returns `pip install llenergymeasure[vllm]`
- `test_get_backend_install_hint_unknown`: Returns reasonable string for unknown backend

**test_env_setup.py:**
- `test_ensure_env_file_creates_when_missing`: Use `tmp_path` fixture, call `ensure_env_file(tmp_path)` → .env file created with PUID/PGID
- `test_ensure_env_file_skips_when_exists`: Create .env in tmp_path first, call `ensure_env_file(tmp_path)` → file unchanged (not overwritten)
- `test_ensure_env_file_content_format`: Check generated .env contains `PUID=` and `PGID=` lines
- `test_ensure_env_file_infers_project_root`: Mock cwd to a directory containing pyproject.toml → infers root correctly

Follow existing test patterns in tests/unit/. Use pytest fixtures (`tmp_path`). Import from `llenergymeasure.config.*`.
  </action>
  <verify>
```bash
pytest tests/unit/test_docker_detection.py tests/unit/test_backend_detection.py tests/unit/test_env_setup.py -v
```
All tests pass.
  </verify>
  <done>
All unit tests pass. Coverage of key scenarios: Docker detection (inside/outside), backend availability (present/absent), .env generation (create/skip).
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>
Phase 2.1 complete: Zero-config install experience with:
- Detection modules (docker_detection, backend_detection, env_setup)
- CLI subcommands (lem docker setup/status/build, lem backend list)
- Campaign refactor (_should_use_docker uses proper detection + ensure_env_file wired)
- Packaging (PyTorch in core deps, setup.sh deleted)
- Documentation refresh (three-path install story)
- Unit tests for all detection modules
- PyPI packaging validated (wheel builds and installs cleanly)
  </what-built>
  <how-to-verify>
1. Run `lem --help` — confirm docker and backend subcommands appear
2. Run `lem backend list` — confirm shows ✓ pytorch (installed) and other backends
3. Run `lem docker status` — confirm shows Docker readiness checklist
4. Run `pip install -e .` — confirm installs without needing [pytorch] extra
5. Run existing tests: `pytest tests/unit/ -v` — confirm no regressions
6. Check `README.md` — confirm three-path install story, no setup.sh references
7. Check `ls setup.sh` — confirm deleted
  </how-to-verify>
  <resume-signal>Type "approved" or describe issues to fix</resume-signal>
</task>

</tasks>

<verification>
```bash
# All new tests pass
pytest tests/unit/test_docker_detection.py tests/unit/test_backend_detection.py tests/unit/test_env_setup.py -v

# No regression in existing tests
pytest tests/unit/ -v

# CLI commands work
lem backend list
lem docker status

# No setup.sh references anywhere
grep -r 'setup.sh' README.md docs/ Makefile src/ | grep -v '.planning' | wc -l  # 0

# Ruff clean
ruff check src/llenergymeasure/config/docker_detection.py src/llenergymeasure/config/backend_detection.py src/llenergymeasure/config/env_setup.py src/llenergymeasure/cli/docker.py src/llenergymeasure/cli/backend.py src/llenergymeasure/cli/campaign.py
```
</verification>

<success_criteria>
- All 3 test files exist with comprehensive test cases
- All tests pass (new + existing)
- User verifies CLI commands work as expected
- Full Phase 2.1 install experience validated
</success_criteria>

<output>
After completion, create `.planning/phases/02.1-zero-config-install/02.1-05-SUMMARY.md`
</output>
