---
phase: 02-config-system
plan: 03
type: execute
wave: 2
depends_on: [02-01]
files_modified:
  - src/llenergymeasure/config/user_config.py
autonomous: true
requirements: [CFG-23, CFG-24, CFG-25, CFG-26]

must_haves:
  truths:
    - "~/.config/llenergymeasure/config.yaml is read on startup — missing file applies all defaults with no error"
    - "Invalid user config raises ConfigError with field path context — same treatment as bad experiment YAML"
    - "User config schema covers researcher workflow preferences only — output paths, runners, measurement settings, UI prefs, execution gaps"
    - "Environment variable overrides (LLEM_RUNNER_PYTORCH etc.) sit above user config in precedence"
  artifacts:
    - path: "src/llenergymeasure/config/user_config.py"
      provides: "UserConfig Pydantic model with XDG path via platformdirs, env var override layer, load_user_config()"
      exports: ["UserConfig", "load_user_config", "get_user_config_path"]
  key_links:
    - from: "src/llenergymeasure/config/user_config.py"
      to: "src/llenergymeasure/exceptions.py"
      via: "raise ConfigError(...)"
      pattern: "raise ConfigError"
---

<objective>
Rewrite user_config.py with the correct XDG path, v2.0 schema (runner mappings, measurement settings, execution gaps), and env var override layer.

Purpose: User config sets machine-local defaults that make the same experiment YAML run correctly on a laptop, workstation, or HPC cluster without touching the experiment file.
Output: UserConfig Pydantic model + load_user_config() that loads from ~/.config/llenergymeasure/config.yaml via platformdirs.
</objective>

<execution_context>
@/home/h.baker@hertie-school.lan/.claude/get-shit-done/workflows/execute-plan.md
@/home/h.baker@hertie-school.lan/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/phases/02-config-system/02-CONTEXT.md
@.planning/phases/02-config-system/02-01-SUMMARY.md
@.product/designs/user-config.md

<interfaces>
<!-- From .product/designs/user-config.md — canonical user config schema -->

User config path: ~/.config/llenergymeasure/config.yaml
Implementation: Path(user_config_dir("llenergymeasure")) / "config.yaml"
(platformdirs.user_config_dir is already used in Phase 1 for state dir)

Schema decisions (from .product/designs/user-config.md):
- output.results_dir: str = "./results"
- output.model_cache_dir: str = "~/.cache/huggingface"
- runners.pytorch: str = "local"      # "local" | "docker:<image>"
- runners.vllm: str = "local"
- runners.tensorrt: str = "local"
- measurement.energy_backend: Literal["auto", "nvml", "zeus"] = "auto"
- measurement.carbon_intensity_gco2_kwh: float | None = None
- measurement.datacenter_pue: float = 1.0
- ui.verbosity: Literal["quiet", "standard", "verbose"] = "standard"
- ui.prompt: bool = True             # False for CI/HPC batch jobs
- advanced.nvml_poll_interval_ms: int = 100
- execution.config_gap_seconds: float = 60.0   # machine-local thermal gap default
- execution.cycle_gap_seconds: float = 300.0

From exceptions.py:
class ConfigError(LLEMError): ...

Env vars (from .product/designs/user-config.md):
LLEM_RUNNER_PYTORCH=local|docker:<image>
LLEM_RUNNER_VLLM=local|docker:<image>
LLEM_RUNNER_TENSORRT=local|docker:<image>
LLEM_CARBON_INTENSITY=<float>
LLEM_DATACENTER_PUE=<float>
LLEM_NO_PROMPT=1
</interfaces>
</context>

<tasks>

<task type="auto">
  <name>Task 1: Rewrite UserConfig and load_user_config</name>
  <files>src/llenergymeasure/config/user_config.py</files>
  <action>
Rewrite user_config.py from scratch with the v2.0 schema. Remove all v1.x content (ThermalGapConfig, DockerConfig, NotificationsConfig — wrong schema; wrong path `.lem-config.yaml` in cwd).

**Nested model classes (all with extra="forbid"):**

```python
class UserOutputConfig(BaseModel):
    model_config = {"extra": "forbid"}
    results_dir: str = Field(default="./results", description="Default results output location")
    model_cache_dir: str = Field(default="~/.cache/huggingface", description="HuggingFace model cache")

class UserRunnersConfig(BaseModel):
    model_config = {"extra": "forbid"}
    pytorch: str = Field(default="local", description="PyTorch runner: 'local' or 'docker:<image>'")
    vllm: str = Field(default="local", description="vLLM runner: 'local' or 'docker:<image>'")
    tensorrt: str = Field(default="local", description="TensorRT runner: 'local' or 'docker:<image>'")

    @model_validator(mode="after")
    def validate_runner_format(self) -> "UserRunnersConfig":
        for field_name in ("pytorch", "vllm", "tensorrt"):
            value = getattr(self, field_name)
            if value != "local" and not value.startswith("docker:"):
                raise ValueError(
                    f"runners.{field_name}: expected 'local' or 'docker:<image>', got '{value}'"
                )
            if value.startswith("singularity:"):
                raise NotImplementedError(
                    f"Singularity runner not yet supported (runners.{field_name}='{value}'). "
                    "Use 'local' or 'docker:<image>'."
                )
        return self

class UserMeasurementConfig(BaseModel):
    model_config = {"extra": "forbid"}
    energy_backend: Literal["auto", "nvml", "zeus"] = Field(default="auto", description="Energy backend: auto=zeus if installed else nvml")
    carbon_intensity_gco2_kwh: float | None = Field(default=None, ge=0.0, description="gCO2/kWh for local electricity grid")
    datacenter_pue: float = Field(default=1.0, ge=1.0, description="Power Usage Effectiveness")

class UserUIConfig(BaseModel):
    model_config = {"extra": "forbid"}
    verbosity: Literal["quiet", "standard", "verbose"] = Field(default="standard")
    prompt: bool = Field(default=True, description="Enable interactive prompts (False for CI/HPC)")

class UserAdvancedConfig(BaseModel):
    model_config = {"extra": "forbid"}
    nvml_poll_interval_ms: int = Field(default=100, ge=10, le=10000, description="NVML sampling interval")

class UserExecutionConfig(BaseModel):
    model_config = {"extra": "forbid"}
    config_gap_seconds: float = Field(default=60.0, ge=0.0, description="Thermal gap between experiments")
    cycle_gap_seconds: float = Field(default=300.0, ge=0.0, description="Thermal gap between cycles")
```

**UserConfig (top-level):**
```python
class UserConfig(BaseModel):
    model_config = {"extra": "forbid"}
    output: UserOutputConfig = Field(default_factory=UserOutputConfig)
    runners: UserRunnersConfig = Field(default_factory=UserRunnersConfig)
    measurement: UserMeasurementConfig = Field(default_factory=UserMeasurementConfig)
    ui: UserUIConfig = Field(default_factory=UserUIConfig)
    advanced: UserAdvancedConfig = Field(default_factory=UserAdvancedConfig)
    execution: UserExecutionConfig = Field(default_factory=UserExecutionConfig)
```

**get_user_config_path() function:**
```python
def get_user_config_path() -> Path:
    """Return the XDG-compliant user config path.
    Linux:   ~/.config/llenergymeasure/config.yaml
    macOS:   ~/Library/Application Support/llenergymeasure/config.yaml
    Windows: %APPDATA%\\llenergymeasure\\config.yaml
    """
    from platformdirs import user_config_dir
    return Path(user_config_dir("llenergymeasure")) / "config.yaml"
```

**_apply_env_overrides() helper:**
```python
def _apply_env_overrides(config: UserConfig) -> UserConfig:
    """Apply LLEM_* environment variable overrides to user config.

    Env vars sit above config file and below CLI flags in precedence.
    Returns updated UserConfig (Pydantic models are immutable; use model_copy).
    """
    import os

    runners_updates: dict[str, str] = {}
    for backend in ("pytorch", "vllm", "tensorrt"):
        env_key = f"LLEM_RUNNER_{backend.upper()}"
        if (val := os.environ.get(env_key)):
            runners_updates[backend] = val

    measurement_updates: dict[str, Any] = {}
    if (val := os.environ.get("LLEM_CARBON_INTENSITY")):
        try:
            measurement_updates["carbon_intensity_gco2_kwh"] = float(val)
        except ValueError:
            pass  # Invalid env var value — silently ignore (same as not set)
    if (val := os.environ.get("LLEM_DATACENTER_PUE")):
        try:
            measurement_updates["datacenter_pue"] = float(val)
        except ValueError:
            pass

    ui_updates: dict[str, Any] = {}
    if os.environ.get("LLEM_NO_PROMPT"):
        ui_updates["prompt"] = False

    # Apply updates using model_copy(update=...) for immutable Pydantic models
    new_runners = config.runners.model_copy(update=runners_updates) if runners_updates else config.runners
    new_measurement = config.measurement.model_copy(update=measurement_updates) if measurement_updates else config.measurement
    new_ui = config.ui.model_copy(update=ui_updates) if ui_updates else config.ui

    if runners_updates or measurement_updates or ui_updates:
        return config.model_copy(update={
            "runners": new_runners,
            "measurement": new_measurement,
            "ui": new_ui,
        })
    return config
```

**load_user_config() function:**
```python
def load_user_config(config_path: Path | None = None) -> UserConfig:
    """Load user configuration from ~/.config/llenergymeasure/config.yaml.

    Missing file: silently applies all defaults — no error.
    Invalid YAML: raises ConfigError with parse error detail.
    Invalid schema: raises ConfigError with field path context.

    Args:
        config_path: Explicit path override (for testing). None = XDG default.

    Returns:
        UserConfig with file values merged over defaults, env vars applied on top.
    """
    from llenergymeasure.exceptions import ConfigError

    path = config_path or get_user_config_path()

    if not path.exists():
        # Missing file — zero-config, apply all defaults + env var overrides
        return _apply_env_overrides(UserConfig())

    try:
        content = path.read_text()
        data = yaml.safe_load(content) or {}
        if not isinstance(data, dict):
            raise ConfigError(f"User config must be a YAML mapping: {path}")
    except yaml.YAMLError as e:
        raise ConfigError(f"Invalid YAML in user config {path}: {e}") from e

    try:
        config = UserConfig.model_validate(data)
    except ValidationError as e:
        # Format Pydantic errors as ConfigError with field paths for researcher clarity
        errors = [f"  {err['loc']}: {err['msg']}" for err in e.errors()]
        raise ConfigError(
            f"Invalid user config {path}:\n" + "\n".join(errors)
        ) from e

    return _apply_env_overrides(config)
```

**__all__:**
```python
__all__ = ["UserConfig", "load_user_config", "get_user_config_path"]
```
  </action>
  <verify>
    <automated>cd /home/h.baker@hertie-school.lan/workspace/llm-efficiency-measurement-tool && python -c "
import os, tempfile
from pathlib import Path
from llenergymeasure.config.user_config import UserConfig, load_user_config, get_user_config_path
from llenergymeasure.exceptions import ConfigError

# Default config path is XDG-compliant
p = get_user_config_path()
assert 'llenergymeasure' in str(p), f'Expected llenergymeasure in path, got {p}'
assert p.name == 'config.yaml'

# Missing file returns defaults, no error
cfg = load_user_config(Path('/nonexistent/llenergymeasure/config.yaml'))
assert cfg.runners.pytorch == 'local'
assert cfg.measurement.energy_backend == 'auto'
assert cfg.execution.config_gap_seconds == 60.0

# Valid config loads
import yaml
with tempfile.NamedTemporaryFile(mode='w', suffix='.yaml', delete=False) as f:
    yaml.dump({'measurement': {'carbon_intensity_gco2_kwh': 350.0}}, f)
    p2 = Path(f.name)
cfg2 = load_user_config(p2)
assert cfg2.measurement.carbon_intensity_gco2_kwh == 350.0

# Invalid config raises ConfigError
with tempfile.NamedTemporaryFile(mode='w', suffix='.yaml', delete=False) as f:
    yaml.dump({'runners': {'pytorch': 'invalid_format'}}, f)
    p3 = Path(f.name)
try:
    load_user_config(p3)
    assert False, 'Should have raised'
except ConfigError:
    pass

# Env var overrides
os.environ['LLEM_NO_PROMPT'] = '1'
cfg3 = load_user_config(Path('/nonexistent/llenergymeasure/config.yaml'))
assert cfg3.ui.prompt == False
del os.environ['LLEM_NO_PROMPT']

print('All checks passed')
"</automated>
  </verify>
  <done>get_user_config_path() returns XDG path with 'llenergymeasure' in it; missing config returns defaults with no error; valid config file loads correctly; invalid schema raises ConfigError; LLEM_NO_PROMPT=1 sets ui.prompt=False</done>
</task>

</tasks>

<verification>
```bash
cd /home/h.baker@hertie-school.lan/workspace/llm-efficiency-measurement-tool
python -c "
from llenergymeasure.config.user_config import UserConfig, load_user_config, get_user_config_path, __all__
assert 'UserConfig' in __all__
assert 'load_user_config' in __all__
assert 'get_user_config_path' in __all__

# All sub-configs have extra=forbid
from pydantic import ValidationError
try:
    from llenergymeasure.config.user_config import UserRunnersConfig
    UserRunnersConfig(pytorch='local', unknown_field=1)
    assert False
except ValidationError:
    pass
print('UserConfig checks passed')
"
```
</verification>

<success_criteria>
- `get_user_config_path()` returns a Path containing `llenergymeasure/config.yaml` (XDG-compliant)
- `load_user_config(nonexistent_path)` returns `UserConfig()` with defaults, no exception
- `load_user_config(valid_yaml)` merges YAML values over defaults
- `load_user_config(invalid_schema_yaml)` raises `ConfigError` (not `ValidationError`)
- `LLEM_NO_PROMPT=1` in env → `ui.prompt == False` in returned config
- `LLEM_RUNNER_PYTORCH=docker:some/image` in env → `runners.pytorch == "docker:some/image"`
</success_criteria>

<output>
After completion, create `.planning/phases/02-config-system/02-03-SUMMARY.md`
</output>
