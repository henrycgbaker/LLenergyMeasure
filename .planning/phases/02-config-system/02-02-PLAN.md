---
phase: 02-config-system
plan: 02
type: execute
wave: 2
depends_on: [02-01]
files_modified:
  - src/llenergymeasure/config/loader.py
autonomous: true
requirements: [CFG-07, CFG-18, CFG-19, CFG-20, CFG-21, CFG-22]

must_haves:
  truths:
    - "A valid experiment YAML loads into ExperimentConfig without error"
    - "An invalid YAML raises ConfigError with file path context and all errors collected at once"
    - "Pydantic ValidationError passes through unchanged — not wrapped in ConfigError"
    - "Unknown top-level YAML keys raise ConfigError with did-you-mean suggestion"
    - "load_experiment_config(path, cli_overrides) merges CLI overrides at highest priority"
    - "YAML anchors (&/*) work natively — no custom _extends inheritance logic"
  artifacts:
    - path: "src/llenergymeasure/config/loader.py"
      provides: "YAML loader with collect-all-errors, ConfigError, did-you-mean, CLI override merging"
      exports: ["load_experiment_config", "deep_merge"]
  key_links:
    - from: "src/llenergymeasure/config/loader.py"
      to: "src/llenergymeasure/config/models.py"
      via: "ExperimentConfig(**merged_dict)"
      pattern: "ExperimentConfig\\("
    - from: "src/llenergymeasure/config/loader.py"
      to: "src/llenergymeasure/exceptions.py"
      via: "raise ConfigError(...)"
      pattern: "raise ConfigError"
---

<objective>
Rewrite loader.py to the v2.0 loading contract: collect-all-errors, ConfigError with file path + did-you-mean, CLI override merging, and native YAML anchor support.

Purpose: The YAML loader is the primary entry point for experiment configs. Researchers must see all validation errors at once (not one at a time) and get helpful error messages.
Output: loader.py with a clean `load_experiment_config()` function that the CLI (Phase 7) and library API (Phase 3) can call.
</objective>

<execution_context>
@/home/h.baker@hertie-school.lan/.claude/get-shit-done/workflows/execute-plan.md
@/home/h.baker@hertie-school.lan/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/phases/02-config-system/02-CONTEXT.md
@.planning/phases/02-config-system/02-01-SUMMARY.md

<interfaces>
<!-- Contracts from Plan 01 output (02-01-PLAN.md) -->

From src/llenergymeasure/config/models.py (v2.0):
```python
class ExperimentConfig(BaseModel):
    model_config = {"extra": "forbid"}
    model: str                              # required
    backend: Literal["pytorch", "vllm", "tensorrt"] = "pytorch"
    precision: Literal["fp32", "fp16", "bf16"] = "bf16"
    n: int = 100
    # ... etc, see 02-01-PLAN.md
```

From src/llenergymeasure/exceptions.py:
```python
class LLEMError(Exception): ...
class ConfigError(LLEMError): ...
```

<!-- Decisions from CONTEXT.md -->
- Error format: ConfigError includes field name + file path + did-you-mean (Levenshtein)
- Collect ALL errors before raising — not one at a time
- Priority: CLI flags > experiment YAML > user config defaults
- Forward-compatible: load_experiment_config accepts cli_overrides dict even though CLI is Phase 7
- Drop _extends inheritance — support native YAML anchors only
- Optional version: "2.0" field — ignored gracefully if present
- ConfigError is FATAL — always — no "continue with warnings" mode
</interfaces>
</context>

<tasks>

<task type="auto">
  <name>Task 1: Rewrite loader.py with v2.0 loading contract</name>
  <files>src/llenergymeasure/config/loader.py</files>
  <action>
Rewrite loader.py completely. The public API is `load_experiment_config()`. Keep `deep_merge()` as it is correct. Remove everything else (resolve_inheritance, load_config, validate_config, load_config_with_provenance, provenance tracking).

**Public API:**
```python
def load_experiment_config(
    path: Path | str | None = None,
    cli_overrides: dict[str, Any] | None = None,
    user_config_defaults: dict[str, Any] | None = None,
) -> ExperimentConfig:
    """Load and validate experiment configuration.

    Priority (highest wins): cli_overrides > path YAML > user_config_defaults

    Args:
        path: Path to YAML or JSON config file. None = only CLI/defaults.
        cli_overrides: Dict of CLI flag overrides (e.g. {"model": "gpt2", "backend": "pytorch"}).
            Keys match ExperimentConfig field names. None values are ignored (unset flags).
        user_config_defaults: Dict of user config defaults to apply as lowest priority.
            Only fields valid on ExperimentConfig (e.g. output_dir, backend defaults).

    Returns:
        Validated ExperimentConfig.

    Raises:
        ConfigError: File not found, parse error, unknown fields, or structural validation failure.
            Includes all errors collected at once (not one-at-a-time).
        ValidationError: Pydantic field-level validation errors pass through unchanged.
            (Bad values like n=-1 are Pydantic's domain; unknown keys become ConfigError.)
    """
```

**Implementation details:**

1. **Build merged dict:**
```python
# Start with user config defaults (lowest priority)
merged: dict[str, Any] = {}
if user_config_defaults:
    merged = deep_merge(merged, {k: v for k, v in user_config_defaults.items() if v is not None})

# Load and apply YAML/JSON file
if path is not None:
    file_dict = _load_file(path)  # raises ConfigError on missing/parse error
    merged = deep_merge(merged, file_dict)

# Apply CLI overrides (highest priority, skip None values)
if cli_overrides:
    overrides = {k: v for k, v in cli_overrides.items() if v is not None}
    merged = deep_merge(merged, _unflatten(overrides))  # handle "pytorch.batch_size" dotted keys
```

2. **Strip version field** before validation (optional `version:` key, not an ExperimentConfig field):
```python
merged.pop("version", None)  # optional YAML version field — not in ExperimentConfig schema
```

3. **Collect unknown field errors** before handing to Pydantic:
```python
known_fields = set(ExperimentConfig.model_fields.keys())
unknown = set(merged.keys()) - known_fields
if unknown:
    errors = []
    for key in sorted(unknown):
        suggestion = _did_you_mean(key, known_fields)
        msg = f"Unknown field '{key}'"
        if suggestion:
            msg += f" — did you mean '{suggestion}'?"
        if path:
            msg += f" (in {path})"
        errors.append(msg)
    raise ConfigError("\n".join(errors))
```

4. **Construct ExperimentConfig — let ValidationError pass through:**
```python
try:
    return ExperimentConfig(**merged)
except ValidationError:
    raise  # Pass through unchanged — not our domain to wrap
except Exception as e:
    context = f" (in {path})" if path else ""
    raise ConfigError(f"Config construction failed{context}: {e}") from e
```

**_load_file() helper:**
```python
def _load_file(path: Path | str) -> dict[str, Any]:
    path = Path(path)
    if not path.exists():
        raise ConfigError(f"Config file not found: {path}")
    try:
        content = path.read_text()
        if path.suffix in (".yaml", ".yml"):
            result = yaml.safe_load(content)  # native YAML anchors handled automatically
        elif path.suffix == ".json":
            result = json.loads(content)
        else:
            raise ConfigError(f"Unsupported config format '{path.suffix}': use .yaml or .json")
        if not isinstance(result, dict):
            raise ConfigError(f"Config must be a mapping (got {type(result).__name__}): {path}")
        return result
    except (yaml.YAMLError, json.JSONDecodeError) as e:
        raise ConfigError(f"Parse error in {path}: {e}") from e
```

**_did_you_mean() helper (Levenshtein-based):**
```python
def _did_you_mean(key: str, candidates: set[str], max_distance: int = 3) -> str | None:
    """Return the closest candidate if within max_distance edits, else None."""
    best: str | None = None
    best_dist = max_distance + 1
    for candidate in candidates:
        dist = _levenshtein(key, candidate)
        if dist < best_dist:
            best_dist = dist
            best = candidate
    return best if best_dist <= max_distance else None

def _levenshtein(a: str, b: str) -> int:
    """Compute Levenshtein distance between two strings."""
    if len(a) < len(b):
        return _levenshtein(b, a)
    if not b:
        return len(a)
    prev = list(range(len(b) + 1))
    for i, ca in enumerate(a):
        curr = [i + 1]
        for j, cb in enumerate(b):
            curr.append(min(prev[j + 1] + 1, curr[j] + 1, prev[j] + (ca != cb)))
        prev = curr
    return prev[-1]
```

**_unflatten() helper** (for dotted CLI keys like "pytorch.batch_size"):
```python
def _unflatten(flat: dict[str, Any]) -> dict[str, Any]:
    """Expand dotted keys into nested dicts. Non-dotted keys pass through."""
    result: dict[str, Any] = {}
    for key, value in flat.items():
        if "." in key:
            parts = key.split(".", 1)
            if parts[0] not in result:
                result[parts[0]] = {}
            if isinstance(result[parts[0]], dict):
                result[parts[0]][parts[1]] = value
        else:
            result[key] = value
    return result
```

**Keep deep_merge() as-is** — it's correct.

**Remove from the file:**
- `resolve_inheritance()` and `_extends` logic — dropped per CONTEXT.md decision
- `validate_config()` and `ConfigWarning` usage — no warnings mode, errors only
- `has_blocking_warnings()`
- `get_pydantic_defaults()`
- `load_config_with_provenance()` and all provenance tracking
- `load_config()` (replaced by `load_experiment_config()`)

**Module-level __all__:**
```python
__all__ = ["load_experiment_config", "deep_merge"]
```
  </action>
  <verify>
    <automated>cd /home/h.baker@hertie-school.lan/workspace/llm-efficiency-measurement-tool && python -c "
from pathlib import Path
import tempfile, yaml
from llenergymeasure.config.loader import load_experiment_config
from llenergymeasure.exceptions import ConfigError
from pydantic import ValidationError

# Valid YAML loads cleanly
with tempfile.NamedTemporaryFile(mode='w', suffix='.yaml', delete=False) as f:
    yaml.dump({'model': 'gpt2', 'backend': 'pytorch', 'n': 50}, f)
    p = Path(f.name)
cfg = load_experiment_config(p)
assert cfg.model == 'gpt2'
assert cfg.n == 50

# Unknown field raises ConfigError (not ValidationError)
with tempfile.NamedTemporaryFile(mode='w', suffix='.yaml', delete=False) as f:
    yaml.dump({'model': 'gpt2', 'modell': 'typo'}, f)
    p2 = Path(f.name)
try:
    load_experiment_config(p2)
    assert False
except ConfigError as e:
    assert 'did you mean' in str(e).lower() or 'unknown field' in str(e).lower()

# CLI overrides take precedence
with tempfile.NamedTemporaryFile(mode='w', suffix='.yaml', delete=False) as f:
    yaml.dump({'model': 'gpt2', 'n': 50}, f)
    p3 = Path(f.name)
cfg2 = load_experiment_config(p3, cli_overrides={'n': 200})
assert cfg2.n == 200

# Missing file raises ConfigError
try:
    load_experiment_config(Path('/nonexistent/path.yaml'))
    assert False
except ConfigError:
    pass

print('All checks passed')
"</automated>
  </verify>
  <done>load_experiment_config(valid_yaml) returns ExperimentConfig; unknown fields raise ConfigError with did-you-mean; CLI overrides override YAML values; missing file raises ConfigError with path; Pydantic ValidationError passes through unchanged</done>
</task>

</tasks>

<verification>
```bash
cd /home/h.baker@hertie-school.lan/workspace/llm-efficiency-measurement-tool
python -c "
from llenergymeasure.config.loader import load_experiment_config, deep_merge, __all__
assert 'load_experiment_config' in __all__
assert 'deep_merge' in __all__

# deep_merge still works
merged = deep_merge({'a': 1, 'b': {'c': 2}}, {'b': {'d': 3}})
assert merged == {'a': 1, 'b': {'c': 2, 'd': 3}}
print('Loader checks passed')
"
```
</verification>

<success_criteria>
- `load_experiment_config(valid_yaml_path)` returns `ExperimentConfig`
- `load_experiment_config(bad_yaml_path)` raises `ConfigError` with file path and did-you-mean
- `load_experiment_config(path, cli_overrides={"n": 200})` applies override over YAML value
- Pydantic `ValidationError` (e.g. `n=-1`) passes through unchanged from Pydantic
- YAML anchors (`&anchor`, `*anchor`) work natively (yaml.safe_load handles this)
- `_extends` keys in YAML no longer have special meaning — treated as unknown fields (ConfigError)
</success_criteria>

<output>
After completion, create `.planning/phases/02-config-system/02-02-SUMMARY.md`
</output>
