---
phase: 06-results-schema-and-persistence
plan: 02
type: execute
wave: 2
depends_on: ["06-01"]
files_modified:
  - src/llenergymeasure/results/persistence.py
  - tests/unit/test_persistence_v2.py
autonomous: true
requirements: [RES-16, RES-17, RES-18, RES-19]

must_haves:
  truths:
    - "result.save(output_dir) creates {model}_{backend}_{timestamp}/ subdirectory"
    - "result.save() writes result.json via atomic write (temp + os.replace)"
    - "result.save() copies timeseries.parquet sidecar to output directory when provided"
    - "Collision suffix _1, _2 appended when directory already exists — never overwrites"
    - "ExperimentResult.from_json(path) loads result and auto-discovers timeseries sidecar"
    - "from_json() with missing sidecar loads successfully with warning (graceful degradation)"
    - "Round-trip: ExperimentResult.from_json(result.save(path)) produces identical data"
    - "save() returns the path to result.json"
  artifacts:
    - path: "src/llenergymeasure/results/persistence.py"
      provides: "v2.0 persistence API: save_result(), load_result(), atomic writes, collision handling"
      contains: "def save_result"
    - path: "tests/unit/test_persistence_v2.py"
      provides: "Unit tests for persistence API"
  key_links:
    - from: "src/llenergymeasure/domain/experiment.py"
      to: "src/llenergymeasure/results/persistence.py"
      via: "ExperimentResult.save() delegates to persistence._save_result()"
      pattern: "from llenergymeasure.results.persistence import"
    - from: "src/llenergymeasure/results/persistence.py"
      to: "src/llenergymeasure/domain/experiment.py"
      via: "imports ExperimentResult for load"
      pattern: "from llenergymeasure.domain.experiment import ExperimentResult"
---

<objective>
Create the v2.0 persistence API — result.save(output_dir) and ExperimentResult.from_json(path) — with atomic writes, collision-safe directory creation, timeseries sidecar management, and round-trip guarantee. Add thin save()/from_json() methods on ExperimentResult that delegate to the persistence module.

Purpose: Without persistence, experiments produce results but cannot write them to disk. The persistence API is the bridge between the in-memory ExperimentResult and the on-disk output directory that researchers navigate via `ls results/`.
Output: New results/persistence.py module, save()/from_json() methods on ExperimentResult, comprehensive unit tests.
</objective>

<execution_context>
@/home/h.baker@hertie-school.lan/.claude/get-shit-done/workflows/execute-plan.md
@/home/h.baker@hertie-school.lan/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06-results-schema-and-persistence/06-CONTEXT.md
@.planning/phases/06-results-schema-and-persistence/06-RESEARCH.md
@.planning/phases/06-results-schema-and-persistence/06-01-SUMMARY.md

<interfaces>
<!-- Key types from Plan 01 output -->

From src/llenergymeasure/domain/experiment.py (rewritten in Plan 01):
```python
class ExperimentResult(BaseModel):
    schema_version: str = Field(default="2.0")
    experiment_id: str = Field(...)
    measurement_config_hash: str = Field(...)
    backend: str = Field(default="pytorch")
    measurement_methodology: Literal["total", "steady_state", "windowed"] = Field(...)
    # ... all v2.0 fields ...
    effective_config: dict[str, Any] = Field(default_factory=dict)
    timeseries: str | None = Field(default=None)  # relative filename
    start_time: datetime = Field(...)
    end_time: datetime = Field(...)
    model_config = {"frozen": True}

def compute_measurement_config_hash(config: "ExperimentConfig") -> str: ...

# v1.x compat alias
AggregatedResult = ExperimentResult
```

From src/llenergymeasure/results/timeseries.py (existing, has atomic write pattern):
```python
def _atomic_write_json(data: dict, path: Path) -> None:
    """Write JSON atomically via temp file + os.replace()."""
    tmp_fd, tmp_path = tempfile.mkstemp(dir=path.parent, suffix=".tmp", prefix=path.stem)
    try:
        with os.fdopen(tmp_fd, "w") as f:
            json.dump(data, f, indent=2, default=str)
        os.replace(tmp_path, path)
    except Exception:
        with contextlib.suppress(OSError):
            os.unlink(tmp_path)
        raise
```

From .product/decisions/output-storage.md:
- Directory format: {model_slug}_{backend}_{timestamp}/
- model_slug: HuggingFace ID with / replaced by -, lowercased
- timestamp: ISO 8601 minute-granular (2026-02-18T14-30), colons → hyphens
- Collision: append _1, _2 counter
- Files: result.json + timeseries.parquet
</interfaces>
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create results/persistence.py and wire save()/from_json() onto ExperimentResult</name>
  <files>
    src/llenergymeasure/results/persistence.py
    src/llenergymeasure/domain/experiment.py
  </files>
  <action>
  **Create `src/llenergymeasure/results/persistence.py`:**

  This is a NEW module — the single source of all disk I/O for v2.0 results. `repository.py` (v1.x) stays untouched for backward compat. No inheritance from old patterns.

  ```python
  """v2.0 results persistence — save, load, atomic writes.

  Handles directory lifecycle ({name}_{timestamp}/), collision avoidance,
  JSON serialisation (primary), and Parquet sidecar management.
  """
  from __future__ import annotations

  import contextlib
  import logging
  import os
  import shutil
  import tempfile
  import warnings
  from datetime import datetime
  from pathlib import Path
  from typing import TYPE_CHECKING

  if TYPE_CHECKING:
      from llenergymeasure.domain.experiment import ExperimentResult

  logger = logging.getLogger(__name__)
  ```

  Implement the following functions:

  **1. `_experiment_dir_name(result: ExperimentResult) -> str`**
  Generate `{model_slug}_{backend}_{timestamp}` directory name.
  - `model_slug`: from `result.effective_config.get("model", "unknown")`, replace `/` with `-`, lowercase
  - `backend`: from `result.backend`
  - `timestamp`: `datetime.now().strftime("%Y-%m-%dT%H-%M")`
  - Return the assembled string

  **2. `_find_collision_free_dir(base: Path) -> Path`**
  Return `base` or `base_1`, `base_2`, etc. — never overwrites.
  ```python
  def _find_collision_free_dir(base: Path) -> Path:
      target = base
      counter = 0
      while target.exists():
          counter += 1
          target = Path(f"{base}_{counter}")
      target.mkdir(parents=True)
      return target
  ```

  **3. `_atomic_write(content: str, path: Path) -> None`**
  Write to temp file in same directory, then `os.replace()` to final path (POSIX atomic).
  Reuse the pattern from `results/timeseries.py`:
  ```python
  def _atomic_write(content: str, path: Path) -> None:
      tmp_fd, tmp_path = tempfile.mkstemp(dir=path.parent, suffix=".tmp", prefix=path.stem)
      try:
          with os.fdopen(tmp_fd, "w") as f:
              f.write(content)
          os.replace(tmp_path, path)
      except Exception:
          with contextlib.suppress(OSError):
              os.unlink(tmp_path)
          raise
  ```

  **4. `save_result(result: ExperimentResult, output_dir: Path, timeseries_source: Path | None = None) -> Path`**
  The main save function:
  - Generate directory name via `_experiment_dir_name(result)`
  - Create collision-free directory under `output_dir` via `_find_collision_free_dir()`
  - Write `result.json` via `_atomic_write(result.model_dump_json(indent=2), target / "result.json")`
  - If `timeseries_source` is provided and exists: copy/move it to `target / "timeseries.parquet"`. Use `shutil.copy2` (copy, not move — caller might need the source).
  - Return the path to `result.json`

  **5. `load_result(path: Path) -> ExperimentResult`**
  Load from `result.json` path. Auto-discover timeseries sidecar.
  ```python
  def load_result(path: Path) -> ExperimentResult:
      from llenergymeasure.domain.experiment import ExperimentResult
      content = Path(path).read_text(encoding="utf-8")
      result = ExperimentResult.model_validate_json(content)

      # Graceful sidecar check
      sidecar = Path(path).parent / "timeseries.parquet"
      if result.timeseries is not None and not sidecar.exists():
          warnings.warn(
              f"Timeseries sidecar missing at {sidecar}. "
              "result.timeseries field preserved but file is not present.",
              stacklevel=2,
          )
      return result
  ```

  **Wire `save()` and `from_json()` onto ExperimentResult in `domain/experiment.py`:**

  Add two methods to ExperimentResult. Both use deferred imports to avoid circular dependency (experiment.py imports from metrics.py, persistence.py imports ExperimentResult):

  ```python
  def save(self, output_dir: "Path", timeseries_source: "Path | None" = None) -> "Path":
      """Save result to {output_dir}/{name}_{timestamp}/ directory.

      Returns the path to result.json (for from_json() round-trip).
      """
      from llenergymeasure.results.persistence import save_result
      return save_result(self, output_dir, timeseries_source=timeseries_source)

  @classmethod
  def from_json(cls, path: "Path") -> "ExperimentResult":
      """Load ExperimentResult from result.json path.

      Auto-discovers timeseries.parquet from the same directory.
      If sidecar missing, loads successfully with timeseries=None + emits warning.
      """
      from llenergymeasure.results.persistence import load_result
      return load_result(path)
  ```

  Add `from pathlib import Path` to the existing imports if not already present (it should be — check). Use string annotations for Path type hints on the methods to avoid import issues.
  </action>
  <verify>
    <automated>cd /home/h.baker@hertie-school.lan/workspace/llm-efficiency-measurement-tool && python -c "
from llenergymeasure.results.persistence import save_result, load_result
from llenergymeasure.domain.experiment import ExperimentResult
from pathlib import Path
import tempfile, os
from datetime import datetime

# Build minimal result
r = ExperimentResult(
    experiment_id='test-001',
    measurement_config_hash='abcdef0123456789',
    measurement_methodology='total',
    total_tokens=1000,
    total_energy_j=50.0,
    total_inference_time_sec=10.0,
    avg_tokens_per_second=100.0,
    avg_energy_per_token_j=0.05,
    total_flops=1e12,
    start_time=datetime(2026, 2, 26, 14, 0),
    end_time=datetime(2026, 2, 26, 14, 0, 10),
    effective_config={'model': 'gpt2', 'backend': 'pytorch'},
)

# Test save
with tempfile.TemporaryDirectory() as tmpdir:
    result_path = r.save(Path(tmpdir))
    assert result_path.name == 'result.json', f'Expected result.json, got {result_path.name}'
    assert result_path.parent.name.startswith('gpt2_pytorch_'), f'Bad dir name: {result_path.parent.name}'

    # Test load
    loaded = ExperimentResult.from_json(result_path)
    assert loaded.experiment_id == r.experiment_id
    assert loaded.schema_version == '2.0'
    assert loaded.measurement_config_hash == r.measurement_config_hash

    # Test collision
    result_path_2 = r.save(Path(tmpdir))
    assert result_path_2 != result_path, 'Collision not handled'
    assert '_1' in result_path_2.parent.name or '_2' in result_path_2.parent.name, f'No suffix: {result_path_2.parent.name}'

print('Persistence OK')
"</automated>
  </verify>
  <done>results/persistence.py created with save_result(), load_result(), atomic writes, collision handling. ExperimentResult.save() and ExperimentResult.from_json() methods delegate to persistence module. Directory names follow {model}_{backend}_{timestamp} pattern. Collision suffixes _1, _2 applied.</done>
</task>

<task type="auto">
  <name>Task 2: Unit tests for persistence API</name>
  <files>
    tests/unit/test_persistence_v2.py
  </files>
  <action>
  **Create `tests/unit/test_persistence_v2.py`:**

  Write comprehensive unit tests (no GPU, uses temp directories):

  1. `test_save_creates_subdirectory()` — save to temp dir, assert subdirectory created with `result.json` inside
  2. `test_save_directory_name_format()` — assert dir name matches `{model}_{backend}_{timestamp}` pattern (regex check)
  3. `test_save_model_slug_normalisation()` — model name with `/` (e.g., "meta-llama/Llama-3.1-8B") becomes "meta-llama-llama-3.1-8b" in directory name
  4. `test_save_atomic_write()` — verify result.json exists and is valid JSON after save
  5. `test_save_returns_result_json_path()` — `save()` return value ends with `result.json`
  6. `test_collision_suffix_applied()` — create existing dir with matching name, save again, assert `_1` suffix
  7. `test_collision_multiple_suffixes()` — create dirs for `_1` and `_2`, assert `_3` suffix used
  8. `test_from_json_loads_correctly()` — save then load, assert all fields match
  9. `test_from_json_round_trip()` — `model_dump_json()` on loaded result matches original (including datetime, tuple)
  10. `test_from_json_missing_sidecar_warns()` — create result with `timeseries="timeseries.parquet"`, save (no sidecar file), load, assert warning emitted via `pytest.warns(UserWarning)`
  11. `test_from_json_missing_sidecar_loads_successfully()` — result loads with timeseries field preserved even when sidecar missing
  12. `test_save_with_timeseries_sidecar()` — create temp parquet file, pass as `timeseries_source`, assert `timeseries.parquet` exists in output dir
  13. `test_save_without_timeseries()` — no timeseries_source, assert no parquet file in output dir
  14. `test_never_overwrites()` — run save 5 times, assert 5 distinct directories
  15. `test_effective_config_round_trips()` — verify effective_config dict survives save/load
  16. `test_steady_state_window_round_trips()` — tuple (12.3, 67.8) survives JSON round-trip

  Create a shared fixture for building valid ExperimentResult instances (same pattern as Plan 01 tests).

  For the timeseries sidecar test, create a minimal parquet file using pyarrow:
  ```python
  import pyarrow as pa
  import pyarrow.parquet as pq

  def _create_temp_parquet(tmp_path):
      table = pa.table({"timestamp_s": [0.0, 1.0], "gpu_power_w": [100.0, 105.0]})
      path = tmp_path / "temp_timeseries.parquet"
      pq.write_table(table, path)
      return path
  ```
  </action>
  <verify>
    <automated>cd /home/h.baker@hertie-school.lan/workspace/llm-efficiency-measurement-tool && python -m pytest tests/unit/test_persistence_v2.py -x -v 2>&1 | tail -25</automated>
  </verify>
  <done>16+ unit tests pass confirming: subdirectory creation, directory name format, slug normalisation, atomic writes, collision suffixes, round-trip fidelity (including datetime and tuple), sidecar management, warning on missing sidecar, never-overwrite guarantee.</done>
</task>

</tasks>

<verification>
1. `python -c "from llenergymeasure.results.persistence import save_result, load_result"` — module exists
2. `python -c "from llenergymeasure.domain.experiment import ExperimentResult; assert hasattr(ExperimentResult, 'save'); assert hasattr(ExperimentResult, 'from_json')"` — methods wired
3. `python -m pytest tests/unit/test_persistence_v2.py -x -v` — all tests pass
4. Manual: create result, save, `ls` output dir — verify `result.json` inside timestamped subdir
</verification>

<success_criteria>
- results/persistence.py created as new module (no inheritance from v1.x repository.py)
- save_result() creates {model}_{backend}_{timestamp}/ subdirectory with result.json
- Collision suffixes _1, _2 applied when directory exists
- Atomic writes via temp + os.replace
- load_result() auto-discovers timeseries sidecar, warns gracefully on missing
- ExperimentResult.save() and .from_json() class method delegate correctly
- Round-trip: save then load produces identical data
- 16+ unit tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/06-results-schema-and-persistence/06-02-SUMMARY.md`
</output>
