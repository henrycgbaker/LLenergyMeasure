---
phase: 04-pytorch-backend-pre-flight
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/llenergymeasure/orchestration/preflight.py
  - src/llenergymeasure/domain/environment.py
  - src/llenergymeasure/domain/experiment.py
  - tests/unit/test_preflight.py
  - tests/unit/test_environment_snapshot.py
autonomous: true
requirements: [CM-29, CM-30, CM-31, CM-32, CM-33]

must_haves:
  truths:
    - "Pre-flight collects all failures into a single PreFlightError (not one at a time)"
    - "Pre-flight checks CUDA availability, backend installed, model accessible — all before GPU allocation"
    - "GPU persistence mode off produces a warning (not an error)"
    - "EnvironmentSnapshot captures Python version, CUDA version, driver version, GPU names, pip freeze, tool version"
    - "CUDA version detection tries torch → version.txt → nvcc → None in order"
  artifacts:
    - path: "src/llenergymeasure/orchestration/preflight.py"
      provides: "Pre-flight validation logic"
      exports: ["run_preflight"]
    - path: "src/llenergymeasure/domain/environment.py"
      provides: "EnvironmentSnapshot model and collection function"
      contains: "class EnvironmentSnapshot"
    - path: "tests/unit/test_preflight.py"
      provides: "Pre-flight unit tests (GPU-free)"
    - path: "tests/unit/test_environment_snapshot.py"
      provides: "EnvironmentSnapshot unit tests (GPU-free)"
  key_links:
    - from: "src/llenergymeasure/orchestration/preflight.py"
      to: "src/llenergymeasure/exceptions.py"
      via: "raises PreFlightError"
      pattern: "raise PreFlightError"
    - from: "src/llenergymeasure/domain/environment.py"
      to: "src/llenergymeasure/__init__.py"
      via: "__version__ import for tool_version"
      pattern: "from llenergymeasure import __version__"
---

<objective>
Create the pre-flight validation module and EnvironmentSnapshot model — the two components that run before any GPU allocation or model loading.

Purpose: Pre-flight catches configuration errors early (before wasting GPU time). EnvironmentSnapshot captures the full software/hardware context for reproducibility. Both are prerequisites for the PyTorch backend (Plan 02).

Output: `orchestration/preflight.py`, augmented `domain/environment.py`, augmented `domain/experiment.py`, and GPU-free unit tests for both.
</objective>

<execution_context>
@/home/h.baker@hertie-school.lan/.claude/get-shit-done/workflows/execute-plan.md
@/home/h.baker@hertie-school.lan/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/STATE.md
@.planning/ROADMAP.md
@.planning/phases/04-pytorch-backend-pre-flight/04-CONTEXT.md
@.planning/phases/04-pytorch-backend-pre-flight/04-RESEARCH.md

<interfaces>
<!-- Key types and contracts the executor needs. Extracted from codebase. -->

From src/llenergymeasure/exceptions.py:
```python
class LLEMError(Exception): ...
class PreFlightError(LLEMError): ...
class BackendError(LLEMError): ...
```

From src/llenergymeasure/config/models.py:
```python
class ExperimentConfig(BaseModel):
    model: str = Field(..., min_length=1)
    backend: Literal["pytorch", "vllm", "tensorrt"] = Field(default="pytorch")
    precision: Literal["fp32", "fp16", "bf16"] = Field(default="bf16")
    passthrough_kwargs: dict[str, Any] | None = Field(default=None)
    pytorch: "PyTorchConfig | None" = Field(default=None)
    # ... other fields
```

From src/llenergymeasure/domain/environment.py:
```python
class GPUEnvironment(BaseModel): ...
class CUDAEnvironment(BaseModel): ...
class ThermalEnvironment(BaseModel): ...
class CPUEnvironment(BaseModel): ...
class ContainerEnvironment(BaseModel): ...
class EnvironmentMetadata(BaseModel):
    gpu: GPUEnvironment
    cuda: CUDAEnvironment
    thermal: ThermalEnvironment
    cpu: CPUEnvironment
    container: ContainerEnvironment
    collected_at: datetime
```

From src/llenergymeasure/domain/experiment.py:
```python
class ExperimentResult(BaseModel):
    environment: EnvironmentMetadata | None = Field(default=None)
    # ... many other fields
    model_config = {"frozen": True}
```

From src/llenergymeasure/__init__.py:
```python
__version__: str = "2.0.0"
```

From src/llenergymeasure/constants.py:
```python
SCHEMA_VERSION = "2.0.0"
```
</interfaces>
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create pre-flight validation module and EnvironmentSnapshot model</name>
  <files>
    src/llenergymeasure/orchestration/preflight.py
    src/llenergymeasure/domain/environment.py
    src/llenergymeasure/domain/experiment.py
  </files>
  <action>
**1. Create `src/llenergymeasure/orchestration/preflight.py`** — the pre-flight validation module.

Function signature: `def run_preflight(config: ExperimentConfig) -> None`

Implementation:
- Use stdlib `logging` only (NOT loguru — see STATE.md decision).
- Use `importlib.util.find_spec()` for backend availability checks (NOT `try: import torch` — avoids heavy module init).
- Collect ALL failures into a `failures: list[str]` before raising a single `PreFlightError`.

Three checks (in order, all run regardless of prior failures):

1. **CUDA available** (`_check_cuda_available() -> bool`):
   - `importlib.util.find_spec("torch")` first — if None, return False.
   - Only if found: `import torch; return torch.cuda.is_available()`.

2. **Backend installed** (`_check_backend_installed(backend: str) -> bool`):
   - Map: `{"pytorch": "transformers", "vllm": "vllm", "tensorrt": "tensorrt_llm"}`.
   - Use `importlib.util.find_spec(package)` to check.

3. **Model accessible** (`_check_model_accessible(model_id: str) -> str | None`):
   - If `model_id` starts with `/`, `./`, or `~` → check `Path(model_id).expanduser().exists()`. Return error string if not found, None if exists.
   - Otherwise (Hub model): if `huggingface_hub` is installed, use `HfApi().model_info(model_id)`.
   - On 401/403/gated → return `"{model_id} gated model — no HF_TOKEN → export HF_TOKEN=<your_token>"`.
   - On 404 → return `"{model_id} not found on HuggingFace Hub"`.
   - On other errors → return None (don't block for network issues).
   - If `huggingface_hub` not installed → return None (skip check).

Non-blocking warning (after checks):

4. **GPU persistence mode** (`_warn_if_persistence_mode_off() -> None`):
   - Try pynvml: `nvmlInit()`, `nvmlDeviceGetHandleByIndex(0)`, `nvmlDeviceGetPersistenceMode(handle)`.
   - If disabled: `logger.warning("GPU persistence mode is off. First experiment may have higher latency. Enable: sudo nvidia-smi -pm 1")`.
   - Wrap entire thing in `except Exception: pass` — never block.
   - Call `nvmlShutdown()` in a finally block.

Error format (from CONTEXT.md):
```
Pre-flight failed: {N} issue(s) found
  ✗ {failure_1}
  ✗ {failure_2}
```

**2. Augment `src/llenergymeasure/domain/environment.py`** — add `EnvironmentSnapshot` model and collection function.

Add to the existing file (AFTER the `EnvironmentMetadata` class):

```python
class EnvironmentSnapshot(BaseModel):
    """Full software+hardware environment snapshot for experiment reproducibility."""
    hardware: EnvironmentMetadata
    python_version: str
    pip_freeze: str
    conda_list: str | None = None
    tool_version: str
    cuda_version: str | None = None
    cuda_version_source: str | None = None  # "torch" | "version_txt" | "nvcc" | None
```

Add collection functions:
- `collect_environment_snapshot() -> EnvironmentSnapshot` — captures full environment state.
  - Calls existing `collect_environment_metadata()` from `core/environment.py` for hardware.
  - Uses `platform.python_version()` for Python version.
  - Calls `_capture_pip_freeze()` — runs `[sys.executable, "-m", "pip", "freeze"]` with 30s timeout.
  - Calls `_capture_conda_list()` — checks `shutil.which("conda")`, runs `["conda", "list"]` with 30s timeout, returns None if conda not detected.
  - Uses `llenergymeasure.__version__` for tool_version.
  - Calls `detect_cuda_version_with_source()` for CUDA version.

- `detect_cuda_version_with_source() -> tuple[str | None, str | None]` — multi-source fallback (CM-33):
  - Source 1: `torch.version.cuda` (if torch installed via `importlib.util.find_spec`).
  - Source 2: Parse `/usr/local/cuda/version.txt` or `version.json` with regex `r"(\d+\.\d+)"`.
  - Source 3: `subprocess.run(["nvcc", "--version"])` with 5s timeout, parse `r"release (\d+\.\d+)"`.
  - Source 4: Return `(None, None)`.

All subprocess calls: use `capture_output=True, text=True`, catch `Exception`, log debug on failure, return empty/None.

**3. Augment `src/llenergymeasure/domain/experiment.py`** — add `environment_snapshot` field to `ExperimentResult`.

Add a new field to `ExperimentResult` (alongside the existing `environment` field):
```python
environment_snapshot: EnvironmentSnapshot | None = Field(
    default=None,
    description="Full software+hardware environment snapshot (v2.0)",
)
```

Add the import: `from llenergymeasure.domain.environment import EnvironmentSnapshot`

Keep the existing `environment: EnvironmentMetadata | None` field as-is (it stays None in Phase 4 outputs; Phase 6 reconciles).

**IMPORTANT constraints:**
- All new code uses `import logging; logger = logging.getLogger(__name__)` — NOT loguru.
- Pre-flight MUST NOT import torch at module level. Use `importlib.util.find_spec()` first, then conditional import inside function bodies.
- `collect_environment_snapshot()` uses deferred imports for `llenergymeasure.__version__` and `core/environment.py` to avoid circular imports.
  </action>
  <verify>
    <automated>cd /home/h.baker@hertie-school.lan/workspace/llm-efficiency-measurement-tool && python -c "from llenergymeasure.orchestration.preflight import run_preflight; from llenergymeasure.domain.environment import EnvironmentSnapshot, collect_environment_snapshot, detect_cuda_version_with_source; print('imports OK')"</automated>
  </verify>
  <done>
    - `preflight.py` exists with `run_preflight()` that collects all failures into a single `PreFlightError`
    - `EnvironmentSnapshot` model exists in `domain/environment.py` with all CM-32 fields
    - `detect_cuda_version_with_source()` implements the 4-source fallback chain (CM-33)
    - `ExperimentResult` has `environment_snapshot: EnvironmentSnapshot | None` field
    - All new code uses stdlib logging (not loguru)
  </done>
</task>

<task type="auto">
  <name>Task 2: Write GPU-free unit tests for pre-flight and EnvironmentSnapshot</name>
  <files>
    tests/unit/test_preflight.py
    tests/unit/test_environment_snapshot.py
  </files>
  <action>
**1. Create `tests/unit/test_preflight.py`** — GPU-free tests using monkeypatch.

Tests (all must pass without a GPU):

```python
# Test: All checks pass → no exception
def test_preflight_passes_when_all_ok(monkeypatch):
    # monkeypatch find_spec to return truthy, torch.cuda.is_available to True,
    # HfApi().model_info to succeed
    ...

# Test: collect-all pattern — multiple failures reported
def test_preflight_collects_all_failures(monkeypatch):
    # monkeypatch CUDA unavailable + backend not installed + model not found
    # Assert PreFlightError raised with "3 issue(s) found"
    # Assert all three failure messages present in error string
    ...

# Test: CUDA unavailable → failure
def test_preflight_cuda_unavailable(monkeypatch):
    # monkeypatch find_spec("torch") to return None
    # Assert PreFlightError contains "CUDA not available"
    ...

# Test: Backend not installed → failure
def test_preflight_backend_not_installed(monkeypatch):
    # monkeypatch find_spec("transformers") to return None but torch is available
    # Assert PreFlightError contains "pytorch not installed"
    ...

# Test: Gated model → failure with token hint
def test_preflight_gated_model(monkeypatch):
    # monkeypatch HfApi().model_info to raise with "403" in message
    # Assert PreFlightError contains "gated model" and "HF_TOKEN"
    ...

# Test: Model not found → failure
def test_preflight_model_not_found(monkeypatch):
    # monkeypatch HfApi().model_info to raise with "404" in message
    # Assert PreFlightError contains "not found"
    ...

# Test: Local model path exists → pass
def test_preflight_local_model_path(monkeypatch, tmp_path):
    # Create a temp dir as local model path
    # monkeypatch CUDA + backend as OK
    # Assert no PreFlightError
    ...

# Test: Local model path missing → failure
def test_preflight_local_model_missing(monkeypatch):
    # Use a non-existent path starting with "/"
    # Assert PreFlightError contains the path
    ...

# Test: Persistence mode warning (non-blocking)
def test_preflight_persistence_mode_warning_not_blocking(monkeypatch, caplog):
    # monkeypatch all checks to pass, pynvml to report persistence mode off
    # Assert no PreFlightError raised (warning only)
    # Assert warning message in caplog
    ...

# Test: Error format matches CONTEXT.md spec
def test_preflight_error_format(monkeypatch):
    # Trigger 2 failures
    # Assert error message starts with "Pre-flight failed: 2 issue(s) found"
    # Assert each failure line starts with "  ✗ "
    ...
```

Import `PreFlightError` from `llenergymeasure.exceptions`. Use `monkeypatch` extensively to avoid requiring torch/pynvml/huggingface_hub at test time.

**2. Create `tests/unit/test_environment_snapshot.py`** — GPU-free tests.

```python
# Test: EnvironmentSnapshot model construction
def test_environment_snapshot_model():
    # Construct with all fields, assert all accessible
    ...

# Test: CUDA version detection — torch source
def test_cuda_version_from_torch(monkeypatch):
    # Mock torch.version.cuda = "12.1"
    # Assert returns ("12.1", "torch")
    ...

# Test: CUDA version detection — version.txt source
def test_cuda_version_from_version_txt(monkeypatch, tmp_path):
    # Mock find_spec("torch") to None
    # Create a version.txt with "CUDA Version 12.4"
    # Monkeypatch Path references
    # Assert returns ("12.4", "version_txt")
    ...

# Test: CUDA version detection — nvcc source
def test_cuda_version_from_nvcc(monkeypatch):
    # Mock find_spec("torch") to None, no version.txt
    # Mock subprocess.run to return nvcc output with "release 12.2"
    # Assert returns ("12.2", "nvcc")
    ...

# Test: CUDA version detection — all sources fail
def test_cuda_version_none(monkeypatch):
    # Mock all sources to fail
    # Assert returns (None, None)
    ...

# Test: pip freeze capture
def test_pip_freeze_capture(monkeypatch):
    # Mock subprocess.run to return known output
    # Assert captured string matches
    ...

# Test: conda list returns None when conda not installed
def test_conda_list_no_conda(monkeypatch):
    # Mock shutil.which("conda") to return None
    # Assert returns None
    ...

# Test: collect_environment_snapshot integration (mocked hardware)
def test_collect_environment_snapshot(monkeypatch):
    # Mock collect_environment_metadata, pip freeze, CUDA detection
    # Assert EnvironmentSnapshot has all fields populated
    ...
```

Use `monkeypatch` for all subprocess and import mocking. No GPU required.
  </action>
  <verify>
    <automated>cd /home/h.baker@hertie-school.lan/workspace/llm-efficiency-measurement-tool && python -m pytest tests/unit/test_preflight.py tests/unit/test_environment_snapshot.py -x -v 2>&1 | tail -20</automated>
  </verify>
  <done>
    - All pre-flight tests pass without a GPU
    - All EnvironmentSnapshot tests pass without a GPU
    - Tests cover: collect-all pattern, each check type, error format, CUDA detection fallback chain, pip/conda capture
    - No test imports torch, pynvml, or huggingface_hub directly (all monkeypatched)
  </done>
</task>

</tasks>

<verification>
- `python -c "from llenergymeasure.orchestration.preflight import run_preflight"` succeeds
- `python -c "from llenergymeasure.domain.environment import EnvironmentSnapshot, collect_environment_snapshot, detect_cuda_version_with_source"` succeeds
- `python -c "from llenergymeasure.domain.experiment import ExperimentResult; assert hasattr(ExperimentResult.model_fields, '__contains__') and 'environment_snapshot' in ExperimentResult.model_fields"` succeeds
- `pytest tests/unit/test_preflight.py tests/unit/test_environment_snapshot.py -x` all pass
- No `from loguru import logger` in any newly created file
</verification>

<success_criteria>
1. `run_preflight()` collects all failures and raises a single `PreFlightError` with the exact format from CONTEXT.md
2. Pre-flight checks CUDA, backend, and model accessibility — all without importing torch at module level
3. GPU persistence mode warning is non-blocking (warning only, not error)
4. `EnvironmentSnapshot` model captures all CM-32 fields: Python version, CUDA version, driver version, GPU names/VRAM, pip freeze, tool version
5. `detect_cuda_version_with_source()` implements `torch → version.txt → nvcc → None` chain (CM-33)
6. `ExperimentResult` has new `environment_snapshot: EnvironmentSnapshot | None` field
7. All unit tests pass without a GPU
</success_criteria>

<output>
After completion, create `.planning/phases/04-pytorch-backend-pre-flight/04-01-SUMMARY.md`
</output>
