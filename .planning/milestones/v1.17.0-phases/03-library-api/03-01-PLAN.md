---
phase: 03-library-api
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/llenergymeasure/domain/experiment.py
  - src/llenergymeasure/domain/__init__.py
  - src/llenergymeasure/config/models.py
autonomous: true
requirements: [CFG-17, LA-09]

must_haves:
  truths:
    - "`ExperimentResult` is the primary class name in domain/experiment.py; `AggregatedResult` is a compatibility alias only"
    - "`StudyConfig` exists in config/models.py with `experiments: list[ExperimentConfig]` and `name: str | None`"
    - "`StudyResult` exists in domain/experiment.py with `experiments: list[ExperimentResult]` and `name: str | None`"
    - "`from llenergymeasure.domain.experiment import ExperimentResult, StudyResult` resolves"
    - "`from llenergymeasure.config.models import StudyConfig` resolves"
  artifacts:
    - path: "src/llenergymeasure/domain/experiment.py"
      provides: "ExperimentResult class (renamed from AggregatedResult), StudyResult stub, AggregatedResult alias"
      contains: "class ExperimentResult"
    - path: "src/llenergymeasure/config/models.py"
      provides: "StudyConfig model"
      contains: "class StudyConfig"
    - path: "src/llenergymeasure/domain/__init__.py"
      provides: "ExperimentResult and StudyResult in __all__"
      contains: "ExperimentResult"
  key_links:
    - from: "src/llenergymeasure/domain/experiment.py"
      to: "AggregatedResult alias"
      via: "AggregatedResult = ExperimentResult"
      pattern: "AggregatedResult = ExperimentResult"
    - from: "src/llenergymeasure/config/models.py"
      to: "ExperimentConfig"
      via: "StudyConfig.experiments field type"
      pattern: "experiments: list\\[ExperimentConfig\\]"
---

<objective>
Rename `AggregatedResult` to `ExperimentResult`, create `StudyResult` stub, and create `StudyConfig` stub -- establishing the type contracts that Plan 02 (`_api.py` + `__init__.py`) depends on.

Purpose: The public API functions (`run_experiment`, `run_study`) and the `__init__.py` surface need these types to exist before they can be imported and wired. This plan delivers those types.

Output: `ExperimentResult` class, `AggregatedResult` compatibility alias, `StudyResult` stub, `StudyConfig` stub.
</objective>

<execution_context>
@/home/h.baker@hertie-school.lan/.claude/get-shit-done/workflows/execute-plan.md
@/home/h.baker@hertie-school.lan/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/STATE.md
@.planning/ROADMAP.md
@.planning/phases/03-library-api/03-CONTEXT.md
@.planning/phases/03-library-api/03-RESEARCH.md
@src/llenergymeasure/domain/experiment.py
@src/llenergymeasure/domain/__init__.py
@src/llenergymeasure/config/models.py

<interfaces>
<!-- Existing types the executor needs to know about -->

From src/llenergymeasure/domain/experiment.py:
```python
class AggregatedResult(BaseModel):
    """Aggregated experiment result from multiple processes."""
    # ~30 fields -- full v1.x schema
    model_config = {"frozen": True}
    # Properties: duration_sec, tokens_per_joule
```

From src/llenergymeasure/config/models.py:
```python
class ExperimentConfig(BaseModel):
    """v2.0 experiment configuration."""
    model_config = {"extra": "forbid"}
    model: str = Field(...)
    backend: Literal["pytorch", "vllm", "tensorrt"] = ...
    # ... many fields ...

# At bottom of file:
def _rebuild_experiment_config() -> None: ...
_rebuild_experiment_config()
```

From src/llenergymeasure/domain/__init__.py:
```python
from llenergymeasure.domain.experiment import (
    AggregatedResult, AggregationMetadata, RawProcessResult, Timestamps,
)
__all__ = ["AggregatedResult", "AggregationMetadata", ...]
```

From src/llenergymeasure/protocols.py (TYPE_CHECKING only):
```python
from llenergymeasure.domain.experiment import ExperimentResult
# Used in ResultsRepository Protocol
```
</interfaces>
</context>

<tasks>

<task type="auto">
  <name>Task 1: Rename AggregatedResult to ExperimentResult and add StudyResult stub</name>
  <files>
    src/llenergymeasure/domain/experiment.py
    src/llenergymeasure/domain/__init__.py
  </files>
  <action>
In `src/llenergymeasure/domain/experiment.py`:

1. **Rename the class** `AggregatedResult` to `ExperimentResult`. Change `class AggregatedResult(BaseModel):` to `class ExperimentResult(BaseModel):`. Update the docstring to say "Experiment result" rather than "Aggregated experiment result from multiple processes". Keep all fields, properties, and `model_config` identical.

2. **Add compatibility alias** at the bottom of the file, after the class definition:
```python
# v1.x compatibility alias -- remove in v3.0
AggregatedResult = ExperimentResult
```
This follows the same pattern already used in `exceptions.py` for `ConfigurationError = ConfigError`.

3. **Add `StudyResult` stub class** after the `ExperimentResult` class and before the alias. This is a minimal Pydantic BaseModel:
```python
class StudyResult(BaseModel):
    """Container for study results.

    M1 stub: experiments list + name only. Full schema (study_design_hash,
    measurement_protocol, result_files, StudySummary) added in M2 (RES-13..15).
    """

    experiments: list[ExperimentResult] = Field(
        default_factory=list, description="Results for each experiment in the study"
    )
    name: str | None = Field(default=None, description="Study name")
```
Import `Field` from pydantic is already present. No `model_config` override needed (mutable is fine for a result container).

4. In `src/llenergymeasure/domain/__init__.py`:
- Change `AggregatedResult` import to also import `ExperimentResult` and `StudyResult`
- Keep `AggregatedResult` in the import (it's the alias, still importable)
- Add `ExperimentResult` and `StudyResult` to `__all__`

The updated imports should look like:
```python
from llenergymeasure.domain.experiment import (
    AggregatedResult,
    AggregationMetadata,
    ExperimentResult,
    RawProcessResult,
    StudyResult,
    Timestamps,
)
```

And `__all__` should include `"ExperimentResult"` and `"StudyResult"`.

**Do NOT update** any other files that import `AggregatedResult` (e.g., `cli/display/results.py`, `results/aggregation.py`). The alias ensures they continue to work. Those files will be updated in Phase 7 (CLI) when they are rewritten.

**Note:** `protocols.py` already has `from llenergymeasure.domain.experiment import ExperimentResult` under `TYPE_CHECKING` -- once the rename is done, that import will resolve correctly with no changes needed.
  </action>
  <verify>
    <automated>cd /home/h.baker@hertie-school.lan/workspace/llm-efficiency-measurement-tool && python -c "
from llenergymeasure.domain.experiment import ExperimentResult, StudyResult, AggregatedResult
assert ExperimentResult is AggregatedResult, 'Alias broken'
assert hasattr(StudyResult, 'model_fields'), 'StudyResult not a Pydantic model'
assert 'experiments' in StudyResult.model_fields, 'Missing experiments field'
assert 'name' in StudyResult.model_fields, 'Missing name field'
print('OK: ExperimentResult + StudyResult + alias all resolve')
"</automated>
  </verify>
  <done>
    - `ExperimentResult` is the primary class in `domain/experiment.py`
    - `AggregatedResult = ExperimentResult` alias exists at bottom of file
    - `StudyResult` stub with `experiments` and `name` fields exists
    - All three names importable from `domain.experiment` and `domain.__init__`
    - Existing code using `AggregatedResult` continues to work unchanged
  </done>
</task>

<task type="auto">
  <name>Task 2: Add StudyConfig to config/models.py</name>
  <files>
    src/llenergymeasure/config/models.py
  </files>
  <action>
Add `StudyConfig` class to `src/llenergymeasure/config/models.py`, placed **after** `ExperimentConfig` and **after** the `_rebuild_experiment_config()` call (at the very bottom of the file). This ensures `ExperimentConfig` is fully built (forward references resolved) before `StudyConfig` references it.

```python
class StudyConfig(BaseModel):
    """Thin resolved container for a study (list of experiments + execution config).

    M1 stub: only experiments + name. ExecutionConfig and sweep grammar added in M2.
    """

    model_config = {"extra": "forbid"}

    experiments: list[ExperimentConfig] = Field(
        ..., min_length=1, description="Resolved list of experiments to run"
    )
    name: str | None = Field(
        default=None, description="Study name (used in output directory naming)"
    )
```

No `model_rebuild()` call needed -- `ExperimentConfig` is already defined and rebuilt above.

**Do NOT** add `StudyConfig` to `config/__init__.py`. The public surface for `StudyConfig` is through the top-level `llenergymeasure.__init__.py` (Plan 02). The `config/__init__.py` is for internal config subsystem consumers.
  </action>
  <verify>
    <automated>cd /home/h.baker@hertie-school.lan/workspace/llm-efficiency-measurement-tool && python -c "
from llenergymeasure.config.models import ExperimentConfig, StudyConfig
# Verify StudyConfig works with a real ExperimentConfig
ec = ExperimentConfig(model='gpt2')
sc = StudyConfig(experiments=[ec])
assert len(sc.experiments) == 1
assert sc.experiments[0].model == 'gpt2'
assert sc.name is None
# Verify extra=forbid
import pydantic
try:
    StudyConfig(experiments=[ec], bad_field='x')
    assert False, 'extra=forbid not working'
except pydantic.ValidationError:
    pass
# Verify min_length=1
try:
    StudyConfig(experiments=[])
    assert False, 'min_length not working'
except pydantic.ValidationError:
    pass
print('OK: StudyConfig validates correctly')
"</automated>
  </verify>
  <done>
    - `StudyConfig` exists in `config/models.py` after `ExperimentConfig`
    - `experiments: list[ExperimentConfig]` with `min_length=1` validates correctly
    - `name: str | None` defaults to `None`
    - `extra="forbid"` rejects unknown fields
    - `StudyConfig(experiments=[ExperimentConfig(model="gpt2")])` constructs successfully
  </done>
</task>

</tasks>

<verification>
Run all verification commands in sequence:

```bash
cd /home/h.baker@hertie-school.lan/workspace/llm-efficiency-measurement-tool

# 1. Type imports resolve
python -c "
from llenergymeasure.domain.experiment import ExperimentResult, StudyResult, AggregatedResult
from llenergymeasure.config.models import ExperimentConfig, StudyConfig
print('All imports resolve')
"

# 2. Alias correctness
python -c "
from llenergymeasure.domain.experiment import ExperimentResult, AggregatedResult
assert ExperimentResult is AggregatedResult
print('Alias correct')
"

# 3. StudyConfig with ExperimentConfig
python -c "
from llenergymeasure.config.models import ExperimentConfig, StudyConfig
sc = StudyConfig(experiments=[ExperimentConfig(model='gpt2')])
assert sc.experiments[0].model == 'gpt2'
print('StudyConfig integration correct')
"

# 4. StudyResult with ExperimentResult
python -c "
from llenergymeasure.domain.experiment import ExperimentResult, StudyResult
sr = StudyResult(experiments=[], name='test')
assert sr.name == 'test'
print('StudyResult correct')
"

# 5. Existing tests still pass (domain and config)
python -m pytest tests/unit/test_domain_experiment.py tests/unit/test_config_models.py -x -q 2>&1 | tail -5
```
</verification>

<success_criteria>
1. `from llenergymeasure.domain.experiment import ExperimentResult, StudyResult, AggregatedResult` all resolve
2. `ExperimentResult is AggregatedResult` (alias, not separate class)
3. `from llenergymeasure.config.models import StudyConfig` resolves
4. `StudyConfig(experiments=[ExperimentConfig(model="gpt2")])` validates
5. `StudyConfig(experiments=[])` raises `ValidationError` (min_length=1)
6. Existing tests in `test_domain_experiment.py` and `test_config_models.py` pass unchanged
</success_criteria>

<output>
After completion, create `.planning/phases/03-library-api/03-01-SUMMARY.md`
</output>
