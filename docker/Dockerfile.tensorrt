# syntax=docker/dockerfile:1
# =============================================================================
# TensorRT-LLM Backend: High-performance compiled inference
# =============================================================================
# IMPORTANT: Requires NVIDIA NGC authentication before building.
#
# Setup NGC access:
#   1. Create account at https://ngc.nvidia.com/
#   2. Generate API key at https://ngc.nvidia.com/setup/api-key
#   3. Login: docker login nvcr.io -u '$oauthtoken' -p <YOUR_API_KEY>
#
# Then build:
#   docker compose build tensorrt
#
# Note: TensorRT-LLM requires NVIDIA GPU with compute capability >= 8.0 (Ampere+)
# =============================================================================

# NVIDIA's official TensorRT-LLM image - includes all CUDA/TensorRT dependencies
# See: https://catalog.ngc.nvidia.com/orgs/nvidia/containers/tensorrt_llm
ARG TRTLLM_VERSION=0.17.0
FROM nvcr.io/nvidia/tensorrt_llm/release:${TRTLLM_VERSION} AS base

WORKDIR /app

# Install additional Python dependencies
RUN pip install --no-cache-dir \
    pydantic loguru typer codecarbon nvidia-ml-py datasets schedule \
    transformers accelerate

# ============================================================================
# Stage: Runtime - Production image
# ============================================================================
FROM base AS runtime

WORKDIR /app

COPY pyproject.toml poetry.lock* README.md ./
COPY src/ ./src/

# Install package (tensorrt-llm already in base)
RUN pip install --no-cache-dir --no-deps -e .

ENV TRT_ENGINE_CACHE=/app/.cache/tensorrt-engines
RUN mkdir -p ${TRT_ENGINE_CACHE}

CMD ["llm-energy-measure", "--help"]

# ============================================================================
# Stage: Dev - Development image
# ============================================================================
FROM base AS dev

WORKDIR /app

COPY pyproject.toml poetry.lock* README.md ./
COPY src/ ./src/

RUN pip install --no-cache-dir --no-deps -e . && \
    pip install --no-cache-dir pytest pytest-cov ruff mypy pre-commit commitizen

ENV TRT_ENGINE_CACHE=/app/.cache/tensorrt-engines
RUN mkdir -p ${TRT_ENGINE_CACHE}

CMD ["/bin/bash"]
