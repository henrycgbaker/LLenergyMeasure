# Test pipeline parallel sharding (splits model stages across GPUs)
config_name: sharding_pipeline
model_name: meta-llama/Llama-2-7b-hf

sharding:
  strategy: pipeline_parallel
  num_shards: 2

gpus: [0, 1]
max_new_tokens: 64
batch_size: 4
