# Example minimal config for testing
# Validates quickly and runs on a single GPU

config_name: test-tinyllama
model_name: TinyLlama/TinyLlama-1.1B-Chat-v1.0

# Minimal settings for quick test
max_input_tokens: 32
max_output_tokens: 16
num_input_prompts: 4

# Single GPU
# On servers with MIG-enabled GPUs, use CUDA_VISIBLE_DEVICES=0 to select
# the physical GPU rather than MIG instances
gpu_list: [0]
num_processes: 1

# Batching
batching_options:
  batch_size: 2
