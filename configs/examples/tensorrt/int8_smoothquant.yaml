# TensorRT-LLM INT8 SmoothQuant configuration
#
# INT8 SmoothQuant provides good accuracy with ~1.5-2x speedup.
# Requires calibration data for optimal accuracy.
#
# Usage:
#   llm-energy-measure experiment configs/examples/tensorrt/int8_smoothquant.yaml -n 50

config_name: tensorrt_int8_smoothquant
model_name: meta-llama/Llama-2-7b-hf
backend: tensorrt

max_input_tokens: 2048
max_output_tokens: 256
num_input_prompts: 50
gpus: [0]

fp_precision: float16

decoder:
  preset: deterministic

# TensorRT-specific configuration
tensorrt:
  # Build configuration
  max_batch_size: 8
  builder_opt_level: 3

  # INT8 SmoothQuant quantization with calibration
  quantization:
    method: int8_sq
    calibration:
      dataset: wikitext
      split: train
      num_samples: 512
      max_length: 2048

  # Runtime configuration
  kv_cache_type: paged
  enable_chunked_context: true
  gpu_memory_utilization: 0.85
