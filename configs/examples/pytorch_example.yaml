schema_version: '3.0.0'
config_name: pytorch-comprehensive

model_name: Qwen/Qwen2.5-0.5B
backend: pytorch
gpus: [0, 1, 2, 3]

# Token configuration
max_input_tokens: 512
max_output_tokens: 128
num_input_prompts: 100

# Precision and determinism
fp_precision: float16
random_seed: 42

# Dataset (simple form)
dataset:
  name: ai_energy_score
  sample_size: 100

# Decoder settings
decoder:
  preset: deterministic

# PyTorch-specific optimizations
pytorch:
  num_processes: 4  # Data parallelism across 4 GPUs
  batch_size: 8
  batching_strategy: dynamic
  attn_implementation: sdpa  # Use flash_attention_2 if installed
  torch_compile: false  # Set to 'inductor' for production
  use_cache: true
  low_cpu_mem_usage: true

# Measurement settings (v3.0.0)
warmup:
  enabled: true
  convergence_detection: true
  min_prompts: 5
  max_prompts: 20
  cv_threshold: 0.05

baseline:
  enabled: true
  cache_ttl_sec: 3600

timeseries:
  enabled: true
  sample_interval_ms: 200

# See docs/cli.md for full parameter reference
