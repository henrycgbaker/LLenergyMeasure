schema_version: '3.0.0'
config_name: tensorrt-comprehensive

model_name: Qwen/Qwen2.5-0.5B
backend: tensorrt
gpus: [0, 1, 2, 3]

max_input_tokens: 512
max_output_tokens: 128
num_input_prompts: 100

fp_precision: float16
random_seed: 42

dataset:
  name: ai_energy_score
  sample_size: 100

decoder:
  preset: deterministic

# TensorRT-LLM optimizations
tensorrt:
  max_batch_size: 8
  builder_opt_level: 3
  tp_size: 2
  quantization: none  # Options: none, fp8, int8_sq
  kv_cache_type: paged
  enable_chunked_context: true
  gpu_memory_utilization: 0.9
  force_rebuild: true  # Rebuild for tp=4

# Measurement settings
warmup:
  enabled: true
  convergence_detection: true
  min_prompts: 5
  cv_threshold: 0.05

baseline:
  enabled: true
  cache_ttl_sec: 3600

timeseries:
  enabled: true
  sample_interval_ms: 200

# See docs/backends.md for TensorRT requirements (Ampere+ GPU)
